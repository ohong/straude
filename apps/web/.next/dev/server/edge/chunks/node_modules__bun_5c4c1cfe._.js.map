{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/dist/module/types.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/src/types.ts"],"sourcesContent":["export type Fetch = typeof fetch\n\n/**\n * Response format\n */\nexport interface FunctionsResponseSuccess<T> {\n  data: T\n  error: null\n  response?: Response\n}\nexport interface FunctionsResponseFailure {\n  data: null\n  error: any\n  response?: Response\n}\nexport type FunctionsResponse<T> = FunctionsResponseSuccess<T> | FunctionsResponseFailure\n\n/**\n * Base error for Supabase Edge Function invocations.\n *\n * @example\n * ```ts\n * import { FunctionsError } from '@supabase/functions-js'\n *\n * throw new FunctionsError('Unexpected error invoking function', 'FunctionsError', {\n *   requestId: 'abc123',\n * })\n * ```\n */\nexport class FunctionsError extends Error {\n  context: any\n  constructor(message: string, name = 'FunctionsError', context?: any) {\n    super(message)\n    this.name = name\n    this.context = context\n  }\n}\n\n/**\n * Error thrown when the network request to an Edge Function fails.\n *\n * @example\n * ```ts\n * import { FunctionsFetchError } from '@supabase/functions-js'\n *\n * throw new FunctionsFetchError({ requestId: 'abc123' })\n * ```\n */\nexport class FunctionsFetchError extends FunctionsError {\n  constructor(context: any) {\n    super('Failed to send a request to the Edge Function', 'FunctionsFetchError', context)\n  }\n}\n\n/**\n * Error thrown when the Supabase relay cannot reach the Edge Function.\n *\n * @example\n * ```ts\n * import { FunctionsRelayError } from '@supabase/functions-js'\n *\n * throw new FunctionsRelayError({ region: 'us-east-1' })\n * ```\n */\nexport class FunctionsRelayError extends FunctionsError {\n  constructor(context: any) {\n    super('Relay Error invoking the Edge Function', 'FunctionsRelayError', context)\n  }\n}\n\n/**\n * Error thrown when the Edge Function returns a non-2xx status code.\n *\n * @example\n * ```ts\n * import { FunctionsHttpError } from '@supabase/functions-js'\n *\n * throw new FunctionsHttpError({ status: 500 })\n * ```\n */\nexport class FunctionsHttpError extends FunctionsError {\n  constructor(context: any) {\n    super('Edge Function returned a non-2xx status code', 'FunctionsHttpError', context)\n  }\n}\n// Define the enum for the 'region' property\nexport enum FunctionRegion {\n  Any = 'any',\n  ApNortheast1 = 'ap-northeast-1',\n  ApNortheast2 = 'ap-northeast-2',\n  ApSouth1 = 'ap-south-1',\n  ApSoutheast1 = 'ap-southeast-1',\n  ApSoutheast2 = 'ap-southeast-2',\n  CaCentral1 = 'ca-central-1',\n  EuCentral1 = 'eu-central-1',\n  EuWest1 = 'eu-west-1',\n  EuWest2 = 'eu-west-2',\n  EuWest3 = 'eu-west-3',\n  SaEast1 = 'sa-east-1',\n  UsEast1 = 'us-east-1',\n  UsWest1 = 'us-west-1',\n  UsWest2 = 'us-west-2',\n}\n\nexport type FunctionInvokeOptions = {\n  /**\n   * Object representing the headers to send with the request.\n   */\n  headers?: { [key: string]: string }\n  /**\n   * The HTTP verb of the request\n   */\n  method?: 'POST' | 'GET' | 'PUT' | 'PATCH' | 'DELETE'\n  /**\n   * The Region to invoke the function in.\n   */\n  region?: FunctionRegion\n  /**\n   * The body of the request.\n   */\n  body?:\n    | File\n    | Blob\n    | ArrayBuffer\n    | FormData\n    | ReadableStream<Uint8Array>\n    | Record<string, any>\n    | string\n  /**\n   * The AbortSignal to use for the request.\n   * */\n  signal?: AbortSignal\n  /**\n   * The timeout for the request in milliseconds.\n   * If the function takes longer than this, the request will be aborted.\n   * */\n  timeout?: number\n}\n"],"names":[],"mappings":"AAiBA;;;;;;;;;;;GAWG;;;;;;;;;;;;AACG,MAAO,cAAe,SAAQ,KAAK;IAEvC,YAAY,OAAe,EAAE,IAAI,GAAG,gBAAgB,EAAE,OAAa,CAAA;QACjE,KAAK,CAAC,OAAO,CAAC,CAAA;QACd,IAAI,CAAC,IAAI,GAAG,IAAI,CAAA;QAChB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;IACxB,CAAC;CACF;AAYK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,+CAA+C,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACxF,CAAC;CACF;AAYK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,wCAAwC,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACjF,CAAC;CACF;AAYK,MAAO,kBAAmB,SAAQ,cAAc;IACpD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,8CAA8C,EAAE,oBAAoB,EAAE,OAAO,CAAC,CAAA;IACtF,CAAC;CACF;AAED,IAAY,cAgBX;AAhBD,CAAA,SAAY,cAAc;IACxB,cAAA,CAAA,MAAA,GAAA,KAAW,CAAA;IACX,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,WAAA,GAAA,YAAuB,CAAA;IACvB,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;AACvB,CAAC,EAhBW,cAAc,IAAA,CAAd,cAAc,GAAA,CAAA,CAAA,GAgBzB"}},
    {"offset": {"line": 71, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/dist/module/helper.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/src/helper.ts"],"sourcesContent":["import { Fetch } from './types'\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n"],"names":[],"mappings":";;;;AAEO,MAAM,YAAY,GAAG,CAAC,WAAmB,EAAS,EAAE;IACzD,IAAI,WAAW,EAAE,CAAC;QAChB,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,UAAY,CAAC,GAAG,IAAI,CAAC,CAAA;IAC1C,CAAC;IACD,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,IAAM,CAAC,GAAG,IAAI,CAAC,CAAA;AACpC,CAAC,CAAA"}},
    {"offset": {"line": 85, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/dist/module/FunctionsClient.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+functions-js@2.95.3/node_modules/@supabase/functions-js/src/FunctionsClient.ts"],"sourcesContent":["import { resolveFetch } from './helper'\nimport {\n  Fetch,\n  FunctionInvokeOptions,\n  FunctionRegion,\n  FunctionsFetchError,\n  FunctionsHttpError,\n  FunctionsRelayError,\n  FunctionsResponse,\n} from './types'\n\n/**\n * Client for invoking Supabase Edge Functions.\n */\nexport class FunctionsClient {\n  protected url: string\n  protected headers: Record<string, string>\n  protected region: FunctionRegion\n  protected fetch: Fetch\n\n  /**\n   * Creates a new Functions client bound to an Edge Functions URL.\n   *\n   * @example\n   * ```ts\n   * import { FunctionsClient, FunctionRegion } from '@supabase/functions-js'\n   *\n   * const functions = new FunctionsClient('https://xyzcompany.supabase.co/functions/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   region: FunctionRegion.UsEast1,\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      customFetch,\n      region = FunctionRegion.Any,\n    }: {\n      headers?: Record<string, string>\n      customFetch?: Fetch\n      region?: FunctionRegion\n    } = {}\n  ) {\n    this.url = url\n    this.headers = headers\n    this.region = region\n    this.fetch = resolveFetch(customFetch)\n  }\n\n  /**\n   * Updates the authorization header\n   * @param token - the new jwt token sent in the authorisation header\n   * @example\n   * ```ts\n   * functions.setAuth(session.access_token)\n   * ```\n   */\n  setAuth(token: string) {\n    this.headers.Authorization = `Bearer ${token}`\n  }\n\n  /**\n   * Invokes a function\n   * @param functionName - The name of the Function to invoke.\n   * @param options - Options for invoking the Function.\n   * @example\n   * ```ts\n   * const { data, error } = await functions.invoke('hello-world', {\n   *   body: { name: 'Ada' },\n   * })\n   * ```\n   */\n  async invoke<T = any>(\n    functionName: string,\n    options: FunctionInvokeOptions = {}\n  ): Promise<FunctionsResponse<T>> {\n    let timeoutId: ReturnType<typeof setTimeout> | undefined\n    let timeoutController: AbortController | undefined\n\n    try {\n      const { headers, method, body: functionArgs, signal, timeout } = options\n      let _headers: Record<string, string> = {}\n      let { region } = options\n      if (!region) {\n        region = this.region\n      }\n      // Add region as query parameter using URL API\n      const url = new URL(`${this.url}/${functionName}`)\n      if (region && region !== 'any') {\n        _headers['x-region'] = region\n        url.searchParams.set('forceFunctionRegion', region)\n      }\n      let body: any\n      if (\n        functionArgs &&\n        ((headers && !Object.prototype.hasOwnProperty.call(headers, 'Content-Type')) || !headers)\n      ) {\n        if (\n          (typeof Blob !== 'undefined' && functionArgs instanceof Blob) ||\n          functionArgs instanceof ArrayBuffer\n        ) {\n          // will work for File as File inherits Blob\n          // also works for ArrayBuffer as it is the same underlying structure as a Blob\n          _headers['Content-Type'] = 'application/octet-stream'\n          body = functionArgs\n        } else if (typeof functionArgs === 'string') {\n          // plain string\n          _headers['Content-Type'] = 'text/plain'\n          body = functionArgs\n        } else if (typeof FormData !== 'undefined' && functionArgs instanceof FormData) {\n          // don't set content-type headers\n          // Request will automatically add the right boundary value\n          body = functionArgs\n        } else {\n          // default, assume this is JSON\n          _headers['Content-Type'] = 'application/json'\n          body = JSON.stringify(functionArgs)\n        }\n      } else {\n        if (\n          functionArgs &&\n          typeof functionArgs !== 'string' &&\n          !(typeof Blob !== 'undefined' && functionArgs instanceof Blob) &&\n          !(functionArgs instanceof ArrayBuffer) &&\n          !(typeof FormData !== 'undefined' && functionArgs instanceof FormData)\n        ) {\n          body = JSON.stringify(functionArgs)\n        } else {\n          body = functionArgs\n        }\n      }\n\n      // Handle timeout by creating an AbortController\n      let effectiveSignal = signal\n      if (timeout) {\n        timeoutController = new AbortController()\n        timeoutId = setTimeout(() => timeoutController!.abort(), timeout)\n\n        // If user provided their own signal, we need to respect both\n        if (signal) {\n          effectiveSignal = timeoutController.signal\n          // If the user's signal is aborted, abort our timeout controller too\n          signal.addEventListener('abort', () => timeoutController!.abort())\n        } else {\n          effectiveSignal = timeoutController.signal\n        }\n      }\n\n      const response = await this.fetch(url.toString(), {\n        method: method || 'POST',\n        // headers priority is (high to low):\n        // 1. invoke-level headers\n        // 2. client-level headers\n        // 3. default Content-Type header\n        headers: { ..._headers, ...this.headers, ...headers },\n        body,\n        signal: effectiveSignal,\n      }).catch((fetchError) => {\n        throw new FunctionsFetchError(fetchError)\n      })\n\n      const isRelayError = response.headers.get('x-relay-error')\n      if (isRelayError && isRelayError === 'true') {\n        throw new FunctionsRelayError(response)\n      }\n\n      if (!response.ok) {\n        throw new FunctionsHttpError(response)\n      }\n\n      let responseType = (response.headers.get('Content-Type') ?? 'text/plain').split(';')[0].trim()\n      let data: any\n      if (responseType === 'application/json') {\n        data = await response.json()\n      } else if (\n        responseType === 'application/octet-stream' ||\n        responseType === 'application/pdf'\n      ) {\n        data = await response.blob()\n      } else if (responseType === 'text/event-stream') {\n        data = response\n      } else if (responseType === 'multipart/form-data') {\n        data = await response.formData()\n      } else {\n        // default to text\n        data = await response.text()\n      }\n\n      return { data, error: null, response }\n    } catch (error) {\n      return {\n        data: null,\n        error,\n        response:\n          error instanceof FunctionsHttpError || error instanceof FunctionsRelayError\n            ? error.context\n            : undefined,\n      }\n    } finally {\n      // Clear the timeout if it was set\n      if (timeoutId) {\n        clearTimeout(timeoutId)\n      }\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,OAAO,EAAE,YAAY,EAAE,MAAM,UAAU,CAAA;AACvC,OAAO,EAGL,cAAc,EACd,mBAAmB,EACnB,kBAAkB,EAClB,mBAAmB,GAEpB,MAAM,SAAS,CAAA;;;;AAKV,MAAO,eAAe;IAM1B;;;;;;;;;;;;OAYG,CACH,YACE,GAAW,EACX,EACE,OAAO,GAAG,CAAA,CAAE,EACZ,WAAW,EACX,MAAM,GAAG,4QAAc,CAAC,GAAG,EAAA,GAKzB,CAAA,CAAE,CAAA;QAEN,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;QACtB,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,IAAI,CAAC,KAAK,OAAG,2QAAY,EAAC,WAAW,CAAC,CAAA;IACxC,CAAC;IAED;;;;;;;OAOG,CACH,OAAO,CAAC,KAAa,EAAA;QACnB,IAAI,CAAC,OAAO,CAAC,aAAa,GAAG,CAAA,OAAA,EAAU,KAAK,EAAE,CAAA;IAChD,CAAC;IAED;;;;;;;;;;OAUG,CACG,MAAM,CAAA,cAAA,EAAA;oQACV,YAAoB,EACpB,UAAiC,CAAA,CAAE;;YAEnC,IAAI,SAAoD,CAAA;YACxD,IAAI,iBAA8C,CAAA;YAElD,IAAI,CAAC;gBACH,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,IAAI,EAAE,YAAY,EAAE,MAAM,EAAE,OAAO,EAAE,GAAG,OAAO,CAAA;gBACxE,IAAI,QAAQ,GAA2B,CAAA,CAAE,CAAA;gBACzC,IAAI,EAAE,MAAM,EAAE,GAAG,OAAO,CAAA;gBACxB,IAAI,CAAC,MAAM,EAAE,CAAC;oBACZ,MAAM,GAAG,IAAI,CAAC,MAAM,CAAA;gBACtB,CAAC;gBACD,8CAA8C;gBAC9C,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,YAAY,EAAE,CAAC,CAAA;gBAClD,IAAI,MAAM,IAAI,MAAM,KAAK,KAAK,EAAE,CAAC;oBAC/B,QAAQ,CAAC,UAAU,CAAC,GAAG,MAAM,CAAA;oBAC7B,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,qBAAqB,EAAE,MAAM,CAAC,CAAA;gBACrD,CAAC;gBACD,IAAI,IAAS,CAAA;gBACb,IACE,YAAY,IACZ,CAAC,AAAC,OAAO,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,cAAc,CAAC,CAAC,GAAI,CAAC,OAAO,CAAC,EACzF,CAAC;oBACD,IACE,AAAC,OAAO,IAAI,KAAK,WAAW,IAAI,YAAY,YAAY,IAAI,CAAC,GAC7D,YAAY,YAAY,WAAW,EACnC,CAAC;wBACD,2CAA2C;wBAC3C,8EAA8E;wBAC9E,QAAQ,CAAC,cAAc,CAAC,GAAG,0BAA0B,CAAA;wBACrD,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE,CAAC;wBAC5C,eAAe;wBACf,QAAQ,CAAC,cAAc,CAAC,GAAG,YAAY,CAAA;wBACvC,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,IAAI,YAAY,YAAY,QAAQ,EAAE,CAAC;wBAC/E,iCAAiC;wBACjC,0DAA0D;wBAC1D,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,CAAC;wBACN,+BAA+B;wBAC/B,QAAQ,CAAC,cAAc,CAAC,GAAG,kBAAkB,CAAA;wBAC7C,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;oBACrC,CAAC;gBACH,CAAC,MAAM,CAAC;oBACN,IACE,YAAY,IACZ,OAAO,YAAY,KAAK,QAAQ,IAChC,CAAC,CAAC,OAAO,IAAI,KAAK,WAAW,IAAI,YAAY,YAAY,IAAI,CAAC,IAC9D,CAAC,CAAC,YAAY,YAAY,WAAW,CAAC,IACtC,CAAC,CAAC,OAAO,QAAQ,KAAK,WAAW,IAAI,YAAY,YAAY,QAAQ,CAAC,EACtE,CAAC;wBACD,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;oBACrC,CAAC,MAAM,CAAC;wBACN,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC;gBACH,CAAC;gBAED,gDAAgD;gBAChD,IAAI,eAAe,GAAG,MAAM,CAAA;gBAC5B,IAAI,OAAO,EAAE,CAAC;oBACZ,iBAAiB,GAAG,IAAI,eAAe,EAAE,CAAA;oBACzC,SAAS,GAAG,UAAU,CAAC,GAAG,CAAG,CAAD,gBAAmB,CAAC,KAAK,EAAE,EAAE,OAAO,CAAC,CAAA;oBAEjE,6DAA6D;oBAC7D,IAAI,MAAM,EAAE,CAAC;wBACX,eAAe,GAAG,iBAAiB,CAAC,MAAM,CAAA;wBAC1C,oEAAoE;wBACpE,MAAM,CAAC,gBAAgB,CAAC,OAAO,EAAE,GAAG,CAAG,CAAD,gBAAmB,CAAC,KAAK,EAAE,CAAC,CAAA;oBACpE,CAAC,MAAM,CAAC;wBACN,eAAe,GAAG,iBAAiB,CAAC,MAAM,CAAA;oBAC5C,CAAC;gBACH,CAAC;gBAED,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,QAAQ,EAAE,EAAE;oBAChD,MAAM,EAAE,MAAM,IAAI,MAAM;oBACxB,qCAAqC;oBACrC,0BAA0B;oBAC1B,0BAA0B;oBAC1B,iCAAiC;oBACjC,OAAO,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,QAAQ,GAAK,IAAI,CAAC,OAAO,GAAK,OAAO,CAAE;oBACrD,IAAI;oBACJ,MAAM,EAAE,eAAe;iBACxB,CAAC,CAAC,KAAK,CAAC,CAAC,UAAU,EAAE,EAAE;oBACtB,MAAM,IAAI,iRAAmB,CAAC,UAAU,CAAC,CAAA;gBAC3C,CAAC,CAAC,CAAA;gBAEF,MAAM,YAAY,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,CAAA;gBAC1D,IAAI,YAAY,IAAI,YAAY,KAAK,MAAM,EAAE,CAAC;oBAC5C,MAAM,IAAI,iRAAmB,CAAC,QAAQ,CAAC,CAAA;gBACzC,CAAC;gBAED,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE,CAAC;oBACjB,MAAM,IAAI,gRAAkB,CAAC,QAAQ,CAAC,CAAA;gBACxC,CAAC;gBAED,IAAI,YAAY,GAAG,CAAC,CAAA,KAAA,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,cAAc,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,YAAY,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAA;gBAC9F,IAAI,IAAS,CAAA;gBACb,IAAI,YAAY,KAAK,kBAAkB,EAAE,CAAC;oBACxC,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC,MAAM,IACL,YAAY,KAAK,0BAA0B,IAC3C,YAAY,KAAK,iBAAiB,EAClC,CAAC;oBACD,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC,MAAM,IAAI,YAAY,KAAK,mBAAmB,EAAE,CAAC;oBAChD,IAAI,GAAG,QAAQ,CAAA;gBACjB,CAAC,MAAM,IAAI,YAAY,KAAK,qBAAqB,EAAE,CAAC;oBAClD,IAAI,GAAG,MAAM,QAAQ,CAAC,QAAQ,EAAE,CAAA;gBAClC,CAAC,MAAM,CAAC;oBACN,kBAAkB;oBAClB,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC;gBAED,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;oBAAE,QAAQ;gBAAA,CAAE,CAAA;YACxC,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;gBACf,OAAO;oBACL,IAAI,EAAE,IAAI;oBACV,KAAK;oBACL,QAAQ,EACN,KAAK,YAAY,gRAAkB,IAAI,KAAK,YAAY,iRAAmB,GACvE,KAAK,CAAC,OAAO,GACb,SAAS;iBAChB,CAAA;YACH,CAAC,QAAS,CAAC;gBACT,kCAAkC;gBAClC,IAAI,SAAS,EAAE,CAAC;oBACd,YAAY,CAAC,SAAS,CAAC,CAAA;gBACzB,CAAC;YACH,CAAC;QACH,CAAC;KAAA;CACF"}},
    {"offset": {"line": 250, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/.bun/tslib@2.8.1/node_modules/tslib/tslib.es6.mjs"],"sourcesContent":["/******************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise, SuppressedError, Symbol, Iterator */\n\nvar extendStatics = function(d, b) {\n  extendStatics = Object.setPrototypeOf ||\n      ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n      function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n  return extendStatics(d, b);\n};\n\nexport function __extends(d, b) {\n  if (typeof b !== \"function\" && b !== null)\n      throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n  extendStatics(d, b);\n  function __() { this.constructor = d; }\n  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\n\nexport var __assign = function() {\n  __assign = Object.assign || function __assign(t) {\n      for (var s, i = 1, n = arguments.length; i < n; i++) {\n          s = arguments[i];\n          for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n      }\n      return t;\n  }\n  return __assign.apply(this, arguments);\n}\n\nexport function __rest(s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n      t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n      for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n          if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n              t[p[i]] = s[p[i]];\n      }\n  return t;\n}\n\nexport function __decorate(decorators, target, key, desc) {\n  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n}\n\nexport function __param(paramIndex, decorator) {\n  return function (target, key) { decorator(target, key, paramIndex); }\n}\n\nexport function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\n  function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\n  var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\n  var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\n  var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\n  var _, done = false;\n  for (var i = decorators.length - 1; i >= 0; i--) {\n      var context = {};\n      for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\n      for (var p in contextIn.access) context.access[p] = contextIn.access[p];\n      context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\n      var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\n      if (kind === \"accessor\") {\n          if (result === void 0) continue;\n          if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\n          if (_ = accept(result.get)) descriptor.get = _;\n          if (_ = accept(result.set)) descriptor.set = _;\n          if (_ = accept(result.init)) initializers.unshift(_);\n      }\n      else if (_ = accept(result)) {\n          if (kind === \"field\") initializers.unshift(_);\n          else descriptor[key] = _;\n      }\n  }\n  if (target) Object.defineProperty(target, contextIn.name, descriptor);\n  done = true;\n};\n\nexport function __runInitializers(thisArg, initializers, value) {\n  var useValue = arguments.length > 2;\n  for (var i = 0; i < initializers.length; i++) {\n      value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\n  }\n  return useValue ? value : void 0;\n};\n\nexport function __propKey(x) {\n  return typeof x === \"symbol\" ? x : \"\".concat(x);\n};\n\nexport function __setFunctionName(f, name, prefix) {\n  if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\n  return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\n};\n\nexport function __metadata(metadataKey, metadataValue) {\n  if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n}\n\nexport function __awaiter(thisArg, _arguments, P, generator) {\n  function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n  return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n      function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n      function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n}\n\nexport function __generator(thisArg, body) {\n  var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === \"function\" ? Iterator : Object).prototype);\n  return g.next = verb(0), g[\"throw\"] = verb(1), g[\"return\"] = verb(2), typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n  function verb(n) { return function (v) { return step([n, v]); }; }\n  function step(op) {\n      if (f) throw new TypeError(\"Generator is already executing.\");\n      while (g && (g = 0, op[0] && (_ = 0)), _) try {\n          if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n          if (y = 0, t) op = [op[0] & 2, t.value];\n          switch (op[0]) {\n              case 0: case 1: t = op; break;\n              case 4: _.label++; return { value: op[1], done: false };\n              case 5: _.label++; y = op[1]; op = [0]; continue;\n              case 7: op = _.ops.pop(); _.trys.pop(); continue;\n              default:\n                  if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                  if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                  if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                  if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                  if (t[2]) _.ops.pop();\n                  _.trys.pop(); continue;\n          }\n          op = body.call(thisArg, _);\n      } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n      if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n  }\n}\n\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n  }\n  Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nexport function __exportStar(m, o) {\n  for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\n}\n\nexport function __values(o) {\n  var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n  if (m) return m.call(o);\n  if (o && typeof o.length === \"number\") return {\n      next: function () {\n          if (o && i >= o.length) o = void 0;\n          return { value: o && o[i++], done: !o };\n      }\n  };\n  throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\n\nexport function __read(o, n) {\n  var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n  if (!m) return o;\n  var i = m.call(o), r, ar = [], e;\n  try {\n      while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n  }\n  catch (error) { e = { error: error }; }\n  finally {\n      try {\n          if (r && !r.done && (m = i[\"return\"])) m.call(i);\n      }\n      finally { if (e) throw e.error; }\n  }\n  return ar;\n}\n\n/** @deprecated */\nexport function __spread() {\n  for (var ar = [], i = 0; i < arguments.length; i++)\n      ar = ar.concat(__read(arguments[i]));\n  return ar;\n}\n\n/** @deprecated */\nexport function __spreadArrays() {\n  for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n  for (var r = Array(s), k = 0, i = 0; i < il; i++)\n      for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n          r[k] = a[j];\n  return r;\n}\n\nexport function __spreadArray(to, from, pack) {\n  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n      if (ar || !(i in from)) {\n          if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n          ar[i] = from[i];\n      }\n  }\n  return to.concat(ar || Array.prototype.slice.call(from));\n}\n\nexport function __await(v) {\n  return this instanceof __await ? (this.v = v, this) : new __await(v);\n}\n\nexport function __asyncGenerator(thisArg, _arguments, generator) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var g = generator.apply(thisArg, _arguments || []), i, q = [];\n  return i = Object.create((typeof AsyncIterator === \"function\" ? AsyncIterator : Object).prototype), verb(\"next\"), verb(\"throw\"), verb(\"return\", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;\n  function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }\n  function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }\n  function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n  function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n  function fulfill(value) { resume(\"next\", value); }\n  function reject(value) { resume(\"throw\", value); }\n  function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n}\n\nexport function __asyncDelegator(o) {\n  var i, p;\n  return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n  function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\n}\n\nexport function __asyncValues(o) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var m = o[Symbol.asyncIterator], i;\n  return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n  function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n  function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n}\n\nexport function __makeTemplateObject(cooked, raw) {\n  if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\n  return cooked;\n};\n\nvar __setModuleDefault = Object.create ? (function(o, v) {\n  Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n  o[\"default\"] = v;\n};\n\nvar ownKeys = function(o) {\n  ownKeys = Object.getOwnPropertyNames || function (o) {\n    var ar = [];\n    for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;\n    return ar;\n  };\n  return ownKeys(o);\n};\n\nexport function __importStar(mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== \"default\") __createBinding(result, mod, k[i]);\n  __setModuleDefault(result, mod);\n  return result;\n}\n\nexport function __importDefault(mod) {\n  return (mod && mod.__esModule) ? mod : { default: mod };\n}\n\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\n\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n}\n\nexport function __classPrivateFieldIn(state, receiver) {\n  if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\n  return typeof state === \"function\" ? receiver === state : state.has(receiver);\n}\n\nexport function __addDisposableResource(env, value, async) {\n  if (value !== null && value !== void 0) {\n    if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\n    var dispose, inner;\n    if (async) {\n      if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\n      dispose = value[Symbol.asyncDispose];\n    }\n    if (dispose === void 0) {\n      if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\n      dispose = value[Symbol.dispose];\n      if (async) inner = dispose;\n    }\n    if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\n    if (inner) dispose = function() { try { inner.call(this); } catch (e) { return Promise.reject(e); } };\n    env.stack.push({ value: value, dispose: dispose, async: async });\n  }\n  else if (async) {\n    env.stack.push({ async: true });\n  }\n  return value;\n}\n\nvar _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\n  var e = new Error(message);\n  return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\n};\n\nexport function __disposeResources(env) {\n  function fail(e) {\n    env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\n    env.hasError = true;\n  }\n  var r, s = 0;\n  function next() {\n    while (r = env.stack.pop()) {\n      try {\n        if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);\n        if (r.dispose) {\n          var result = r.dispose.call(r.value);\n          if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\n        }\n        else s |= 1;\n      }\n      catch (e) {\n        fail(e);\n      }\n    }\n    if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();\n    if (env.hasError) throw env.error;\n  }\n  return next();\n}\n\nexport function __rewriteRelativeImportExtension(path, preserveJsx) {\n  if (typeof path === \"string\" && /^\\.\\.?\\//.test(path)) {\n      return path.replace(/\\.(tsx)$|((?:\\.d)?)((?:\\.[^./]+?)?)\\.([cm]?)ts$/i, function (m, tsx, d, ext, cm) {\n          return tsx ? preserveJsx ? \".jsx\" : \".js\" : d && (!ext || !cm) ? m : (d + ext + \".\" + cm.toLowerCase() + \"js\");\n      });\n  }\n  return path;\n}\n\nexport default {\n  __extends,\n  __assign,\n  __rest,\n  __decorate,\n  __param,\n  __esDecorate,\n  __runInitializers,\n  __propKey,\n  __setFunctionName,\n  __metadata,\n  __awaiter,\n  __generator,\n  __createBinding,\n  __exportStar,\n  __values,\n  __read,\n  __spread,\n  __spreadArrays,\n  __spreadArray,\n  __await,\n  __asyncGenerator,\n  __asyncDelegator,\n  __asyncValues,\n  __makeTemplateObject,\n  __importStar,\n  __importDefault,\n  __classPrivateFieldGet,\n  __classPrivateFieldSet,\n  __classPrivateFieldIn,\n  __addDisposableResource,\n  __disposeResources,\n  __rewriteRelativeImportExtension,\n};\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;;;;;;8EAa8E,GAC9E,8DAA8D,GAE9D,IAAI,gBAAgB,SAAS,CAAC,EAAE,CAAC;IAC/B,gBAAgB,OAAO,cAAc,IAChC,CAAA;QAAE,WAAW,EAAE;IAAC,CAAA,aAAa,SAAS,SAAU,CAAC,EAAE,CAAC;QAAI,EAAE,SAAS,GAAG;IAAG,KAC1E,SAAU,CAAC,EAAE,CAAC;QAAI,IAAK,IAAI,KAAK,EAAG,IAAI,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE;IAAE;IACpG,OAAO,cAAc,GAAG;AAC1B;AAEO,SAAS,UAAU,CAAC,EAAE,CAAC;IAC5B,IAAI,OAAO,MAAM,cAAc,MAAM,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,KAAK;IAC7D,cAAc,GAAG;IACjB,SAAS;QAAO,IAAI,CAAC,WAAW,GAAG;IAAG;IACtC,EAAE,SAAS,GAAG,MAAM,OAAO,OAAO,MAAM,CAAC,KAAK,CAAC,GAAG,SAAS,GAAG,EAAE,SAAS,EAAE,IAAI,IAAI;AACrF;AAEO,IAAI,WAAW;IACpB,WAAW,OAAO,MAAM,IAAI,SAAS,SAAS,CAAC;QAC3C,IAAK,IAAI,GAAG,IAAI,GAAG,IAAI,UAAU,MAAM,EAAE,IAAI,GAAG,IAAK;YACjD,IAAI,SAAS,CAAC,EAAE;YAChB,IAAK,IAAI,KAAK,EAAG,IAAI,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE;QAChF;QACA,OAAO;IACX;IACA,OAAO,SAAS,KAAK,CAAC,IAAI,EAAE;AAC9B;AAEO,SAAS,OAAO,CAAC,EAAE,CAAC;IACzB,IAAI,IAAI,CAAC;IACT,IAAK,IAAI,KAAK,EAAG,IAAI,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,GAAG,MAAM,EAAE,OAAO,CAAC,KAAK,GAC9E,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE;IACf,IAAI,KAAK,QAAQ,OAAO,OAAO,qBAAqB,KAAK,YACrD,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,qBAAqB,CAAC,IAAI,IAAI,EAAE,MAAM,EAAE,IAAK;QACpE,IAAI,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,KAAK,OAAO,SAAS,CAAC,oBAAoB,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,GACzE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;IACzB;IACJ,OAAO;AACT;AAEO,SAAS,WAAW,UAAU,EAAE,MAAM,EAAE,GAAG,EAAE,IAAI;IACtD,IAAI,IAAI,UAAU,MAAM,EAAE,IAAI,IAAI,IAAI,SAAS,SAAS,OAAO,OAAO,OAAO,wBAAwB,CAAC,QAAQ,OAAO,MAAM;IAC3H,IAAI,OAAO,YAAY,YAAY,OAAO,QAAQ,QAAQ,KAAK,YAAY,IAAI,QAAQ,QAAQ,CAAC,YAAY,QAAQ,KAAK;SACpH,IAAK,IAAI,IAAI,WAAW,MAAM,GAAG,GAAG,KAAK,GAAG,IAAK,IAAI,IAAI,UAAU,CAAC,EAAE,EAAE,IAAI,CAAC,IAAI,IAAI,EAAE,KAAK,IAAI,IAAI,EAAE,QAAQ,KAAK,KAAK,EAAE,QAAQ,IAAI,KAAK;IAChJ,OAAO,IAAI,KAAK,KAAK,OAAO,cAAc,CAAC,QAAQ,KAAK,IAAI;AAC9D;AAEO,SAAS,QAAQ,UAAU,EAAE,SAAS;IAC3C,OAAO,SAAU,MAAM,EAAE,GAAG;QAAI,UAAU,QAAQ,KAAK;IAAa;AACtE;AAEO,SAAS,aAAa,IAAI,EAAE,YAAY,EAAE,UAAU,EAAE,SAAS,EAAE,YAAY,EAAE,iBAAiB;IACrG,SAAS,OAAO,CAAC;QAAI,IAAI,MAAM,KAAK,KAAK,OAAO,MAAM,YAAY,MAAM,IAAI,UAAU;QAAsB,OAAO;IAAG;IACtH,IAAI,OAAO,UAAU,IAAI,EAAE,MAAM,SAAS,WAAW,QAAQ,SAAS,WAAW,QAAQ;IACzF,IAAI,SAAS,CAAC,gBAAgB,OAAO,SAAS,CAAC,SAAS,GAAG,OAAO,KAAK,SAAS,GAAG;IACnF,IAAI,aAAa,gBAAgB,CAAC,SAAS,OAAO,wBAAwB,CAAC,QAAQ,UAAU,IAAI,IAAI,CAAC,CAAC;IACvG,IAAI,GAAG,OAAO;IACd,IAAK,IAAI,IAAI,WAAW,MAAM,GAAG,GAAG,KAAK,GAAG,IAAK;QAC7C,IAAI,UAAU,CAAC;QACf,IAAK,IAAI,KAAK,UAAW,OAAO,CAAC,EAAE,GAAG,MAAM,WAAW,CAAC,IAAI,SAAS,CAAC,EAAE;QACxE,IAAK,IAAI,KAAK,UAAU,MAAM,CAAE,QAAQ,MAAM,CAAC,EAAE,GAAG,UAAU,MAAM,CAAC,EAAE;QACvE,QAAQ,cAAc,GAAG,SAAU,CAAC;YAAI,IAAI,MAAM,MAAM,IAAI,UAAU;YAA2D,kBAAkB,IAAI,CAAC,OAAO,KAAK;QAAQ;QAC5K,IAAI,SAAS,CAAC,GAAG,UAAU,CAAC,EAAE,EAAE,SAAS,aAAa;YAAE,KAAK,WAAW,GAAG;YAAE,KAAK,WAAW,GAAG;QAAC,IAAI,UAAU,CAAC,IAAI,EAAE;QACtH,IAAI,SAAS,YAAY;YACrB,IAAI,WAAW,KAAK,GAAG;YACvB,IAAI,WAAW,QAAQ,OAAO,WAAW,UAAU,MAAM,IAAI,UAAU;YACvE,IAAI,IAAI,OAAO,OAAO,GAAG,GAAG,WAAW,GAAG,GAAG;YAC7C,IAAI,IAAI,OAAO,OAAO,GAAG,GAAG,WAAW,GAAG,GAAG;YAC7C,IAAI,IAAI,OAAO,OAAO,IAAI,GAAG,aAAa,OAAO,CAAC;QACtD,OACK,IAAI,IAAI,OAAO,SAAS;YACzB,IAAI,SAAS,SAAS,aAAa,OAAO,CAAC;iBACtC,UAAU,CAAC,IAAI,GAAG;QAC3B;IACJ;IACA,IAAI,QAAQ,OAAO,cAAc,CAAC,QAAQ,UAAU,IAAI,EAAE;IAC1D,OAAO;AACT;;AAEO,SAAS,kBAAkB,OAAO,EAAE,YAAY,EAAE,KAAK;IAC5D,IAAI,WAAW,UAAU,MAAM,GAAG;IAClC,IAAK,IAAI,IAAI,GAAG,IAAI,aAAa,MAAM,EAAE,IAAK;QAC1C,QAAQ,WAAW,YAAY,CAAC,EAAE,CAAC,IAAI,CAAC,SAAS,SAAS,YAAY,CAAC,EAAE,CAAC,IAAI,CAAC;IACnF;IACA,OAAO,WAAW,QAAQ,KAAK;AACjC;;AAEO,SAAS,UAAU,CAAC;IACzB,OAAO,OAAO,MAAM,WAAW,IAAI,GAAG,MAAM,CAAC;AAC/C;;AAEO,SAAS,kBAAkB,CAAC,EAAE,IAAI,EAAE,MAAM;IAC/C,IAAI,OAAO,SAAS,UAAU,OAAO,KAAK,WAAW,GAAG,IAAI,MAAM,CAAC,KAAK,WAAW,EAAE,OAAO;IAC5F,OAAO,OAAO,cAAc,CAAC,GAAG,QAAQ;QAAE,cAAc;QAAM,OAAO,SAAS,GAAG,MAAM,CAAC,QAAQ,KAAK,QAAQ;IAAK;AACpH;;AAEO,SAAS,WAAW,WAAW,EAAE,aAAa;IACnD,IAAI,OAAO,YAAY,YAAY,OAAO,QAAQ,QAAQ,KAAK,YAAY,OAAO,QAAQ,QAAQ,CAAC,aAAa;AAClH;AAEO,SAAS,UAAU,OAAO,EAAE,UAAU,EAAE,CAAC,EAAE,SAAS;IACzD,SAAS,MAAM,KAAK;QAAI,OAAO,iBAAiB,IAAI,QAAQ,IAAI,EAAE,SAAU,OAAO;YAAI,QAAQ;QAAQ;IAAI;IAC3G,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,OAAO,CAAC,EAAE,SAAU,OAAO,EAAE,MAAM;QACrD,SAAS,UAAU,KAAK;YAAI,IAAI;gBAAE,KAAK,UAAU,IAAI,CAAC;YAAS,EAAE,OAAO,GAAG;gBAAE,OAAO;YAAI;QAAE;QAC1F,SAAS,SAAS,KAAK;YAAI,IAAI;gBAAE,KAAK,SAAS,CAAC,QAAQ,CAAC;YAAS,EAAE,OAAO,GAAG;gBAAE,OAAO;YAAI;QAAE;QAC7F,SAAS,KAAK,MAAM;YAAI,OAAO,IAAI,GAAG,QAAQ,OAAO,KAAK,IAAI,MAAM,OAAO,KAAK,EAAE,IAAI,CAAC,WAAW;QAAW;QAC7G,KAAK,CAAC,YAAY,UAAU,KAAK,CAAC,SAAS,cAAc,EAAE,CAAC,EAAE,IAAI;IACtE;AACF;AAEO,SAAS,YAAY,OAAO,EAAE,IAAI;IACvC,IAAI,IAAI;QAAE,OAAO;QAAG,MAAM;YAAa,IAAI,CAAC,CAAC,EAAE,GAAG,GAAG,MAAM,CAAC,CAAC,EAAE;YAAE,OAAO,CAAC,CAAC,EAAE;QAAE;QAAG,MAAM,EAAE;QAAE,KAAK,EAAE;IAAC,GAAG,GAAG,GAAG,GAAG,IAAI,OAAO,MAAM,CAAC,CAAC,OAAO,aAAa,aAAa,WAAW,MAAM,EAAE,SAAS;IAC/L,OAAO,EAAE,IAAI,GAAG,KAAK,IAAI,CAAC,CAAC,QAAQ,GAAG,KAAK,IAAI,CAAC,CAAC,SAAS,GAAG,KAAK,IAAI,OAAO,WAAW,cAAc,CAAC,CAAC,CAAC,OAAO,QAAQ,CAAC,GAAG;QAAa,OAAO,IAAI;IAAE,CAAC,GAAG;;;IAC1J,SAAS,KAAK,CAAC;QAAI,OAAO,SAAU,CAAC;YAAI,OAAO,KAAK;gBAAC;gBAAG;aAAE;QAAG;IAAG;IACjE,SAAS,KAAK,EAAE;QACZ,IAAI,GAAG,MAAM,IAAI,UAAU;QAC3B,MAAO,KAAK,CAAC,IAAI,GAAG,EAAE,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,EAAG,IAAI;YAC1C,IAAI,IAAI,GAAG,KAAK,CAAC,IAAI,EAAE,CAAC,EAAE,GAAG,IAAI,CAAC,CAAC,SAAS,GAAG,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC,QAAQ,IAAI,CAAC,CAAC,IAAI,CAAC,CAAC,SAAS,KAAK,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,IAAI,KAAK,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,EAAE,IAAI,EAAE,OAAO;YAC3J,IAAI,IAAI,GAAG,GAAG,KAAK;gBAAC,EAAE,CAAC,EAAE,GAAG;gBAAG,EAAE,KAAK;aAAC;YACvC,OAAQ,EAAE,CAAC,EAAE;gBACT,KAAK;gBAAG,KAAK;oBAAG,IAAI;oBAAI;gBACxB,KAAK;oBAAG,EAAE,KAAK;oBAAI,OAAO;wBAAE,OAAO,EAAE,CAAC,EAAE;wBAAE,MAAM;oBAAM;gBACtD,KAAK;oBAAG,EAAE,KAAK;oBAAI,IAAI,EAAE,CAAC,EAAE;oBAAE,KAAK;wBAAC;qBAAE;oBAAE;gBACxC,KAAK;oBAAG,KAAK,EAAE,GAAG,CAAC,GAAG;oBAAI,EAAE,IAAI,CAAC,GAAG;oBAAI;gBACxC;oBACI,IAAI,CAAC,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,MAAM,GAAG,KAAK,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,KAAK,CAAC,EAAE,CAAC,EAAE,KAAK,KAAK,EAAE,CAAC,EAAE,KAAK,CAAC,GAAG;wBAAE,IAAI;wBAAG;oBAAU;oBAC3G,IAAI,EAAE,CAAC,EAAE,KAAK,KAAK,CAAC,CAAC,KAAM,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE,AAAC,GAAG;wBAAE,EAAE,KAAK,GAAG,EAAE,CAAC,EAAE;wBAAE;oBAAO;oBACrF,IAAI,EAAE,CAAC,EAAE,KAAK,KAAK,EAAE,KAAK,GAAG,CAAC,CAAC,EAAE,EAAE;wBAAE,EAAE,KAAK,GAAG,CAAC,CAAC,EAAE;wBAAE,IAAI;wBAAI;oBAAO;oBACpE,IAAI,KAAK,EAAE,KAAK,GAAG,CAAC,CAAC,EAAE,EAAE;wBAAE,EAAE,KAAK,GAAG,CAAC,CAAC,EAAE;wBAAE,EAAE,GAAG,CAAC,IAAI,CAAC;wBAAK;oBAAO;oBAClE,IAAI,CAAC,CAAC,EAAE,EAAE,EAAE,GAAG,CAAC,GAAG;oBACnB,EAAE,IAAI,CAAC,GAAG;oBAAI;YACtB;YACA,KAAK,KAAK,IAAI,CAAC,SAAS;QAC5B,EAAE,OAAO,GAAG;YAAE,KAAK;gBAAC;gBAAG;aAAE;YAAE,IAAI;QAAG,SAAU;YAAE,IAAI,IAAI;QAAG;QACzD,IAAI,EAAE,CAAC,EAAE,GAAG,GAAG,MAAM,EAAE,CAAC,EAAE;QAAE,OAAO;YAAE,OAAO,EAAE,CAAC,EAAE,GAAG,EAAE,CAAC,EAAE,GAAG,KAAK;YAAG,MAAM;QAAK;IACnF;AACF;AAEO,IAAI,kBAAkB,OAAO,MAAM,GAAI,SAAS,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE;IAChE,IAAI,OAAO,WAAW,KAAK;IAC3B,IAAI,OAAO,OAAO,wBAAwB,CAAC,GAAG;IAC9C,IAAI,CAAC,QAAQ,CAAC,SAAS,OAAO,CAAC,EAAE,UAAU,GAAG,KAAK,QAAQ,IAAI,KAAK,YAAY,GAAG;QAC/E,OAAO;YAAE,YAAY;YAAM,KAAK;gBAAa,OAAO,CAAC,CAAC,EAAE;YAAE;QAAE;IAChE;IACA,OAAO,cAAc,CAAC,GAAG,IAAI;AAC/B,IAAM,SAAS,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE;IACxB,IAAI,OAAO,WAAW,KAAK;IAC3B,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,EAAE;AACd;AAEO,SAAS,aAAa,CAAC,EAAE,CAAC;IAC/B,IAAK,IAAI,KAAK,EAAG,IAAI,MAAM,aAAa,CAAC,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,GAAG,IAAI,gBAAgB,GAAG,GAAG;AAC7G;AAEO,SAAS,SAAS,CAAC;IACxB,IAAI,IAAI,OAAO,WAAW,cAAc,OAAO,QAAQ,EAAE,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,IAAI;IAC5E,IAAI,GAAG,OAAO,EAAE,IAAI,CAAC;IACrB,IAAI,KAAK,OAAO,EAAE,MAAM,KAAK,UAAU,OAAO;QAC1C,MAAM;YACF,IAAI,KAAK,KAAK,EAAE,MAAM,EAAE,IAAI,KAAK;YACjC,OAAO;gBAAE,OAAO,KAAK,CAAC,CAAC,IAAI;gBAAE,MAAM,CAAC;YAAE;QAC1C;IACJ;IACA,MAAM,IAAI,UAAU,IAAI,4BAA4B;AACtD;AAEO,SAAS,OAAO,CAAC,EAAE,CAAC;IACzB,IAAI,IAAI,OAAO,WAAW,cAAc,CAAC,CAAC,OAAO,QAAQ,CAAC;IAC1D,IAAI,CAAC,GAAG,OAAO;IACf,IAAI,IAAI,EAAE,IAAI,CAAC,IAAI,GAAG,KAAK,EAAE,EAAE;IAC/B,IAAI;QACA,MAAO,CAAC,MAAM,KAAK,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,IAAI,EAAE,IAAI,EAAE,EAAE,IAAI,CAAE,GAAG,IAAI,CAAC,EAAE,KAAK;IAC7E,EACA,OAAO,OAAO;QAAE,IAAI;YAAE,OAAO;QAAM;IAAG,SAC9B;QACJ,IAAI;YACA,IAAI,KAAK,CAAC,EAAE,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,SAAS,GAAG,EAAE,IAAI,CAAC;QAClD,SACQ;YAAE,IAAI,GAAG,MAAM,EAAE,KAAK;QAAE;IACpC;IACA,OAAO;AACT;AAGO,SAAS;IACd,IAAK,IAAI,KAAK,EAAE,EAAE,IAAI,GAAG,IAAI,UAAU,MAAM,EAAE,IAC3C,KAAK,GAAG,MAAM,CAAC,OAAO,SAAS,CAAC,EAAE;IACtC,OAAO;AACT;AAGO,SAAS;IACd,IAAK,IAAI,IAAI,GAAG,IAAI,GAAG,KAAK,UAAU,MAAM,EAAE,IAAI,IAAI,IAAK,KAAK,SAAS,CAAC,EAAE,CAAC,MAAM;IACnF,IAAK,IAAI,IAAI,MAAM,IAAI,IAAI,GAAG,IAAI,GAAG,IAAI,IAAI,IACzC,IAAK,IAAI,IAAI,SAAS,CAAC,EAAE,EAAE,IAAI,GAAG,KAAK,EAAE,MAAM,EAAE,IAAI,IAAI,KAAK,IAC1D,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE;IACnB,OAAO;AACT;AAEO,SAAS,cAAc,EAAE,EAAE,IAAI,EAAE,IAAI;IAC1C,IAAI,QAAQ,UAAU,MAAM,KAAK,GAAG,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,MAAM,EAAE,IAAI,IAAI,GAAG,IAAK;QACjF,IAAI,MAAM,CAAC,CAAC,KAAK,IAAI,GAAG;YACpB,IAAI,CAAC,IAAI,KAAK,MAAM,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,GAAG;YAClD,EAAE,CAAC,EAAE,GAAG,IAAI,CAAC,EAAE;QACnB;IACJ;IACA,OAAO,GAAG,MAAM,CAAC,MAAM,MAAM,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC;AACpD;AAEO,SAAS,QAAQ,CAAC;IACvB,OAAO,IAAI,YAAY,UAAU,CAAC,IAAI,CAAC,CAAC,GAAG,GAAG,IAAI,IAAI,IAAI,QAAQ;AACpE;AAEO,SAAS,iBAAiB,OAAO,EAAE,UAAU,EAAE,SAAS;IAC7D,IAAI,CAAC,OAAO,aAAa,EAAE,MAAM,IAAI,UAAU;IAC/C,IAAI,IAAI,UAAU,KAAK,CAAC,SAAS,cAAc,EAAE,GAAG,GAAG,IAAI,EAAE;IAC7D,OAAO,IAAI,OAAO,MAAM,CAAC,CAAC,OAAO,kBAAkB,aAAa,gBAAgB,MAAM,EAAE,SAAS,GAAG,KAAK,SAAS,KAAK,UAAU,KAAK,UAAU,cAAc,CAAC,CAAC,OAAO,aAAa,CAAC,GAAG;QAAc,OAAO,IAAI;IAAE,GAAG;;;IACtN,SAAS,YAAY,CAAC;QAAI,OAAO,SAAU,CAAC;YAAI,OAAO,QAAQ,OAAO,CAAC,GAAG,IAAI,CAAC,GAAG;QAAS;IAAG;IAC9F,SAAS,KAAK,CAAC,EAAE,CAAC;QAAI,IAAI,CAAC,CAAC,EAAE,EAAE;YAAE,CAAC,CAAC,EAAE,GAAG,SAAU,CAAC;gBAAI,OAAO,IAAI,QAAQ,SAAU,CAAC,EAAE,CAAC;oBAAI,EAAE,IAAI,CAAC;wBAAC;wBAAG;wBAAG;wBAAG;qBAAE,IAAI,KAAK,OAAO,GAAG;gBAAI;YAAI;YAAG,IAAI,GAAG,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,EAAE;QAAG;IAAE;IACvK,SAAS,OAAO,CAAC,EAAE,CAAC;QAAI,IAAI;YAAE,KAAK,CAAC,CAAC,EAAE,CAAC;QAAK,EAAE,OAAO,GAAG;YAAE,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;QAAI;IAAE;IACjF,SAAS,KAAK,CAAC;QAAI,EAAE,KAAK,YAAY,UAAU,QAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,SAAS,UAAU,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;IAAI;IACvH,SAAS,QAAQ,KAAK;QAAI,OAAO,QAAQ;IAAQ;IACjD,SAAS,OAAO,KAAK;QAAI,OAAO,SAAS;IAAQ;IACjD,SAAS,OAAO,CAAC,EAAE,CAAC;QAAI,IAAI,EAAE,IAAI,EAAE,KAAK,IAAI,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE;IAAG;AACnF;AAEO,SAAS,iBAAiB,CAAC;IAChC,IAAI,GAAG;IACP,OAAO,IAAI,CAAC,GAAG,KAAK,SAAS,KAAK,SAAS,SAAU,CAAC;QAAI,MAAM;IAAG,IAAI,KAAK,WAAW,CAAC,CAAC,OAAO,QAAQ,CAAC,GAAG;QAAc,OAAO,IAAI;IAAE,GAAG;;;IAC1I,SAAS,KAAK,CAAC,EAAE,CAAC;QAAI,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAAU,CAAC;YAAI,OAAO,CAAC,IAAI,CAAC,CAAC,IAAI;gBAAE,OAAO,QAAQ,CAAC,CAAC,EAAE,CAAC;gBAAK,MAAM;YAAM,IAAI,IAAI,EAAE,KAAK;QAAG,IAAI;IAAG;AACvI;AAEO,SAAS,cAAc,CAAC;IAC7B,IAAI,CAAC,OAAO,aAAa,EAAE,MAAM,IAAI,UAAU;IAC/C,IAAI,IAAI,CAAC,CAAC,OAAO,aAAa,CAAC,EAAE;IACjC,OAAO,IAAI,EAAE,IAAI,CAAC,KAAK,CAAC,IAAI,OAAO,aAAa,aAAa,SAAS,KAAK,CAAC,CAAC,OAAO,QAAQ,CAAC,IAAI,IAAI,CAAC,GAAG,KAAK,SAAS,KAAK,UAAU,KAAK,WAAW,CAAC,CAAC,OAAO,aAAa,CAAC,GAAG;QAAc,OAAO,IAAI;IAAE,GAAG,CAAC;;;IAC/M,SAAS,KAAK,CAAC;QAAI,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,SAAU,CAAC;YAAI,OAAO,IAAI,QAAQ,SAAU,OAAO,EAAE,MAAM;gBAAI,IAAI,CAAC,CAAC,EAAE,CAAC,IAAI,OAAO,SAAS,QAAQ,EAAE,IAAI,EAAE,EAAE,KAAK;YAAG;QAAI;IAAG;IAC/J,SAAS,OAAO,OAAO,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC;QAAI,QAAQ,OAAO,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC;YAAI,QAAQ;gBAAE,OAAO;gBAAG,MAAM;YAAE;QAAI,GAAG;IAAS;AAC7H;AAEO,SAAS,qBAAqB,MAAM,EAAE,GAAG;IAC9C,IAAI,OAAO,cAAc,EAAE;QAAE,OAAO,cAAc,CAAC,QAAQ,OAAO;YAAE,OAAO;QAAI;IAAI,OAAO;QAAE,OAAO,GAAG,GAAG;IAAK;IAC9G,OAAO;AACT;;AAEA,IAAI,qBAAqB,OAAO,MAAM,GAAI,SAAS,CAAC,EAAE,CAAC;IACrD,OAAO,cAAc,CAAC,GAAG,WAAW;QAAE,YAAY;QAAM,OAAO;IAAE;AACnE,IAAK,SAAS,CAAC,EAAE,CAAC;IAChB,CAAC,CAAC,UAAU,GAAG;AACjB;AAEA,IAAI,UAAU,SAAS,CAAC;IACtB,UAAU,OAAO,mBAAmB,IAAI,SAAU,CAAC;QACjD,IAAI,KAAK,EAAE;QACX,IAAK,IAAI,KAAK,EAAG,IAAI,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,MAAM,CAAC,GAAG;QACjF,OAAO;IACT;IACA,OAAO,QAAQ;AACjB;AAEO,SAAS,aAAa,GAAG;IAC9B,IAAI,OAAO,IAAI,UAAU,EAAE,OAAO;IAClC,IAAI,SAAS,CAAC;IACd,IAAI,OAAO,MAAM;QAAA,IAAK,IAAI,IAAI,QAAQ,MAAM,IAAI,GAAG,IAAI,EAAE,MAAM,EAAE,IAAK,IAAI,CAAC,CAAC,EAAE,KAAK,WAAW,gBAAgB,QAAQ,KAAK,CAAC,CAAC,EAAE;IAAC;IAChI,mBAAmB,QAAQ;IAC3B,OAAO;AACT;AAEO,SAAS,gBAAgB,GAAG;IACjC,OAAO,AAAC,OAAO,IAAI,UAAU,GAAI,MAAM;QAAE,SAAS;IAAI;AACxD;AAEO,SAAS,uBAAuB,QAAQ,EAAE,KAAK,EAAE,IAAI,EAAE,CAAC;IAC7D,IAAI,SAAS,OAAO,CAAC,GAAG,MAAM,IAAI,UAAU;IAC5C,IAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,WAAW,MAAM,IAAI,UAAU;IACvG,OAAO,SAAS,MAAM,IAAI,SAAS,MAAM,EAAE,IAAI,CAAC,YAAY,IAAI,EAAE,KAAK,GAAG,MAAM,GAAG,CAAC;AACtF;AAEO,SAAS,uBAAuB,QAAQ,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,CAAC;IACpE,IAAI,SAAS,KAAK,MAAM,IAAI,UAAU;IACtC,IAAI,SAAS,OAAO,CAAC,GAAG,MAAM,IAAI,UAAU;IAC5C,IAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,WAAW,MAAM,IAAI,UAAU;IACvG,OAAO,AAAC,SAAS,MAAM,EAAE,IAAI,CAAC,UAAU,SAAS,IAAI,EAAE,KAAK,GAAG,QAAQ,MAAM,GAAG,CAAC,UAAU,QAAS;AACtG;AAEO,SAAS,sBAAsB,KAAK,EAAE,QAAQ;IACnD,IAAI,aAAa,QAAS,OAAO,aAAa,YAAY,OAAO,aAAa,YAAa,MAAM,IAAI,UAAU;IAC/G,OAAO,OAAO,UAAU,aAAa,aAAa,QAAQ,MAAM,GAAG,CAAC;AACtE;AAEO,SAAS,wBAAwB,GAAG,EAAE,KAAK,EAAE,KAAK;IACvD,IAAI,UAAU,QAAQ,UAAU,KAAK,GAAG;QACtC,IAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,MAAM,IAAI,UAAU;QAClF,IAAI,SAAS;QACb,IAAI,OAAO;YACT,IAAI,CAAC,OAAO,YAAY,EAAE,MAAM,IAAI,UAAU;YAC9C,UAAU,KAAK,CAAC,OAAO,YAAY,CAAC;QACtC;QACA,IAAI,YAAY,KAAK,GAAG;YACtB,IAAI,CAAC,OAAO,OAAO,EAAE,MAAM,IAAI,UAAU;YACzC,UAAU,KAAK,CAAC,OAAO,OAAO,CAAC;YAC/B,IAAI,OAAO,QAAQ;QACrB;QACA,IAAI,OAAO,YAAY,YAAY,MAAM,IAAI,UAAU;QACvD,IAAI,OAAO,UAAU;YAAa,IAAI;gBAAE,MAAM,IAAI,CAAC,IAAI;YAAG,EAAE,OAAO,GAAG;gBAAE,OAAO,QAAQ,MAAM,CAAC;YAAI;QAAE;QACpG,IAAI,KAAK,CAAC,IAAI,CAAC;YAAE,OAAO;YAAO,SAAS;YAAS,OAAO;QAAM;IAChE,OACK,IAAI,OAAO;QACd,IAAI,KAAK,CAAC,IAAI,CAAC;YAAE,OAAO;QAAK;IAC/B;IACA,OAAO;AACT;AAEA,IAAI,mBAAmB,OAAO,oBAAoB,aAAa,kBAAkB,SAAU,KAAK,EAAE,UAAU,EAAE,OAAO;IACnH,IAAI,IAAI,IAAI,MAAM;IAClB,OAAO,EAAE,IAAI,GAAG,mBAAmB,EAAE,KAAK,GAAG,OAAO,EAAE,UAAU,GAAG,YAAY;AACjF;AAEO,SAAS,mBAAmB,GAAG;IACpC,SAAS,KAAK,CAAC;QACb,IAAI,KAAK,GAAG,IAAI,QAAQ,GAAG,IAAI,iBAAiB,GAAG,IAAI,KAAK,EAAE,8CAA8C;QAC5G,IAAI,QAAQ,GAAG;IACjB;IACA,IAAI,GAAG,IAAI;IACX,SAAS;QACP,MAAO,IAAI,IAAI,KAAK,CAAC,GAAG,GAAI;YAC1B,IAAI;gBACF,IAAI,CAAC,EAAE,KAAK,IAAI,MAAM,GAAG,OAAO,IAAI,GAAG,IAAI,KAAK,CAAC,IAAI,CAAC,IAAI,QAAQ,OAAO,GAAG,IAAI,CAAC;gBACjF,IAAI,EAAE,OAAO,EAAE;oBACb,IAAI,SAAS,EAAE,OAAO,CAAC,IAAI,CAAC,EAAE,KAAK;oBACnC,IAAI,EAAE,KAAK,EAAE,OAAO,KAAK,GAAG,QAAQ,OAAO,CAAC,QAAQ,IAAI,CAAC,MAAM,SAAS,CAAC;wBAAI,KAAK;wBAAI,OAAO;oBAAQ;gBACvG,OACK,KAAK;YACZ,EACA,OAAO,GAAG;gBACR,KAAK;YACP;QACF;QACA,IAAI,MAAM,GAAG,OAAO,IAAI,QAAQ,GAAG,QAAQ,MAAM,CAAC,IAAI,KAAK,IAAI,QAAQ,OAAO;QAC9E,IAAI,IAAI,QAAQ,EAAE,MAAM,IAAI,KAAK;IACnC;IACA,OAAO;AACT;AAEO,SAAS,iCAAiC,IAAI,EAAE,WAAW;IAChE,IAAI,OAAO,SAAS,YAAY,WAAW,IAAI,CAAC,OAAO;QACnD,OAAO,KAAK,OAAO,CAAC,oDAAoD,SAAU,CAAC,EAAE,GAAG,EAAE,CAAC,EAAE,GAAG,EAAE,EAAE;YAChG,OAAO,MAAM,cAAc,SAAS,QAAQ,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,IAAI,IAAK,IAAI,MAAM,MAAM,GAAG,WAAW,KAAK;QAC7G;IACJ;IACA,OAAO;AACT;uCAEe;IACb;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;AACF","ignoreList":[0]}},
    {"offset": {"line": 885, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/dist/index.mjs","sources":["turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestError.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestTransformBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestFilterBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestQueryBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/PostgrestClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+postgrest-js@2.95.3/node_modules/@supabase/postgrest-js/src/index.ts"],"sourcesContent":["/**\n * Error format\n *\n * {@link https://postgrest.org/en/stable/api.html?highlight=options#errors-and-http-status-codes}\n */\nexport default class PostgrestError extends Error {\n  details: string\n  hint: string\n  code: string\n\n  /**\n   * @example\n   * ```ts\n   * import PostgrestError from '@supabase/postgrest-js'\n   *\n   * throw new PostgrestError({\n   *   message: 'Row level security prevented the request',\n   *   details: 'RLS denied the insert',\n   *   hint: 'Check your policies',\n   *   code: 'PGRST301',\n   * })\n   * ```\n   */\n  constructor(context: { message: string; details: string; hint: string; code: string }) {\n    super(context.message)\n    this.name = 'PostgrestError'\n    this.details = context.details\n    this.hint = context.hint\n    this.code = context.code\n  }\n}\n","import type {\n  PostgrestSingleResponse,\n  PostgrestResponseSuccess,\n  CheckMatchingArrayTypes,\n  MergePartialResult,\n  IsValidResultOverride,\n} from './types/types'\nimport { ClientServerOptions, Fetch } from './types/common/common'\nimport PostgrestError from './PostgrestError'\nimport { ContainsNull } from './select-query-parser/types'\n\nexport default abstract class PostgrestBuilder<\n  ClientOptions extends ClientServerOptions,\n  Result,\n  ThrowOnError extends boolean = false,\n> implements\n    PromiseLike<\n      ThrowOnError extends true ? PostgrestResponseSuccess<Result> : PostgrestSingleResponse<Result>\n    >\n{\n  protected method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n  protected url: URL\n  protected headers: Headers\n  protected schema?: string\n  protected body?: unknown\n  protected shouldThrowOnError = false\n  protected signal?: AbortSignal\n  protected fetch: Fetch\n  protected isMaybeSingle: boolean\n  protected urlLengthLimit: number\n\n  /**\n   * Creates a builder configured for a specific PostgREST request.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const builder = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: new Headers({ apikey: 'public-anon-key' }) }\n   * )\n   * ```\n   */\n  constructor(builder: {\n    method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n    url: URL\n    headers: HeadersInit\n    schema?: string\n    body?: unknown\n    shouldThrowOnError?: boolean\n    signal?: AbortSignal\n    fetch?: Fetch\n    isMaybeSingle?: boolean\n    urlLengthLimit?: number\n  }) {\n    this.method = builder.method\n    this.url = builder.url\n    this.headers = new Headers(builder.headers)\n    this.schema = builder.schema\n    this.body = builder.body\n    this.shouldThrowOnError = builder.shouldThrowOnError ?? false\n    this.signal = builder.signal\n    this.isMaybeSingle = builder.isMaybeSingle ?? false\n    this.urlLengthLimit = builder.urlLengthLimit ?? 8000\n\n    if (builder.fetch) {\n      this.fetch = builder.fetch\n    } else {\n      this.fetch = fetch\n    }\n  }\n\n  /**\n   * If there's an error with the query, throwOnError will reject the promise by\n   * throwing the error instead of returning it as part of a successful response.\n   *\n   * {@link https://github.com/supabase/supabase-js/issues/92}\n   */\n  throwOnError(): this & PostgrestBuilder<ClientOptions, Result, true> {\n    this.shouldThrowOnError = true\n    return this as this & PostgrestBuilder<ClientOptions, Result, true>\n  }\n\n  /**\n   * Set an HTTP header for the request.\n   */\n  setHeader(name: string, value: string): this {\n    this.headers = new Headers(this.headers)\n    this.headers.set(name, value)\n    return this\n  }\n\n  then<\n    TResult1 = ThrowOnError extends true\n      ? PostgrestResponseSuccess<Result>\n      : PostgrestSingleResponse<Result>,\n    TResult2 = never,\n  >(\n    onfulfilled?:\n      | ((\n          value: ThrowOnError extends true\n            ? PostgrestResponseSuccess<Result>\n            : PostgrestSingleResponse<Result>\n        ) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): PromiseLike<TResult1 | TResult2> {\n    // https://postgrest.org/en/stable/api.html#switching-schemas\n    if (this.schema === undefined) {\n      // skip\n    } else if (['GET', 'HEAD'].includes(this.method)) {\n      this.headers.set('Accept-Profile', this.schema)\n    } else {\n      this.headers.set('Content-Profile', this.schema)\n    }\n    if (this.method !== 'GET' && this.method !== 'HEAD') {\n      this.headers.set('Content-Type', 'application/json')\n    }\n\n    // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n    // https://github.com/supabase/postgrest-js/pull/247\n    const _fetch = this.fetch\n    let res = _fetch(this.url.toString(), {\n      method: this.method,\n      headers: this.headers,\n      body: JSON.stringify(this.body),\n      signal: this.signal,\n    }).then(async (res) => {\n      let error = null\n      let data = null\n      let count: number | null = null\n      let status = res.status\n      let statusText = res.statusText\n\n      if (res.ok) {\n        if (this.method !== 'HEAD') {\n          const body = await res.text()\n          if (body === '') {\n            // Prefer: return=minimal\n          } else if (this.headers.get('Accept') === 'text/csv') {\n            data = body\n          } else if (\n            this.headers.get('Accept') &&\n            this.headers.get('Accept')?.includes('application/vnd.pgrst.plan+text')\n          ) {\n            data = body\n          } else {\n            data = JSON.parse(body)\n          }\n        }\n\n        const countHeader = this.headers.get('Prefer')?.match(/count=(exact|planned|estimated)/)\n        const contentRange = res.headers.get('content-range')?.split('/')\n        if (countHeader && contentRange && contentRange.length > 1) {\n          count = parseInt(contentRange[1])\n        }\n\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n          if (data.length > 1) {\n            error = {\n              // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n              code: 'PGRST116',\n              details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n              hint: null,\n              message: 'JSON object requested, multiple (or no) rows returned',\n            }\n            data = null\n            count = null\n            status = 406\n            statusText = 'Not Acceptable'\n          } else if (data.length === 1) {\n            data = data[0]\n          } else {\n            data = null\n          }\n        }\n      } else {\n        const body = await res.text()\n\n        try {\n          error = JSON.parse(body)\n\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (Array.isArray(error) && res.status === 404) {\n            data = []\n            error = null\n            status = 200\n            statusText = 'OK'\n          }\n        } catch {\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (res.status === 404 && body === '') {\n            status = 204\n            statusText = 'No Content'\n          } else {\n            error = {\n              message: body,\n            }\n          }\n        }\n\n        if (error && this.isMaybeSingle && error?.details?.includes('0 rows')) {\n          error = null\n          status = 200\n          statusText = 'OK'\n        }\n\n        if (error && this.shouldThrowOnError) {\n          throw new PostgrestError(error)\n        }\n      }\n\n      const postgrestResponse = {\n        error,\n        data,\n        count,\n        status,\n        statusText,\n      }\n\n      return postgrestResponse\n    })\n    if (!this.shouldThrowOnError) {\n      res = res.catch((fetchError) => {\n        // Build detailed error information including cause if available\n        // Note: We don't populate code/hint for client-side network errors since those\n        // fields are meant for upstream service errors (PostgREST/PostgreSQL)\n        let errorDetails = ''\n        let hint = ''\n        let code = ''\n\n        // Add cause information if available (e.g., DNS errors, network failures)\n        const cause = fetchError?.cause\n        if (cause) {\n          const causeMessage = cause?.message ?? ''\n          const causeCode = cause?.code ?? ''\n\n          errorDetails = `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`\n          errorDetails += `\\n\\nCaused by: ${cause?.name ?? 'Error'}: ${causeMessage}`\n          if (causeCode) {\n            errorDetails += ` (${causeCode})`\n          }\n          if (cause?.stack) {\n            errorDetails += `\\n${cause.stack}`\n          }\n        } else {\n          // No cause available, just include the error stack\n          errorDetails = fetchError?.stack ?? ''\n        }\n\n        // Get URL length for potential hints\n        const urlLength = this.url.toString().length\n\n        // Handle AbortError specially with helpful hints\n        if (fetchError?.name === 'AbortError' || fetchError?.code === 'ABORT_ERR') {\n          code = ''\n          hint = 'Request was aborted (timeout or manual cancellation)'\n\n          if (urlLength > this.urlLengthLimit) {\n            hint += `. Note: Your request URL is ${urlLength} characters, which may exceed server limits. If selecting many fields, consider using views. If filtering with large arrays (e.g., .in('id', [many IDs])), consider using an RPC function to pass values server-side.`\n          }\n        }\n        // Handle HeadersOverflowError from undici (Node.js fetch implementation)\n        else if (\n          cause?.name === 'HeadersOverflowError' ||\n          cause?.code === 'UND_ERR_HEADERS_OVERFLOW'\n        ) {\n          code = ''\n          hint = 'HTTP headers exceeded server limits (typically 16KB)'\n\n          if (urlLength > this.urlLengthLimit) {\n            hint += `. Your request URL is ${urlLength} characters. If selecting many fields, consider using views. If filtering with large arrays (e.g., .in('id', [200+ IDs])), consider using an RPC function instead.`\n          }\n        }\n\n        return {\n          error: {\n            message: `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`,\n            details: errorDetails,\n            hint: hint,\n            code: code,\n          },\n          data: null,\n          count: null,\n          status: 0,\n          statusText: '',\n        }\n      })\n    }\n\n    return res.then(onfulfilled, onrejected)\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestBuilder<\n    ClientOptions,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    /* istanbul ignore next */\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n\n  /**\n   * Override the type of the returned `data` field in the response.\n   *\n   * @typeParam NewResult - The new type to cast the response data to\n   * @typeParam Options - Optional type configuration (defaults to { merge: true })\n   * @typeParam Options.merge - When true, merges the new type with existing return type. When false, replaces the existing types entirely (defaults to true)\n   * @example\n   * ```typescript\n   * // Merge with existing types (default behavior)\n   * const query = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ custom_field: string }>()\n   *\n   * // Replace existing types completely\n   * const replaceQuery = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ id: number; name: string }, { merge: false }>()\n   * ```\n   * @returns A PostgrestBuilder instance with the new type\n   */\n  overrideTypes<\n    NewResult,\n    Options extends { merge?: boolean } = { merge: true },\n  >(): PostgrestBuilder<\n    ClientOptions,\n    IsValidResultOverride<Result, NewResult, false, false> extends true\n      ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n        ContainsNull<Result> extends true\n        ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n        : MergePartialResult<NewResult, Result, Options>\n      : CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      IsValidResultOverride<Result, NewResult, false, false> extends true\n        ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n          ContainsNull<Result> extends true\n          ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n          : MergePartialResult<NewResult, Result, Options>\n        : CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n}\n","import PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestFilterBuilder, { InvalidMethodError } from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport { CheckMatchingArrayTypes } from './types/types'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\nimport type { MaxAffectedEnabled } from './types/feature-flags'\n\nexport default class PostgrestTransformBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestBuilder<ClientOptions, Result> {\n  /**\n   * Perform a SELECT on the query result.\n   *\n   * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n   * return modified rows. By calling this method, modified rows are returned in\n   * `data`.\n   *\n   * @param columns - The columns to retrieve, separated by commas\n   */\n  select<\n    Query extends string = '*',\n    NewResultOne = GetResult<Schema, Row, RelationName, Relationships, Query, ClientOptions>,\n  >(\n    columns?: Query\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    Method extends 'RPC'\n      ? Result extends unknown[]\n        ? NewResultOne[]\n        : NewResultOne\n      : NewResultOne[],\n    RelationName,\n    Relationships,\n    Method\n  > {\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n    this.headers.append('Prefer', 'return=representation')\n    return this as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      Method extends 'RPC'\n        ? Result extends unknown[]\n          ? NewResultOne[]\n          : NewResultOne\n        : NewResultOne[],\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: undefined }\n  ): this\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: string }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: undefined }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: string }\n  ): this\n  /**\n   * Order the query result by `column`.\n   *\n   * You can call this method multiple times to order by multiple columns.\n   *\n   * You can order referenced tables, but it only affects the ordering of the\n   * parent table if you use `!inner` in the query.\n   *\n   * @param column - The column to order by\n   * @param options - Named parameters\n   * @param options.ascending - If `true`, the result will be in ascending order\n   * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n   * `null`s appear last.\n   * @param options.referencedTable - Set this to order a referenced table by\n   * its columns\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  order(\n    column: string,\n    {\n      ascending = true,\n      nullsFirst,\n      foreignTable,\n      referencedTable = foreignTable,\n    }: {\n      ascending?: boolean\n      nullsFirst?: boolean\n      foreignTable?: string\n      referencedTable?: string\n    } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.order` : 'order'\n    const existingOrder = this.url.searchParams.get(key)\n\n    this.url.searchParams.set(\n      key,\n      `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${\n        nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'\n      }`\n    )\n    return this\n  }\n\n  /**\n   * Limit the query result by `count`.\n   *\n   * @param count - The maximum number of rows to return\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  limit(\n    count: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(key, `${count}`)\n    return this\n  }\n\n  /**\n   * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n   * Only records within this range are returned.\n   * This respects the query order and if there is no order clause the range could behave unexpectedly.\n   * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n   * and fourth rows of the query.\n   *\n   * @param from - The starting index from which to limit the result\n   * @param to - The last index to which to limit the result\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  range(\n    from: number,\n    to: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const keyOffset =\n      typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`\n    const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(keyOffset, `${from}`)\n    // Range is inclusive, so add 1\n    this.url.searchParams.set(keyLimit, `${to - from + 1}`)\n    return this\n  }\n\n  /**\n   * Set the AbortSignal for the fetch request.\n   *\n   * @param signal - The AbortSignal to use for the fetch request\n   */\n  abortSignal(signal: AbortSignal): this {\n    this.signal = signal\n    return this\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n   * returns an error.\n   */\n  single<ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never>(): PostgrestBuilder<\n    ClientOptions,\n    ResultOne\n  > {\n    this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne>\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n   * this returns an error.\n   */\n  maybeSingle<\n    ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never,\n  >(): PostgrestBuilder<ClientOptions, ResultOne | null> {\n    // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n    // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n    if (this.method === 'GET') {\n      this.headers.set('Accept', 'application/json')\n    } else {\n      this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    }\n    this.isMaybeSingle = true\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne | null>\n  }\n\n  /**\n   * Return `data` as a string in CSV format.\n   */\n  csv(): PostgrestBuilder<ClientOptions, string> {\n    this.headers.set('Accept', 'text/csv')\n    return this as unknown as PostgrestBuilder<ClientOptions, string>\n  }\n\n  /**\n   * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n   */\n  geojson(): PostgrestBuilder<ClientOptions, Record<string, unknown>> {\n    this.headers.set('Accept', 'application/geo+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>>\n  }\n\n  /**\n   * Return `data` as the EXPLAIN plan for the query.\n   *\n   * You need to enable the\n   * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n   * setting before using this method.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.analyze - If `true`, the query will be executed and the\n   * actual run time will be returned\n   *\n   * @param options.verbose - If `true`, the query identifier will be returned\n   * and `data` will include the output columns of the query\n   *\n   * @param options.settings - If `true`, include information on configuration\n   * parameters that affect query planning\n   *\n   * @param options.buffers - If `true`, include information on buffer usage\n   *\n   * @param options.wal - If `true`, include information on WAL record generation\n   *\n   * @param options.format - The format of the output, can be `\"text\"` (default)\n   * or `\"json\"`\n   */\n  explain({\n    analyze = false,\n    verbose = false,\n    settings = false,\n    buffers = false,\n    wal = false,\n    format = 'text',\n  }: {\n    analyze?: boolean\n    verbose?: boolean\n    settings?: boolean\n    buffers?: boolean\n    wal?: boolean\n    format?: 'json' | 'text'\n  } = {}) {\n    const options = [\n      analyze ? 'analyze' : null,\n      verbose ? 'verbose' : null,\n      settings ? 'settings' : null,\n      buffers ? 'buffers' : null,\n      wal ? 'wal' : null,\n    ]\n      .filter(Boolean)\n      .join('|')\n    // An Accept header can carry multiple media types but postgrest-js always sends one\n    const forMediatype = this.headers.get('Accept') ?? 'application/json'\n    this.headers.set(\n      'Accept',\n      `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`\n    )\n    if (format === 'json') {\n      return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>[]>\n    } else {\n      return this as unknown as PostgrestBuilder<ClientOptions, string>\n    }\n  }\n\n  /**\n   * Rollback the query.\n   *\n   * `data` will still be returned, but the query is not committed.\n   */\n  rollback(): this {\n    this.headers.append('Prefer', 'tx=rollback')\n    return this\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    RelationName,\n    Relationships,\n    Method\n  > {\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  /**\n   * Set the maximum number of rows that can be affected by the query.\n   * Only available in PostgREST v13+ and only works with PATCH and DELETE methods.\n   *\n   * @param value - The maximum number of rows that can be affected\n   */\n  maxAffected(value: number): MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n    ? // TODO: update the RPC case to only work on RPC that returns SETOF rows\n      Method extends 'PATCH' | 'DELETE' | 'RPC'\n      ? this\n      : InvalidMethodError<'maxAffected method only available on update or delete'>\n    : InvalidMethodError<'maxAffected method only available on postgrest 13+'> {\n    this.headers.append('Prefer', 'handling=strict')\n    this.headers.append('Prefer', `max-affected=${value}`)\n    return this as unknown as MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n      ? Method extends 'PATCH' | 'DELETE' | 'RPC'\n        ? this\n        : InvalidMethodError<'maxAffected method only available on update or delete'>\n      : InvalidMethodError<'maxAffected method only available on postgrest 13+'>\n  }\n}\n","import PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport { JsonPathToAccessor, JsonPathToType } from './select-query-parser/utils'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\n\ntype FilterOperator =\n  | 'eq'\n  | 'neq'\n  | 'gt'\n  | 'gte'\n  | 'lt'\n  | 'lte'\n  | 'like'\n  | 'ilike'\n  | 'is'\n  | 'isdistinct'\n  | 'in'\n  | 'cs'\n  | 'cd'\n  | 'sl'\n  | 'sr'\n  | 'nxl'\n  | 'nxr'\n  | 'adj'\n  | 'ov'\n  | 'fts'\n  | 'plfts'\n  | 'phfts'\n  | 'wfts'\n  | 'match'\n  | 'imatch'\n\nexport type IsStringOperator<Path extends string> = Path extends `${string}->>${string}`\n  ? true\n  : false\n\nconst PostgrestReservedCharsRegexp = new RegExp('[,()]')\n\n// Match relationship filters with `table.column` syntax and resolve underlying\n// column value. If not matched, fallback to generic type.\n// TODO: Validate the relationship itself ala select-query-parser. Currently we\n// assume that all tables have valid relationships to each other, despite\n// nonexistent foreign keys.\ntype ResolveFilterValue<\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  ColumnName extends string,\n> = ColumnName extends `${infer RelationshipTable}.${infer Remainder}`\n  ? Remainder extends `${infer _}.${infer _}`\n    ? ResolveFilterValue<Schema, Row, Remainder>\n    : ResolveFilterRelationshipValue<Schema, RelationshipTable, Remainder>\n  : ColumnName extends keyof Row\n    ? Row[ColumnName]\n    : // If the column selection is a jsonpath like `data->value` or `data->>value` we attempt to match\n      // the expected type with the parsed custom json type\n      IsStringOperator<ColumnName> extends true\n      ? string\n      : JsonPathToType<Row, JsonPathToAccessor<ColumnName>> extends infer JsonPathValue\n        ? JsonPathValue extends never\n          ? never\n          : JsonPathValue\n        : never\n\ntype ResolveFilterRelationshipValue<\n  Schema extends GenericSchema,\n  RelationshipTable extends string,\n  RelationshipColumn extends string,\n> = Schema['Tables'] & Schema['Views'] extends infer TablesAndViews\n  ? RelationshipTable extends keyof TablesAndViews\n    ? 'Row' extends keyof TablesAndViews[RelationshipTable]\n      ? RelationshipColumn extends keyof TablesAndViews[RelationshipTable]['Row']\n        ? TablesAndViews[RelationshipTable]['Row'][RelationshipColumn]\n        : unknown\n      : unknown\n    : unknown\n  : never\n\nexport type InvalidMethodError<S extends string> = { Error: S }\n\nexport default class PostgrestFilterBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestTransformBuilder<\n  ClientOptions,\n  Schema,\n  Row,\n  Result,\n  RelationName,\n  Relationships,\n  Method\n> {\n  /**\n   * Match only rows where `column` is equal to `value`.\n   *\n   * To check if the value of `column` is NULL, you should use `.is()` instead.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  eq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? NonNullable<unknown>\n      : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n        // type resolution error\n        ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? NonNullable<ResolvedFilterValue>\n        : // We should never enter this case as all the branches are covered above\n          never\n  ): this {\n    this.url.searchParams.append(column, `eq.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is not equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  neq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `neq.${value}`)\n    return this\n  }\n\n  gt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gt.${value}`)\n    return this\n  }\n\n  gte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gte.${value}`)\n    return this\n  }\n\n  lt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lt.${value}`)\n    return this\n  }\n\n  lte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lte.${value}`)\n    return this\n  }\n\n  like<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  like(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  like(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `like.${pattern}`)\n    return this\n  }\n\n  likeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  likeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilike<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  ilike(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  ilike(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `ilike.${pattern}`)\n    return this\n  }\n\n  ilikeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilikeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  regexMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-sensitively (using the `~` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `match.${pattern}`)\n    return this\n  }\n\n  regexIMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexIMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-insensitively (using the `~*` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexIMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `imatch.${pattern}`)\n    return this\n  }\n\n  is<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: Row[ColumnName] & (boolean | null)\n  ): this\n  is(column: string, value: boolean | null): this\n  /**\n   * Match only rows where `column` IS `value`.\n   *\n   * For non-boolean columns, this is only relevant for checking if the value of\n   * `column` is NULL by setting `value` to `null`.\n   *\n   * For boolean columns, you can also set `value` to `true` or `false` and it\n   * will behave the same way as `.eq()`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  is(column: string, value: boolean | null): this {\n    this.url.searchParams.append(column, `is.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` IS DISTINCT FROM `value`.\n   *\n   * Unlike `.neq()`, this treats `NULL` as a comparable value. Two `NULL` values\n   * are considered equal (not distinct), and comparing `NULL` with any non-NULL\n   * value returns true (distinct).\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  isDistinct<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `isdistinct.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  in<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n          // type resolution error\n          ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : // We should never enter this case as all the branches are covered above\n            never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `in.(${cleanedValues})`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is NOT included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  notIn<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `not.in.(${cleanedValues})`)\n    return this\n  }\n\n  contains<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * `column` contains every element appearing in `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n      // keep it simple and accept a string\n      this.url.searchParams.append(column, `cs.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cs.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  containedBy<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * every element appearing in `column` is contained by `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `cd.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cd.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  rangeGt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is greater than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sr.${range}`)\n    return this\n  }\n\n  rangeGte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or greater than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxl.${range}`)\n    return this\n  }\n\n  rangeLt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is less than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sl.${range}`)\n    return this\n  }\n\n  rangeLte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or less than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxr.${range}`)\n    return this\n  }\n\n  rangeAdjacent<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeAdjacent(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where `column` is\n   * mutually exclusive to `range` and there can be no element between the two\n   * ranges.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeAdjacent(column: string, range: string): this {\n    this.url.searchParams.append(column, `adj.${range}`)\n    return this\n  }\n\n  overlaps<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]>\n  ): this\n  overlaps(column: string, value: string | readonly unknown[]): this\n  /**\n   * Only relevant for array and range columns. Match only rows where\n   * `column` and `value` have an element in common.\n   *\n   * @param column - The array or range column to filter on\n   * @param value - The array or range value to filter with\n   */\n  overlaps(column: string, value: string | readonly unknown[]): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `ov.${value}`)\n    } else {\n      // array\n      this.url.searchParams.append(column, `ov.{${value.join(',')}}`)\n    }\n    return this\n  }\n\n  textSearch<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  textSearch(\n    column: string,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  /**\n   * Only relevant for text and tsvector columns. Match only rows where\n   * `column` matches the query string in `query`.\n   *\n   * @param column - The text or tsvector column to filter on\n   * @param query - The query text to match with\n   * @param options - Named parameters\n   * @param options.config - The text search configuration to use\n   * @param options.type - Change how the `query` text is interpreted\n   */\n  textSearch(\n    column: string,\n    query: string,\n    { config, type }: { config?: string; type?: 'plain' | 'phrase' | 'websearch' } = {}\n  ): this {\n    let typePart = ''\n    if (type === 'plain') {\n      typePart = 'pl'\n    } else if (type === 'phrase') {\n      typePart = 'ph'\n    } else if (type === 'websearch') {\n      typePart = 'w'\n    }\n    const configPart = config === undefined ? '' : `(${config})`\n    this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`)\n    return this\n  }\n\n  match<ColumnName extends string & keyof Row>(query: Record<ColumnName, Row[ColumnName]>): this\n  match(query: Record<string, unknown>): this\n  /**\n   * Match only rows where each column in `query` keys is equal to its\n   * associated value. Shorthand for multiple `.eq()`s.\n   *\n   * @param query - The object to filter with, with column names as keys mapped\n   * to their filter values\n   */\n  match(query: Record<string, unknown>): this {\n    Object.entries(query).forEach(([column, value]) => {\n      this.url.searchParams.append(column, `eq.${value}`)\n    })\n    return this\n  }\n\n  not<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: FilterOperator,\n    value: Row[ColumnName]\n  ): this\n  not(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which doesn't satisfy the filter.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to be negated to filter with, following\n   * PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  not(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `not.${operator}.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows which satisfy at least one of the filters.\n   *\n   * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure it's properly sanitized.\n   *\n   * It's currently not possible to do an `.or()` filter across multiple tables.\n   *\n   * @param filters - The filters to use, following PostgREST syntax\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to filter on referenced tables\n   * instead of the parent table\n   * @param options.foreignTable - Deprecated, use `referencedTable` instead\n   */\n  or(\n    filters: string,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.or` : 'or'\n    this.url.searchParams.append(key, `(${filters})`)\n    return this\n  }\n\n  filter<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: `${'' | 'not.'}${FilterOperator}`,\n    value: unknown\n  ): this\n  filter(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which satisfy the filter. This is an escape hatch - you\n   * should use the specific filter methods wherever possible.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to filter with, following PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  filter(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `${operator}.${value}`)\n    return this\n  }\n}\n","import PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport {\n  ClientServerOptions,\n  Fetch,\n  GenericSchema,\n  GenericTable,\n  GenericView,\n} from './types/common/common'\n\nexport default class PostgrestQueryBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Relation extends GenericTable | GenericView,\n  RelationName = unknown,\n  Relationships = Relation extends { Relationships: infer R } ? R : unknown,\n> {\n  url: URL\n  headers: Headers\n  schema?: string\n  signal?: AbortSignal\n  fetch?: Fetch\n  urlLengthLimit: number\n\n  /**\n   * Creates a query builder scoped to a Postgres table or view.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const query = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: { apikey: 'public-anon-key' } }\n   * )\n   * ```\n   */\n  constructor(\n    url: URL,\n    {\n      headers = {},\n      schema,\n      fetch,\n      urlLengthLimit = 8000,\n    }: {\n      headers?: HeadersInit\n      schema?: string\n      fetch?: Fetch\n      urlLengthLimit?: number\n    }\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schema = schema\n    this.fetch = fetch\n    this.urlLengthLimit = urlLengthLimit\n  }\n\n  /**\n   * Clone URL and headers to prevent shared state between operations.\n   */\n  private cloneRequestState(): { url: URL; headers: Headers } {\n    return {\n      url: new URL(this.url.toString()),\n      headers: new Headers(this.headers),\n    }\n  }\n\n  /**\n   * Perform a SELECT query on the table or view.\n   *\n   * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n   *\n   * @param options - Named parameters\n   *\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   *\n   * @param options.count - Count algorithm to use to count rows in the table or view.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @remarks\n   * When using `count` with `.range()` or `.limit()`, the returned `count` is the total number of rows\n   * that match your filters, not the number of rows in the current page. Use this to build pagination UI.\n   */\n  select<\n    Query extends string = '*',\n    ResultOne = GetResult<\n      Schema,\n      Relation['Row'],\n      RelationName,\n      Relationships,\n      Query,\n      ClientOptions\n    >,\n  >(\n    columns?: Query,\n    options?: {\n      head?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    ResultOne[],\n    RelationName,\n    Relationships,\n    'GET'\n  > {\n    const { head = false, count } = options ?? {}\n\n    const method = head ? 'HEAD' : 'GET'\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n\n    const { url, headers } = this.cloneRequestState()\n    url.searchParams.set('select', cleanedColumns)\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      fetch: this.fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk inserts.\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an INSERT into the table or view.\n   *\n   * By default, inserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to insert. Pass an object to insert a single row\n   * or an array to insert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count inserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. Only applies for bulk\n   * inserts.\n   */\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      count,\n      defaultToNull = true,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      headers.append('Prefer', `missing=default`)\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk upserts.\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an UPSERT on the table or view. Depending on the column(s) passed\n   * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n   * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n   * exist, or if it does exist, perform an alternative action depending on\n   * `ignoreDuplicates`.\n   *\n   * By default, upserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to upsert with. Pass an object to upsert a\n   * single row or an array to upsert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n   * duplicate rows are determined. Two rows are duplicates if all the\n   * `onConflict` columns are equal.\n   *\n   * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n   * `false`, duplicate rows are merged with existing rows.\n   *\n   * @param options.count - Count algorithm to use to count upserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. This only applies when\n   * inserting new rows, not when merging with existing rows under\n   * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n   *\n   * @example Upsert a single row using a unique key\n   * ```ts\n   * // Upserting a single row, overwriting based on the 'username' unique column\n   * const { data, error } = await supabase\n   *   .from('users')\n   *   .upsert({ username: 'supabot' }, { onConflict: 'username' })\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     { id: 4, message: 'bar', username: 'supabot' }\n   * //   ],\n   * //   error: null\n   * // }\n   * ```\n   *\n   * @example Upsert with conflict resolution and exact row counting\n   * ```ts\n   * // Upserting and returning exact count\n   * const { data, error, count } = await supabase\n   *   .from('users')\n   *   .upsert(\n   *     {\n   *       id: 3,\n   *       message: 'foo',\n   *       username: 'supabot'\n   *     },\n   *     {\n   *       onConflict: 'username',\n   *       count: 'exact'\n   *     }\n   *   )\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     {\n   * //       id: 42,\n   * //       handle: \"saoirse\",\n   * //       display_name: \"Saoirse\"\n   * //     }\n   * //   ],\n   * //   count: 1,\n   * //   error: null\n   * // }\n   * ```\n   */\n\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      onConflict,\n      ignoreDuplicates = false,\n      count,\n      defaultToNull = true,\n    }: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n    const { url, headers } = this.cloneRequestState()\n\n    headers.append('Prefer', `resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`)\n\n    if (onConflict !== undefined) url.searchParams.set('on_conflict', onConflict)\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      headers.append('Prefer', 'missing=default')\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  /**\n   * Perform an UPDATE on the table or view.\n   *\n   * By default, updated rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param values - The values to update with\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count updated rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  update<Row extends Relation extends { Update: unknown } ? Relation['Update'] : never>(\n    values: Row,\n    {\n      count,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'PATCH'\n  > {\n    const method = 'PATCH'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  /**\n   * Perform a DELETE on the table or view.\n   *\n   * By default, deleted rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count deleted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  delete({\n    count,\n  }: {\n    count?: 'exact' | 'planned' | 'estimated'\n  } = {}): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'DELETE'\n  > {\n    const method = 'DELETE'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      fetch: this.fetch ?? fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n}\n","import PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { Fetch, GenericSchema, ClientServerOptions } from './types/common/common'\nimport { GetRpcFunctionFilterBuilderByArgs } from './types/common/rpc'\n\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nexport default class PostgrestClient<\n  Database = any,\n  ClientOptions extends ClientServerOptions = Database extends {\n    __InternalSupabase: infer I extends ClientServerOptions\n  }\n    ? I\n    : {},\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = 'public' extends keyof Omit<\n    Database,\n    '__InternalSupabase'\n  >\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  Schema extends GenericSchema = Omit<\n    Database,\n    '__InternalSupabase'\n  >[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : any,\n> {\n  url: string\n  headers: Headers\n  schemaName?: SchemaName\n  fetch?: Fetch\n  urlLengthLimit: number\n\n  // TODO: Add back shouldThrowOnError once we figure out the typings\n  /**\n   * Creates a PostgREST client.\n   *\n   * @param url - URL of the PostgREST endpoint\n   * @param options - Named parameters\n   * @param options.headers - Custom headers\n   * @param options.schema - Postgres schema to switch to\n   * @param options.fetch - Custom fetch\n   * @param options.timeout - Optional timeout in milliseconds for all requests. When set, requests will automatically abort after this duration to prevent indefinite hangs.\n   * @param options.urlLengthLimit - Maximum URL length in characters before warnings/errors are triggered. Defaults to 8000.\n   * @example\n   * ```ts\n   * import PostgrestClient from '@supabase/postgrest-js'\n   *\n   * const postgrest = new PostgrestClient('https://xyzcompany.supabase.co/rest/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   schema: 'public',\n   *   timeout: 30000, // 30 second timeout\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      schema,\n      fetch,\n      timeout,\n      urlLengthLimit = 8000,\n    }: {\n      headers?: HeadersInit\n      schema?: SchemaName\n      fetch?: Fetch\n      timeout?: number\n      urlLengthLimit?: number\n    } = {}\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schemaName = schema\n    this.urlLengthLimit = urlLengthLimit\n\n    const originalFetch = fetch ?? globalThis.fetch\n\n    // Wrap fetch with timeout if specified\n    if (timeout !== undefined && timeout > 0) {\n      this.fetch = (input, init) => {\n        const controller = new AbortController()\n        const timeoutId = setTimeout(() => controller.abort(), timeout)\n\n        // Merge abort signals if one already exists\n        const existingSignal = init?.signal\n        if (existingSignal) {\n          // If the existing signal is already aborted, use it directly\n          if (existingSignal.aborted) {\n            clearTimeout(timeoutId)\n            return originalFetch(input, init)\n          }\n\n          // Listen to existing signal and abort our controller too\n          const abortHandler = () => {\n            clearTimeout(timeoutId)\n            controller.abort()\n          }\n          existingSignal.addEventListener('abort', abortHandler, { once: true })\n\n          return originalFetch(input, {\n            ...init,\n            signal: controller.signal,\n          }).finally(() => {\n            clearTimeout(timeoutId)\n            existingSignal.removeEventListener('abort', abortHandler)\n          })\n        }\n\n        return originalFetch(input, {\n          ...init,\n          signal: controller.signal,\n        }).finally(() => clearTimeout(timeoutId))\n      }\n    } else {\n      this.fetch = originalFetch\n    }\n  }\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any, any> {\n    if (!relation || typeof relation !== 'string' || relation.trim() === '') {\n      throw new Error('Invalid relation name: relation must be a non-empty string.')\n    }\n\n    const url = new URL(`${this.url}/${relation}`)\n    return new PostgrestQueryBuilder(url, {\n      headers: new Headers(this.headers),\n      schema: this.schemaName,\n      fetch: this.fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return new PostgrestClient(this.url, {\n      headers: this.headers,\n      schema,\n      fetch: this.fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @example\n   * ```ts\n   * // For cross-schema functions where type inference fails, use overrideTypes:\n   * const { data } = await supabase\n   *   .schema('schema_b')\n   *   .rpc('function_a', {})\n   *   .overrideTypes<{ id: string; user_id: string }[]>()\n   * ```\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    {\n      head = false,\n      get = false,\n      count,\n    }: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    let method: 'HEAD' | 'GET' | 'POST'\n    const url = new URL(`${this.url}/rpc/${fn}`)\n    let body: unknown | undefined\n    // objects/arrays-of-objects can't be serialized to URL params, use POST + return=minimal instead\n    const _isObject = (v: unknown): boolean =>\n      v !== null && typeof v === 'object' && (!Array.isArray(v) || v.some(_isObject))\n    const _hasObjectArg = head && Object.values(args as object).some(_isObject)\n    if (_hasObjectArg) {\n      method = 'POST'\n      body = args\n    } else if (head || get) {\n      method = head ? 'HEAD' : 'GET'\n      Object.entries(args)\n        // params with undefined value needs to be filtered out, otherwise it'll\n        // show up as `?param=undefined`\n        .filter(([_, value]) => value !== undefined)\n        // array values need special syntax\n        .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n        .forEach(([name, value]) => {\n          url.searchParams.append(name, value)\n        })\n    } else {\n      method = 'POST'\n      body = args\n    }\n\n    const headers = new Headers(this.headers)\n    if (_hasObjectArg) {\n      headers.set('Prefer', count ? `count=${count},return=minimal` : 'return=minimal')\n    } else if (count) {\n      headers.set('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schemaName,\n      body,\n      fetch: this.fetch ?? fetch,\n      urlLengthLimit: this.urlLengthLimit,\n    })\n  }\n}\n","import PostgrestClient from './PostgrestClient'\nimport PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestError from './PostgrestError'\n\nexport {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport type {\n  PostgrestResponse,\n  PostgrestResponseFailure,\n  PostgrestResponseSuccess,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from './types/types'\nexport type { ClientServerOptions as PostgrestClientOptions } from './types/common/common'\n// https://github.com/supabase/postgrest-js/issues/551\n// To be replaced with a helper type that only uses public types\nexport type { GetResult as UnstableGetResult } from './select-query-parser/result'\n"],"names":["count: number | null","res","this","fetch","fetch","method: 'HEAD' | 'GET' | 'POST'","body: unknown | undefined"],"mappings":";;;;;;;;;;;;;;;;;;;;;GAKA,IAAqB,iBAArB,cAA4C,MAAM;;;;;;;;;;;;;IAkBhD,YAAY,OAAA,CAA2E;QACrF,KAAA,CAAM,QAAQ,OAAA,CAAQ;QACtB,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,OAAA,GAAU,QAAQ,OAAA;QACvB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;QACpB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;;;;;ACjBxB,IAA8B,mBAA9B,MAQA;;;;;;;;;;;;;IAyBE,YAAY,OAAA,CAWT;;aA9BO,kBAAA,GAAqB;QA+B7B,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,GAAA,GAAM,QAAQ,GAAA;QACnB,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ,OAAA,CAAQ;QAC3C,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;QACpB,IAAA,CAAK,kBAAA,GAAA,CAAA,wBAAqB,QAAQ,kBAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAsB;QACxD,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,aAAA,GAAA,CAAA,wBAAgB,QAAQ,aAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAiB;QAC9C,IAAA,CAAK,cAAA,GAAA,CAAA,wBAAiB,QAAQ,cAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAkB;QAEhD,IAAI,QAAQ,KAAA,CACV,CAAA,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;aAErB,IAAA,CAAK,KAAA,GAAQ;;;;;;;IAUjB,eAAqE;QACnE,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;IAMT,UAAU,IAAA,EAAc,KAAA,EAAqB;QAC3C,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;QACxC,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,MAAM,MAAM;QAC7B,OAAO,IAAA;;IAGT,KAME,WAAA,EAQA,UAAA,EACkC;;QAElC,IAAI,IAAA,CAAK,MAAA,KAAW,KAAA,GAAW,CAAA,OAAA,IAEpB;YAAC;YAAO;SAAO,CAAC,QAAA,CAAS,IAAA,CAAK,MAAA,CAAO,CAC9C,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,kBAAkB,IAAA,CAAK,MAAA,CAAO;aAE/C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,mBAAmB,IAAA,CAAK,MAAA,CAAO;QAElD,IAAI,IAAA,CAAK,MAAA,KAAW,SAAS,IAAA,CAAK,MAAA,KAAW,OAC3C,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,gBAAgB,mBAAmB;QAKtD,MAAM,SAAS,IAAA,CAAK,KAAA;QACpB,IAAI,MAAM,OAAO,IAAA,CAAK,GAAA,CAAI,QAAA,EAAU,EAAE;YACpC,QAAQ,IAAA,CAAK,MAAA;YACb,SAAS,IAAA,CAAK,OAAA;YACd,MAAM,KAAK,SAAA,CAAU,IAAA,CAAK,IAAA,CAAK;YAC/B,QAAQ,IAAA,CAAK,MAAA;SACd,CAAC,CAAC,IAAA,CAAK,OAAO,UAAQ;YACrB,IAAI,QAAQ;YACZ,IAAI,OAAO;YACX,IAAIA,QAAuB;YAC3B,IAAI,SAASC,MAAI,MAAA;YACjB,IAAI,aAAaA,MAAI,UAAA;YAErB,IAAIA,MAAI,EAAA,EAAI;;gBACV,IAAIC,MAAK,MAAA,KAAW,QAAQ;;oBAC1B,MAAM,OAAO,MAAMD,MAAI,IAAA,EAAM;oBAC7B,IAAI,SAAS,IAAI,CAAA,OAAA,IAENC,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,KAAK,WACxC,CAAA,OAAO;6BAEPA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,IAAA,CAAA,CAAA,oBAC1BA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,sBAAA,KAAA,IAAA,KAAA,IAAA,kBAAE,QAAA,CAAS,kCAAkC,EAEvE,CAAA,OAAO;yBAEP,OAAO,KAAK,KAAA,CAAM,KAAK;;gBAI3B,MAAM,cAAA,CAAA,qBAAcA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,uBAAA,KAAA,IAAA,KAAA,IAAA,mBAAE,KAAA,CAAM,kCAAkC;gBACxF,MAAM,eAAA,CAAA,mBAAeD,MAAI,OAAA,CAAQ,GAAA,CAAI,gBAAgB,MAAA,QAAA,qBAAA,KAAA,IAAA,KAAA,IAAA,iBAAE,KAAA,CAAM,IAAI;gBACjE,IAAI,eAAe,gBAAgB,aAAa,MAAA,GAAS,EACvD,CAAA,QAAQ,SAAS,YAAA,CAAa,EAAA,CAAG;gBAKnC,IAAIC,MAAK,aAAA,IAAiBA,MAAK,MAAA,KAAW,SAAS,MAAM,OAAA,CAAQ,KAAK,CACpE,CAAA,IAAI,KAAK,MAAA,GAAS,GAAG;oBACnB,QAAQ;wBAEN,MAAM;wBACN,SAAS,CAAA,gBAAA,EAAmB,KAAK,MAAA,CAAO,uDAAA,CAAA;wBACxC,MAAM;wBACN,SAAS;qBACV;oBACD,OAAO;oBACP,QAAQ;oBACR,SAAS;oBACT,aAAa;2BACJ,KAAK,MAAA,KAAW,EACzB,CAAA,OAAO,IAAA,CAAK,EAAA;qBAEZ,OAAO;mBAGN;;gBACL,MAAM,OAAO,MAAMD,MAAI,IAAA,EAAM;gBAE7B,IAAI;oBACF,QAAQ,KAAK,KAAA,CAAM,KAAK;oBAGxB,IAAI,MAAM,OAAA,CAAQ,MAAM,IAAIA,MAAI,MAAA,KAAW,KAAK;wBAC9C,OAAO,EAAE;wBACT,QAAQ;wBACR,SAAS;wBACT,aAAa;;kCAET;oBAEN,IAAIA,MAAI,MAAA,KAAW,OAAO,SAAS,IAAI;wBACrC,SAAS;wBACT,aAAa;0BAEb,CAAA,QAAQ;wBACN,SAAS;oBAAA,CACV;;gBAIL,IAAI,SAASC,MAAK,aAAA,IAAA,CAAA,UAAA,QAAA,UAAA,KAAA,KAAA,CAAA,iBAAiB,MAAO,OAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,KAAA,IAAA,eAAS,QAAA,CAAS,SAAS,GAAE;oBACrE,QAAQ;oBACR,SAAS;oBACT,aAAa;;gBAGf,IAAI,SAASA,MAAK,kBAAA,CAChB,CAAA,MAAM,IAAI,eAAe,MAAM;;YAYnC,OAR0B;gBACxB;gBACA;gBACA;gBACA;gBACA;aACD;UAGD;QACF,IAAI,CAAC,IAAA,CAAK,kBAAA,CACR,CAAA,MAAM,IAAI,KAAA,CAAA,CAAO,eAAe;;YAI9B,IAAI,eAAe;YACnB,IAAI,OAAO;YACX,IAAI,OAAO;YAGX,MAAM,QAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAQ,WAAY,KAAA;YAC1B,IAAI,OAAO;;gBACT,MAAM,eAAA,CAAA,iBAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAe,MAAO,OAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,iBAAW;gBACvC,MAAM,YAAA,CAAA,cAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAY,MAAO,IAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAQ;gBAEjC,eAAe,GAAA,CAAA,mBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAG,WAAY,IAAA,MAAA,QAAA,qBAAA,KAAA,IAAA,mBAAQ,aAAa,EAAA,EAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAI,WAAY,OAAA,EAAA;gBACnE,gBAAgB,CAAA,eAAA,EAAA,CAAA,cAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAkB,MAAO,IAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAQ,QAAQ,EAAA,EAAI,cAAA;gBAC7D,IAAI,UACF,CAAA,gBAAgB,CAAA,EAAA,EAAK,UAAU,CAAA,CAAA;gBAEjC,IAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAI,MAAO,KAAA,CACT,CAAA,gBAAgB,CAAA,EAAA,EAAK,MAAM,KAAA,EAAA;mBAExB;;gBAEL,eAAA,CAAA,oBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAe,WAAY,KAAA,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAS;;YAItC,MAAM,YAAY,IAAA,CAAK,GAAA,CAAI,QAAA,EAAU,CAAC,MAAA;YAGtC,IAAA,CAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAI,WAAY,IAAA,MAAS,gBAAA,CAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAgB,WAAY,IAAA,MAAS,aAAa;gBACzE,OAAO;gBACP,OAAO;gBAEP,IAAI,YAAY,IAAA,CAAK,cAAA,CACnB,CAAA,QAAQ,CAAA,4BAAA,EAA+B,UAAU,qNAAA,CAAA;sEAKnD,MAAO,IAAA,MAAS,0BAAA,CAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAChB,MAAO,IAAA,MAAS,4BAChB;gBACA,OAAO;gBACP,OAAO;gBAEP,IAAI,YAAY,IAAA,CAAK,cAAA,CACnB,CAAA,QAAQ,CAAA,sBAAA,EAAyB,UAAU,kKAAA,CAAA;;YAI/C,OAAO;gBACL,OAAO;oBACL,SAAS,GAAA,CAAA,oBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAG,WAAY,IAAA,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAQ,aAAa,EAAA,EAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAI,WAAY,OAAA,EAAA;oBAC7D,SAAS;oBACH;oBACA;iBACP;gBACD,MAAM;gBACN,OAAO;gBACP,QAAQ;gBACR,YAAY;aACb;UACD;QAGJ,OAAO,IAAI,IAAA,CAAK,aAAa,WAAW;;;;;;;IAS1C,UAIE;mCAEA,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;IA6BT,gBAYE;QACA,OAAO,IAAA;;;;;ACxVX,IAAqB,4BAArB,cAQU,iBAAwC;;;;;;;;;IAUhD,OAIE,OAAA,EAaA;QAEA,IAAI,SAAS;QACb,MAAM,iBAAA,CAAkB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,GAAA,EAChC,KAAA,CAAM,GAAG,CACT,GAAA,CAAA,CAAK,MAAM;YACV,IAAI,KAAK,IAAA,CAAK,EAAE,IAAI,CAAC,OACnB,CAAA,OAAO;YAET,IAAI,MAAM,KACR,CAAA,SAAS,CAAC;YAEZ,OAAO;UACP,CACD,IAAA,CAAK,GAAG;QACX,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAU,eAAe;QACnD,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,wBAAwB;QACtD,OAAO,IAAA;;;;;;;;;;;;;;;;;;;IAuDT,MACE,MAAA,EACA,EACE,YAAY,IAAA,EACZ,UAAA,EACA,YAAA,EACA,kBAAkB,YAAA,EAAA,GAMhB,CAAA,CAAE,EACA;QACN,MAAM,MAAM,kBAAkB,GAAG,gBAAgB,MAAA,CAAA,GAAU;QAC3D,MAAM,gBAAgB,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,IAAI;QAEpD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CACpB,KACA,GAAG,gBAAgB,GAAG,cAAc,CAAA,CAAA,GAAK,KAAK,OAAO,CAAA,EAAG,YAAY,QAAQ,SAC1E,eAAe,KAAA,IAAY,KAAK,aAAa,gBAAgB,cAAA,CAEhE;QACD,OAAO,IAAA;;;;;;;;;;;IAaT,MACE,KAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,MAAM,OAAO,oBAAoB,cAAc,UAAU,GAAG,gBAAgB,MAAA,CAAA;QAClF,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,KAAK,GAAG,OAAA,CAAQ;QAC1C,OAAO,IAAA;;;;;;;;;;;;;;;;IAkBT,MACE,IAAA,EACA,EAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,YACJ,OAAO,oBAAoB,cAAc,WAAW,GAAG,gBAAgB,OAAA,CAAA;QACzE,MAAM,WAAW,OAAO,oBAAoB,cAAc,UAAU,GAAG,gBAAgB,MAAA,CAAA;QACvF,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,WAAW,GAAG,MAAA,CAAO;QAE/C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAU,GAAG,KAAK,OAAO,GAAA,CAAI;QACvD,OAAO,IAAA;;;;;;IAQT,YAAY,MAAA,EAA2B;QACrC,IAAA,CAAK,MAAA,GAAS;QACd,OAAO,IAAA;;;;;;;IAST,SAGE;QACA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,oCAAoC;QAC/D,OAAO,IAAA;;;;;;;IAST,cAEuD;QAGrD,IAAI,IAAA,CAAK,MAAA,KAAW,MAClB,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,mBAAmB;aAE9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,oCAAoC;QAEjE,IAAA,CAAK,aAAA,GAAgB;QACrB,OAAO,IAAA;;;;IAMT,MAA+C;QAC7C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,WAAW;QACtC,OAAO,IAAA;;;;IAMT,UAAoE;QAClE,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,uBAAuB;QAClD,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BT,QAAQ,EACN,UAAU,KAAA,EACV,UAAU,KAAA,EACV,WAAW,KAAA,EACX,UAAU,KAAA,EACV,MAAM,KAAA,EACN,SAAS,MAAA,EAAA,GAQP,CAAA,CAAE,EAAE;;QACN,MAAM,UAAU;YACd,UAAU,YAAY;YACtB,UAAU,YAAY;YACtB,WAAW,aAAa;YACxB,UAAU,YAAY;YACtB,MAAM,QAAQ;SACf,CACE,MAAA,CAAO,QAAQ,CACf,IAAA,CAAK,IAAI;QAEZ,MAAM,eAAA,CAAA,oBAAe,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAI;QACnD,IAAA,CAAK,OAAA,CAAQ,GAAA,CACX,UACA,CAAA,2BAAA,EAA8B,OAAO,OAAA,EAAS,aAAa,WAAA,EAAa,QAAQ,CAAA,CAAA,CACjF;QACD,IAAI,WAAW,OACb,CAAA,OAAO,IAAA;aAEP,OAAO,IAAA;;;;;;IASX,WAAiB;QACf,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,cAAc;QAC5C,OAAO,IAAA;;;;;;;IAST,UAQE;QACA,OAAO,IAAA;;;;;;;IAiBT,YAAY,KAAA,EAKiE;QAC3E,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,kBAAkB;QAChD,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,aAAA,EAAgB,OAAA,CAAQ;QACtD,OAAO,IAAA;;;;;AC3UX,MAAM,+BAAA,aAAA,GAA+B,IAAI,OAAO,QAAQ;AA2CxD,IAAqB,yBAArB,cAQU,0BAQR;;;;;;;;IASA,GACE,MAAA,EACA,KAAA,EAQM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAST,IACE,MAAA,EACA,KAAA,EAKM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,GAAG,MAAA,EAAgB,KAAA,EAAsB;QACvC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAWT,IAAI,MAAA,EAAgB,KAAA,EAAsB;QACxC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,GAAG,MAAA,EAAgB,KAAA,EAAsB;QACvC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAWT,IAAI,MAAA,EAAgB,KAAA,EAAsB;QACxC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,KAAK,MAAA,EAAgB,OAAA,EAAuB;QAC1C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,KAAA,EAAQ,SAAA,CAAU;QACvD,OAAO,IAAA;;;;;;;IAcT,UAAU,MAAA,EAAgB,QAAA,EAAmC;QAC3D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QACzE,OAAO,IAAA;;;;;;;IAcT,UAAU,MAAA,EAAgB,QAAA,EAAmC;QAC3D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QACzE,OAAO,IAAA;;;;;;;IAWT,MAAM,MAAA,EAAgB,OAAA,EAAuB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,MAAA,EAAS,SAAA,CAAU;QACxD,OAAO,IAAA;;;;;;;IAcT,WAAW,MAAA,EAAgB,QAAA,EAAmC;QAC5D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,YAAA,EAAe,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAC1E,OAAO,IAAA;;;;;;;IAcT,WAAW,MAAA,EAAgB,QAAA,EAAmC;QAC5D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,YAAA,EAAe,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAC1E,OAAO,IAAA;;;;;;;;IAYT,WAAW,MAAA,EAAgB,OAAA,EAAuB;QAChD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,MAAA,EAAS,SAAA,CAAU;QACxD,OAAO,IAAA;;;;;;;;IAYT,YAAY,MAAA,EAAgB,OAAA,EAAuB;QACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,OAAA,EAAU,SAAA,CAAU;QACzD,OAAO,IAAA;;;;;;;;;;;;;IAoBT,GAAG,MAAA,EAAgB,KAAA,EAA6B;QAC9C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;;;IAaT,WACE,MAAA,EACA,KAAA,EAKM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,OAAA,CAAQ;QAC3D,OAAO,IAAA;;;;;;;IAST,GACE,MAAA,EACA,MAAA,EAUM;QACN,MAAM,gBAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,OAAO,CAAC,CAC9C,GAAA,CAAA,CAAK,MAAM;YAGV,IAAI,OAAO,MAAM,YAAY,6BAA6B,IAAA,CAAK,EAAE,CAAE,CAAA,OAAO,CAAA,CAAA,EAAI,EAAE,CAAA,CAAA;iBAC3E,OAAO,GAAG,GAAA;UACf,CACD,IAAA,CAAK,IAAI;QACZ,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,cAAc,CAAA,CAAA,CAAG;QAC7D,OAAO,IAAA;;;;;;;IAST,MACE,MAAA,EACA,MAAA,EAOM;QACN,MAAM,gBAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,OAAO,CAAC,CAC9C,GAAA,CAAA,CAAK,MAAM;YAGV,IAAI,OAAO,MAAM,YAAY,6BAA6B,IAAA,CAAK,EAAE,CAAE,CAAA,OAAO,CAAA,CAAA,EAAI,EAAE,CAAA,CAAA;iBAC3E,OAAO,GAAG,GAAA;UACf,CACD,IAAA,CAAK,IAAI;QACZ,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,QAAA,EAAW,cAAc,CAAA,CAAA,CAAG;QACjE,OAAO,IAAA;;;;;;;;IAeT,SAAS,MAAA,EAAgB,KAAA,EAAoE;QAC3F,IAAI,OAAO,UAAU,SAGnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;iBAC1C,MAAM,OAAA,CAAQ,MAAM,CAE7B,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;aAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,MAAM,EAAA,CAAG;QAErE,OAAO,IAAA;;;;;;;;IAeT,YAAY,MAAA,EAAgB,KAAA,EAAoE;QAC9F,IAAI,OAAO,UAAU,SAEnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;iBAC1C,MAAM,OAAA,CAAQ,MAAM,CAE7B,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;aAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,MAAM,EAAA,CAAG;QAErE,OAAO,IAAA;;;;;;;;IAYT,QAAQ,MAAA,EAAgB,KAAA,EAAqB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;IAaT,SAAS,MAAA,EAAgB,KAAA,EAAqB;QAC5C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;IAYT,QAAQ,MAAA,EAAgB,KAAA,EAAqB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;IAaT,SAAS,MAAA,EAAgB,KAAA,EAAqB;QAC5C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;;IAaT,cAAc,MAAA,EAAgB,KAAA,EAAqB;QACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;IAeT,SAAS,MAAA,EAAgB,KAAA,EAA0C;QACjE,IAAI,OAAO,UAAU,SAEnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;aAGnD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAEjE,OAAO,IAAA;;;;;;;;;;;IAuBT,WACE,MAAA,EACA,KAAA,EACA,EAAE,MAAA,EAAQ,IAAA,EAAA,GAAuE,CAAA,CAAE,EAC7E;QACN,IAAI,WAAW;QACf,IAAI,SAAS,QACX,CAAA,WAAW;iBACF,SAAS,SAClB,CAAA,WAAW;iBACF,SAAS,YAClB,CAAA,WAAW;QAEb,MAAM,aAAa,WAAW,KAAA,IAAY,KAAK,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA;QAC1D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,GAAG,SAAS,GAAA,EAAK,WAAW,CAAA,EAAG,OAAA,CAAQ;QAC5E,OAAO,IAAA;;;;;;;;IAYT,MAAM,KAAA,EAAsC;QAC1C,OAAO,OAAA,CAAQ,MAAM,CAAC,OAAA,CAAA,CAAS,CAAC,QAAQ,MAAA,KAAW;YACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;UACnD;QACF,OAAO,IAAA;;;;;;;;;;;;;;IAsBT,IAAI,MAAA,EAAgB,QAAA,EAAkB,KAAA,EAAsB;QAC1D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,SAAS,CAAA,EAAG,OAAA,CAAQ;QAChE,OAAO,IAAA;;;;;;;;;;;;;;;;IAkBT,GACE,OAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,MAAM,kBAAkB,GAAG,gBAAgB,GAAA,CAAA,GAAO;QACxD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,KAAK,CAAA,CAAA,EAAI,QAAQ,CAAA,CAAA,CAAG;QACjD,OAAO,IAAA;;;;;;;;;;;;;;IAsBT,OAAO,MAAA,EAAgB,QAAA,EAAkB,KAAA,EAAsB;QAC7D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,GAAG,SAAS,CAAA,EAAG,OAAA,CAAQ;QAC5D,OAAO,IAAA;;;;;AClqBX,IAAqB,wBAArB,MAME;;;;;;;;;;;;;IAqBA,YACE,GAAA,EACA,EACE,UAAU,CAAA,CAAE,EACZ,MAAA,EACA,OAAA,OAAA,EACA,iBAAiB,GAAA,EAAA,CAOnB;QACA,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ;QACnC,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,KAAA,GAAQC;QACb,IAAA,CAAK,cAAA,GAAiB;;;;IAMhB,oBAAoD;QAC1D,OAAO;YACL,KAAK,IAAI,IAAI,IAAA,CAAK,GAAA,CAAI,QAAA,EAAU,CAAC;YACjC,SAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;SACnC;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BH,OAWE,OAAA,EACA,OAAA,EAYA;QACA,MAAM,EAAE,OAAO,KAAA,EAAO,KAAA,EAAA,GAAU,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,CAAA,CAAE;QAE7C,MAAM,SAAS,OAAO,SAAS;QAE/B,IAAI,SAAS;QACb,MAAM,iBAAA,CAAkB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,GAAA,EAChC,KAAA,CAAM,GAAG,CACT,GAAA,CAAA,CAAK,MAAM;YACV,IAAI,KAAK,IAAA,CAAK,EAAE,IAAI,CAAC,OACnB,CAAA,OAAO;YAET,IAAI,MAAM,KACR,CAAA,SAAS,CAAC;YAEZ,OAAO;UACP,CACD,IAAA,CAAK,GAAG;QAEX,MAAM,EAAE,GAAA,EAAK,OAAA,EAAA,GAAY,IAAA,CAAK,iBAAA,EAAmB;QACjD,IAAI,YAAA,CAAa,GAAA,CAAI,UAAU,eAAe;QAE9C,IAAI,MACF,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAG5C,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,MAAA;YACb,OAAO,IAAA,CAAK,KAAA;YACZ,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;IA2DJ,OACE,MAAA,EACA,EACE,KAAA,EACA,gBAAgB,IAAA,EAAA,GAId,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QACf,MAAM,EAAE,GAAA,EAAK,OAAA,EAAA,GAAY,IAAA,CAAK,iBAAA,EAAmB;QAEjD,IAAI,MACF,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAE5C,IAAI,CAAC,cACH,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,eAAA,CAAA,CAAkB;QAG7C,IAAI,MAAM,OAAA,CAAQ,OAAO,EAAE;YACzB,MAAM,UAAU,OAAO,MAAA,CAAA,CAAQ,KAAK,IAAM,IAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,EAAE,EAAE,CAAa;YACrF,IAAI,QAAQ,MAAA,GAAS,GAAG;gBACtB,MAAM,gBAAgB,CAAC;uBAAG,IAAI,IAAI,QAAQ;iBAAC,CAAC,GAAA,CAAA,CAAK,SAAW,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAG;gBAC1E,IAAI,YAAA,CAAa,GAAA,CAAI,WAAW,cAAc,IAAA,CAAK,IAAI,CAAC;;;QAI5D,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,cAAO,IAAA,CAAK,KAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAS;YACrB,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA2HJ,OACE,MAAA,EACA,EACE,UAAA,EACA,mBAAmB,KAAA,EACnB,KAAA,EACA,gBAAgB,IAAA,EAAA,GAMd,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QACf,MAAM,EAAE,GAAA,EAAK,OAAA,EAAA,GAAY,IAAA,CAAK,iBAAA,EAAmB;QAEjD,QAAQ,MAAA,CAAO,UAAU,CAAA,WAAA,EAAc,mBAAmB,WAAW,QAAQ,WAAA,CAAA,CAAa;QAE1F,IAAI,eAAe,KAAA,EAAW,CAAA,IAAI,YAAA,CAAa,GAAA,CAAI,eAAe,WAAW;QAC7E,IAAI,MACF,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAE5C,IAAI,CAAC,cACH,CAAA,QAAQ,MAAA,CAAO,UAAU,kBAAkB;QAG7C,IAAI,MAAM,OAAA,CAAQ,OAAO,EAAE;YACzB,MAAM,UAAU,OAAO,MAAA,CAAA,CAAQ,KAAK,IAAM,IAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,EAAE,EAAE,CAAa;YACrF,IAAI,QAAQ,MAAA,GAAS,GAAG;gBACtB,MAAM,gBAAgB,CAAC;uBAAG,IAAI,IAAI,QAAQ;iBAAC,CAAC,GAAA,CAAA,CAAK,SAAW,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAG;gBAC1E,IAAI,YAAA,CAAa,GAAA,CAAI,WAAW,cAAc,IAAA,CAAK,IAAI,CAAC;;;QAI5D,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;YACrB,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;IAwBJ,OACE,MAAA,EACA,EACE,KAAA,EAAA,GAGE,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QACf,MAAM,EAAE,GAAA,EAAK,OAAA,EAAA,GAAY,IAAA,CAAK,iBAAA,EAAmB;QAEjD,IAAI,MACF,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAG5C,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;YACrB,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;IAsBJ,OAAO,EACL,KAAA,EAAA,GAGE,CAAA,CAAE,EAQJ;;QACA,MAAM,SAAS;QACf,MAAM,EAAE,GAAA,EAAK,OAAA,EAAA,GAAY,IAAA,CAAK,iBAAA,EAAmB;QAEjD,IAAI,MACF,CAAA,QAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAG5C,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,MAAA;YACb,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;YACrB,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCpgBN,IAAqB,kBAArB,MAAqB,gBAoBnB;;;;;;;;;;;;;;;;;;;;;IA6BA,YACE,GAAA,EACA,EACE,UAAU,CAAA,CAAE,EACZ,MAAA,EACA,OAAA,OAAA,EACA,OAAA,EACA,iBAAiB,GAAA,EAAA,GAOf,CAAA,CAAE,CACN;QACA,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ;QACnC,IAAA,CAAK,UAAA,GAAa;QAClB,IAAA,CAAK,cAAA,GAAiB;QAEtB,MAAM,gBAAgBC,YAAAA,QAAAA,YAAAA,KAAAA,IAAAA,UAAS,WAAW,KAAA;QAG1C,IAAI,YAAY,KAAA,KAAa,UAAU,EACrC,CAAA,IAAA,CAAK,KAAA,GAAA,CAAS,OAAO,SAAS;YAC5B,MAAM,aAAa,IAAI,iBAAiB;YACxC,MAAM,YAAY,WAAA,IAAiB,WAAW,KAAA,EAAO,EAAE,QAAQ;YAG/D,MAAM,iBAAA,SAAA,QAAA,SAAA,KAAA,IAAA,KAAA,IAAiB,KAAM,MAAA;YAC7B,IAAI,gBAAgB;gBAElB,IAAI,eAAe,OAAA,EAAS;oBAC1B,aAAa,UAAU;oBACvB,OAAO,cAAc,OAAO,KAAK;;gBAInC,MAAM,eAAA,MAAqB;oBACzB,aAAa,UAAU;oBACvB,WAAW,KAAA,EAAO;;gBAEpB,eAAe,gBAAA,CAAiB,SAAS,cAAc;oBAAE,MAAM;gBAAA,CAAM,CAAC;gBAEtE,OAAO,cAAc,OAAA,eAAA,eAAA,CAAA,GAChB,OAAA,CAAA,GAAA;oBACH,QAAQ,WAAW,MAAA;gBAAA,GACnB,CAAC,OAAA,CAAA,MAAc;oBACf,aAAa,UAAU;oBACvB,eAAe,mBAAA,CAAoB,SAAS,aAAa;kBACzD;;YAGJ,OAAO,cAAc,OAAA,eAAA,eAAA,CAAA,GAChB,OAAA,CAAA,GAAA;gBACH,QAAQ,WAAW,MAAA;YAAA,GACnB,CAAC,OAAA,CAAA,IAAc,aAAa,UAAU,CAAC;;aAG3C,IAAA,CAAK,KAAA,GAAQ;;;;;;IAejB,KAAK,QAAA,EAA0E;QAC7E,IAAI,CAAC,YAAY,OAAO,aAAa,YAAY,SAAS,IAAA,EAAM,KAAK,GACnE,CAAA,MAAM,IAAI,MAAM,8DAA8D;QAIhF,OAAO,IAAI,sBADC,IAAI,IAAI,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,UAAA,CAAW,EACR;YACpC,SAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;YAClC,QAAQ,IAAA,CAAK,UAAA;YACb,OAAO,IAAA,CAAK,KAAA;YACZ,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;IAUJ,OACE,MAAA,EAMA;QACA,OAAO,IAAI,gBAAgB,IAAA,CAAK,GAAA,EAAK;YACnC,SAAS,IAAA,CAAK,OAAA;YACd;YACA,OAAO,IAAA,CAAK,KAAA;YACZ,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAmCJ,IASE,EAAA,EACA,OAAa,CAAA,CAAE,EACf,EACE,OAAO,KAAA,EACP,MAAM,KAAA,EACN,KAAA,EAAA,GAKE,CAAA,CAAE,EASN;;QACA,IAAIC;QACJ,MAAM,MAAM,IAAI,IAAI,GAAG,IAAA,CAAK,GAAA,CAAI,KAAA,EAAO,IAAA,CAAK;QAC5C,IAAIC;QAEJ,MAAM,YAAA,CAAa,IACjB,MAAM,QAAQ,OAAO,MAAM,YAAA,CAAa,CAAC,MAAM,OAAA,CAAQ,EAAE,IAAI,EAAE,IAAA,CAAK,UAAU;QAChF,MAAM,gBAAgB,QAAQ,OAAO,MAAA,CAAO,KAAe,CAAC,IAAA,CAAK,UAAU;QAC3E,IAAI,eAAe;YACjB,SAAS;YACT,OAAO;mBACE,QAAQ,KAAK;YACtB,SAAS,OAAO,SAAS;YACzB,OAAO,OAAA,CAAQ,KAAK,CAGjB,MAAA,CAAA,CAAQ,CAAC,GAAG,MAAA,GAAW,UAAU,KAAA,EAAU,CAE3C,GAAA,CAAA,CAAK,CAAC,MAAM,MAAA,GAAW;oBAAC;oBAAM,MAAM,OAAA,CAAQ,MAAM,GAAG,CAAA,CAAA,EAAI,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,GAAK,GAAG,OAAA;iBAAQ,CAAC,CAC1F,OAAA,CAAA,CAAS,CAAC,MAAM,MAAA,KAAW;gBAC1B,IAAI,YAAA,CAAa,MAAA,CAAO,MAAM,MAAM;cACpC;eACC;YACL,SAAS;YACT,OAAO;;QAGT,MAAM,UAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;QACzC,IAAI,cACF,CAAA,QAAQ,GAAA,CAAI,UAAU,QAAQ,CAAA,MAAA,EAAS,MAAM,eAAA,CAAA,GAAmB,iBAAiB;iBACxE,MACT,CAAA,QAAQ,GAAA,CAAI,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAGzC,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,UAAA;YACb;YACA,OAAA,CAAA,cAAO,IAAA,CAAK,KAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAS;YACrB,gBAAgB,IAAA,CAAK,cAAA;SACtB,CAAC;;;;;ACvQN,IAAA,cAAe;IACb;IACA;IACA;IACA;IACA;IACA;CACD"}},
    {"offset": {"line": 2213, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/dist/index.mjs","sources":["turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/errors/IcebergError.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/utils/url.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/http/createFetchClient.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/catalog/namespaces.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/catalog/tables.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/catalog/IcebergRestCatalog.ts","turbopack:///[project]/node_modules/.bun/iceberg-js@0.8.1/node_modules/iceberg-js/src/catalog/types.ts"],"sourcesContent":["export interface IcebergErrorResponse {\n  error: {\n    message: string\n    type: string\n    code: number\n    stack?: string[]\n  }\n}\n\nexport class IcebergError extends Error {\n  readonly status: number\n  readonly icebergType?: string\n  readonly icebergCode?: number\n  readonly details?: unknown\n  readonly isCommitStateUnknown: boolean\n\n  constructor(\n    message: string,\n    opts: {\n      status: number\n      icebergType?: string\n      icebergCode?: number\n      details?: unknown\n    }\n  ) {\n    super(message)\n    this.name = 'IcebergError'\n    this.status = opts.status\n    this.icebergType = opts.icebergType\n    this.icebergCode = opts.icebergCode\n    this.details = opts.details\n\n    // Detect CommitStateUnknownException (500, 502, 504 during table commits)\n    this.isCommitStateUnknown =\n      opts.icebergType === 'CommitStateUnknownException' ||\n      ([500, 502, 504].includes(opts.status) && opts.icebergType?.includes('CommitState') === true)\n  }\n\n  /**\n   * Returns true if the error is a 404 Not Found error.\n   */\n  isNotFound(): boolean {\n    return this.status === 404\n  }\n\n  /**\n   * Returns true if the error is a 409 Conflict error.\n   */\n  isConflict(): boolean {\n    return this.status === 409\n  }\n\n  /**\n   * Returns true if the error is a 419 Authentication Timeout error.\n   */\n  isAuthenticationTimeout(): boolean {\n    return this.status === 419\n  }\n}\n","export function buildUrl(\n  baseUrl: string,\n  path: string,\n  query?: Record<string, string | undefined>\n): string {\n  const url = new URL(path, baseUrl)\n\n  if (query) {\n    for (const [key, value] of Object.entries(query)) {\n      if (value !== undefined) {\n        url.searchParams.set(key, value)\n      }\n    }\n  }\n\n  return url.toString()\n}\n","import { IcebergError, type IcebergErrorResponse } from '../errors/IcebergError'\nimport { buildUrl } from '../utils/url'\nimport type { AuthConfig, HttpClient, HttpRequest, HttpResponse } from './types'\n\nasync function buildAuthHeaders(auth?: AuthConfig): Promise<Record<string, string>> {\n  if (!auth || auth.type === 'none') {\n    return {}\n  }\n\n  if (auth.type === 'bearer') {\n    return { Authorization: `Bearer ${auth.token}` }\n  }\n\n  if (auth.type === 'header') {\n    return { [auth.name]: auth.value }\n  }\n\n  if (auth.type === 'custom') {\n    return await auth.getHeaders()\n  }\n\n  return {}\n}\n\nexport function createFetchClient(options: {\n  baseUrl: string\n  auth?: AuthConfig\n  fetchImpl?: typeof fetch\n}): HttpClient {\n  const fetchFn = options.fetchImpl ?? globalThis.fetch\n\n  return {\n    async request<T>({\n      method,\n      path,\n      query,\n      body,\n      headers,\n    }: HttpRequest): Promise<HttpResponse<T>> {\n      const url = buildUrl(options.baseUrl, path, query)\n      const authHeaders = await buildAuthHeaders(options.auth)\n\n      const res = await fetchFn(url, {\n        method,\n        headers: {\n          ...(body ? { 'Content-Type': 'application/json' } : {}),\n          ...authHeaders,\n          ...headers,\n        },\n        body: body ? JSON.stringify(body) : undefined,\n      })\n\n      const text = await res.text()\n      const isJson = (res.headers.get('content-type') || '').includes('application/json')\n      const data = isJson && text ? (JSON.parse(text) as T) : (text as T)\n\n      if (!res.ok) {\n        const errBody = isJson ? (data as IcebergErrorResponse) : undefined\n        const errorDetail = errBody?.error\n        throw new IcebergError(\n          errorDetail?.message ?? `Request failed with status ${res.status}`,\n          {\n            status: res.status,\n            icebergType: errorDetail?.type,\n            icebergCode: errorDetail?.code,\n            details: errBody,\n          }\n        )\n      }\n\n      return { status: res.status, headers: res.headers, data: data as T }\n    },\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateNamespaceRequest,\n  CreateNamespaceResponse,\n  GetNamespaceResponse,\n  ListNamespacesResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class NamespaceOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = ''\n  ) {}\n\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    const query = parent ? { parent: namespaceToPath(parent.namespace) } : undefined\n\n    const response = await this.client.request<ListNamespacesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces`,\n      query,\n    })\n\n    return response.data.namespaces.map((ns) => ({ namespace: ns }))\n  }\n\n  async createNamespace(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse> {\n    const request: CreateNamespaceRequest = {\n      namespace: id.namespace,\n      properties: metadata?.properties,\n    }\n\n    const response = await this.client.request<CreateNamespaceResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces`,\n      body: request,\n    })\n\n    return response.data\n  }\n\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n  }\n\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    const response = await this.client.request<GetNamespaceResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n\n    return {\n      properties: response.data.properties,\n    }\n  }\n\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    try {\n      return await this.createNamespace(id, metadata)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return\n      }\n      throw error\n    }\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateTableRequest,\n  CommitTableResponse,\n  ListTablesResponse,\n  LoadTableResponse,\n  NamespaceIdentifier,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class TableOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = '',\n    private readonly accessDelegation?: string\n  ) {}\n\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    const response = await this.client.request<ListTablesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n    })\n\n    return response.data.identifiers\n  }\n\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n      body: request,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      body: request,\n    })\n\n    return {\n      'metadata-location': response.data['metadata-location'],\n      metadata: response.data.metadata,\n    }\n  }\n\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      query: { purgeRequested: String(options?.purge ?? false) },\n    })\n  }\n\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n        headers,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    try {\n      return await this.createTable(namespace, request)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return await this.loadTable({ namespace: namespace.namespace, name: request.name })\n      }\n      throw error\n    }\n  }\n}\n","import { createFetchClient } from '../http/createFetchClient'\nimport type { AuthConfig, HttpClient } from '../http/types'\nimport { NamespaceOperations } from './namespaces'\nimport { TableOperations } from './tables'\nimport type {\n  CreateTableRequest,\n  CreateNamespaceResponse,\n  CommitTableResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\n/**\n * Access delegation mechanisms supported by the Iceberg REST Catalog.\n *\n * - `vended-credentials`: Server provides temporary credentials for data access\n * - `remote-signing`: Server signs requests on behalf of the client\n */\nexport type AccessDelegation = 'vended-credentials' | 'remote-signing'\n\n/**\n * Configuration options for the Iceberg REST Catalog client.\n */\nexport interface IcebergRestCatalogOptions {\n  /** Base URL of the Iceberg REST Catalog API */\n  baseUrl: string\n  /** Optional catalog name prefix for multi-catalog servers */\n  catalogName?: string\n  /** Authentication configuration */\n  auth?: AuthConfig\n  /** Custom fetch implementation (defaults to globalThis.fetch) */\n  fetch?: typeof fetch\n  /**\n   * Access delegation mechanisms to request from the server.\n   * When specified, the X-Iceberg-Access-Delegation header will be sent\n   * with supported operations (createTable, loadTable).\n   *\n   * @example ['vended-credentials']\n   * @example ['vended-credentials', 'remote-signing']\n   */\n  accessDelegation?: AccessDelegation[]\n}\n\n/**\n * Client for interacting with an Apache Iceberg REST Catalog.\n *\n * This class provides methods for managing namespaces and tables in an Iceberg catalog.\n * It handles authentication, request formatting, and error handling automatically.\n *\n * @example\n * ```typescript\n * const catalog = new IcebergRestCatalog({\n *   baseUrl: 'https://my-catalog.example.com/iceberg/v1',\n *   auth: { type: 'bearer', token: process.env.ICEBERG_TOKEN }\n * });\n *\n * // Create a namespace\n * await catalog.createNamespace({ namespace: ['analytics'] });\n *\n * // Create a table\n * await catalog.createTable(\n *   { namespace: ['analytics'] },\n *   {\n *     name: 'events',\n *     schema: { type: 'struct', fields: [...] }\n *   }\n * );\n * ```\n */\nexport class IcebergRestCatalog {\n  private readonly client: HttpClient\n  private readonly namespaceOps: NamespaceOperations\n  private readonly tableOps: TableOperations\n  private readonly accessDelegation?: string\n\n  /**\n   * Creates a new Iceberg REST Catalog client.\n   *\n   * @param options - Configuration options for the catalog client\n   */\n  constructor(options: IcebergRestCatalogOptions) {\n    let prefix = 'v1'\n    if (options.catalogName) {\n      prefix += `/${options.catalogName}`\n    }\n\n    const baseUrl = options.baseUrl.endsWith('/') ? options.baseUrl : `${options.baseUrl}/`\n\n    this.client = createFetchClient({\n      baseUrl,\n      auth: options.auth,\n      fetchImpl: options.fetch,\n    })\n\n    // Format accessDelegation as comma-separated string per spec\n    this.accessDelegation = options.accessDelegation?.join(',')\n\n    this.namespaceOps = new NamespaceOperations(this.client, prefix)\n    this.tableOps = new TableOperations(this.client, prefix, this.accessDelegation)\n  }\n\n  /**\n   * Lists all namespaces in the catalog.\n   *\n   * @param parent - Optional parent namespace to list children under\n   * @returns Array of namespace identifiers\n   *\n   * @example\n   * ```typescript\n   * // List all top-level namespaces\n   * const namespaces = await catalog.listNamespaces();\n   *\n   * // List namespaces under a parent\n   * const children = await catalog.listNamespaces({ namespace: ['analytics'] });\n   * ```\n   */\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    return this.namespaceOps.listNamespaces(parent)\n  }\n\n  /**\n   * Creates a new namespace in the catalog.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespace(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * console.log(response.namespace); // ['analytics']\n   * console.log(response.properties); // { owner: 'data-team', ... }\n   * ```\n   */\n  async createNamespace(id: NamespaceIdentifier, metadata?: NamespaceMetadata): Promise<CreateNamespaceResponse> {\n    return this.namespaceOps.createNamespace(id, metadata)\n  }\n\n  /**\n   * Drops a namespace from the catalog.\n   *\n   * The namespace must be empty (contain no tables) before it can be dropped.\n   *\n   * @param id - Namespace identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropNamespace({ namespace: ['analytics'] });\n   * ```\n   */\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.namespaceOps.dropNamespace(id)\n  }\n\n  /**\n   * Loads metadata for a namespace.\n   *\n   * @param id - Namespace identifier to load\n   * @returns Namespace metadata including properties\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadNamespaceMetadata({ namespace: ['analytics'] });\n   * console.log(metadata.properties);\n   * ```\n   */\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    return this.namespaceOps.loadNamespaceMetadata(id)\n  }\n\n  /**\n   * Lists all tables in a namespace.\n   *\n   * @param namespace - Namespace identifier to list tables from\n   * @returns Array of table identifiers\n   *\n   * @example\n   * ```typescript\n   * const tables = await catalog.listTables({ namespace: ['analytics'] });\n   * console.log(tables); // [{ namespace: ['analytics'], name: 'events' }, ...]\n   * ```\n   */\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    return this.tableOps.listTables(namespace)\n  }\n\n  /**\n   * Creates a new table in the catalog.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTable(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: [\n   *         { source_id: 2, field_id: 1000, name: 'ts_day', transform: 'day' }\n   *       ]\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTable(namespace, request)\n  }\n\n  /**\n   * Updates an existing table's metadata.\n   *\n   * Can update the schema, partition spec, or properties of a table.\n   *\n   * @param id - Table identifier to update\n   * @param request - Update request with fields to modify\n   * @returns Response containing the metadata location and updated table metadata\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.updateTable(\n   *   { namespace: ['analytics'], name: 'events' },\n   *   {\n   *     properties: { 'read.split.target-size': '134217728' }\n   *   }\n   * );\n   * console.log(response['metadata-location']); // s3://...\n   * console.log(response.metadata); // TableMetadata object\n   * ```\n   */\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    return this.tableOps.updateTable(id, request)\n  }\n\n  /**\n   * Drops a table from the catalog.\n   *\n   * @param id - Table identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropTable({ namespace: ['analytics'], name: 'events' });\n   * ```\n   */\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.tableOps.dropTable(id, options)\n  }\n\n  /**\n   * Loads metadata for a table.\n   *\n   * @param id - Table identifier to load\n   * @returns Table metadata including schema, partition spec, location, etc.\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadTable({ namespace: ['analytics'], name: 'events' });\n   * console.log(metadata.schema);\n   * console.log(metadata.location);\n   * ```\n   */\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    return this.tableOps.loadTable(id)\n  }\n\n  /**\n   * Checks if a namespace exists in the catalog.\n   *\n   * @param id - Namespace identifier to check\n   * @returns True if the namespace exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.namespaceExists({ namespace: ['analytics'] });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    return this.namespaceOps.namespaceExists(id)\n  }\n\n  /**\n   * Checks if a table exists in the catalog.\n   *\n   * @param id - Table identifier to check\n   * @returns True if the table exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.tableExists({ namespace: ['analytics'], name: 'events' });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    return this.tableOps.tableExists(id)\n  }\n\n  /**\n   * Creates a namespace if it does not exist.\n   *\n   * If the namespace already exists, returns void. If created, returns the response.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties, or void if it already exists\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespaceIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * if (response) {\n   *   console.log('Created:', response.namespace);\n   * } else {\n   *   console.log('Already exists');\n   * }\n   * ```\n   */\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    return this.namespaceOps.createNamespaceIfNotExists(id, metadata)\n  }\n\n  /**\n   * Creates a table if it does not exist.\n   *\n   * If the table already exists, returns its metadata instead.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created or existing table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTableIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTableIfNotExists(namespace, request)\n  }\n}\n","export interface NamespaceIdentifier {\n  namespace: string[]\n}\n\nexport interface NamespaceMetadata {\n  properties: Record<string, string>\n}\n\nexport interface TableIdentifier {\n  namespace: string[]\n  name: string\n}\n\n/**\n * Primitive types in Iceberg - all represented as strings.\n * Parameterized types use string format: decimal(precision,scale) and fixed[length]\n *\n * Note: The OpenAPI spec defines PrimitiveType as `type: string`, so any string is valid.\n * We include known types for autocomplete, plus a catch-all for flexibility.\n */\nexport type PrimitiveType =\n  | 'boolean'\n  | 'int'\n  | 'long'\n  | 'float'\n  | 'double'\n  | 'string'\n  | 'timestamp'\n  | 'date'\n  | 'time'\n  | 'timestamptz'\n  | 'uuid'\n  | 'binary'\n  | `decimal(${number},${number})`\n  | `fixed[${number}]`\n  | (string & {}) // catch-all for any format (e.g., \"decimal(10, 2)\" with spaces) and future types\n\n/**\n * Regex patterns for parsing parameterized types.\n * These allow flexible whitespace matching.\n */\nconst DECIMAL_REGEX = /^decimal\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)$/\nconst FIXED_REGEX = /^fixed\\s*\\[\\s*(\\d+)\\s*\\]$/\n\n/**\n * Parse a decimal type string into its components.\n * Handles any whitespace formatting (e.g., \"decimal(10,2)\", \"decimal(10, 2)\", \"decimal( 10 , 2 )\").\n *\n * @param type - The type string to parse\n * @returns Object with precision and scale, or null if not a valid decimal type\n */\nexport function parseDecimalType(type: string): { precision: number; scale: number } | null {\n  const match = type.match(DECIMAL_REGEX)\n  if (!match) return null\n  return {\n    precision: parseInt(match[1], 10),\n    scale: parseInt(match[2], 10),\n  }\n}\n\n/**\n * Parse a fixed type string into its length.\n * Handles any whitespace formatting (e.g., \"fixed[16]\", \"fixed[ 16 ]\").\n *\n * @param type - The type string to parse\n * @returns Object with length, or null if not a valid fixed type\n */\nexport function parseFixedType(type: string): { length: number } | null {\n  const match = type.match(FIXED_REGEX)\n  if (!match) return null\n  return {\n    length: parseInt(match[1], 10),\n  }\n}\n\n/**\n * Check if a type string is a decimal type.\n */\nexport function isDecimalType(type: string): boolean {\n  return DECIMAL_REGEX.test(type)\n}\n\n/**\n * Check if a type string is a fixed type.\n */\nexport function isFixedType(type: string): boolean {\n  return FIXED_REGEX.test(type)\n}\n\n/**\n * Compare two Iceberg type strings for equality, ignoring whitespace differences.\n * This is useful when comparing types from user input vs catalog responses,\n * as catalogs may normalize whitespace differently.\n *\n * @param a - First type string\n * @param b - Second type string\n * @returns true if the types are equivalent\n */\nexport function typesEqual(a: string, b: string): boolean {\n  // For decimal types, compare parsed values\n  const decimalA = parseDecimalType(a)\n  const decimalB = parseDecimalType(b)\n  if (decimalA && decimalB) {\n    return decimalA.precision === decimalB.precision && decimalA.scale === decimalB.scale\n  }\n\n  // For fixed types, compare parsed values\n  const fixedA = parseFixedType(a)\n  const fixedB = parseFixedType(b)\n  if (fixedA && fixedB) {\n    return fixedA.length === fixedB.length\n  }\n\n  // For other types, direct string comparison\n  return a === b\n}\n\n/**\n * Struct type - a nested structure containing fields.\n * Used for nested records within a field.\n */\nexport interface StructType {\n  type: 'struct'\n  fields: StructField[]\n}\n\n/**\n * List type - an array of elements.\n */\nexport interface ListType {\n  type: 'list'\n  'element-id': number\n  element: IcebergType\n  'element-required': boolean\n}\n\n/**\n * Map type - a key-value mapping.\n */\nexport interface MapType {\n  type: 'map'\n  'key-id': number\n  key: IcebergType\n  'value-id': number\n  value: IcebergType\n  'value-required': boolean\n}\n\n/**\n * Union of all Iceberg types.\n * Can be a primitive type (string) or a complex type (struct, list, map).\n */\nexport type IcebergType = PrimitiveType | StructType | ListType | MapType\n\n/**\n * Primitive type values for default values.\n * Represents the possible values for initial-default and write-default.\n */\nexport type PrimitiveTypeValue = boolean | number | string\n\n/**\n * A field within a struct (used in nested StructType).\n */\nexport interface StructField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\n/**\n * A field within a table schema (top-level).\n * Equivalent to StructField but kept for backwards compatibility.\n */\nexport interface TableField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\nexport interface TableSchema {\n  type: 'struct'\n  fields: TableField[]\n  'schema-id'?: number\n  'identifier-field-ids'?: number[]\n}\n\nexport interface PartitionField {\n  source_id: number\n  field_id: number\n  name: string\n  transform: string\n}\n\nexport interface PartitionSpec {\n  'spec-id': number\n  fields: PartitionField[]\n}\n\nexport interface SortField {\n  source_id: number\n  transform: string\n  direction: 'asc' | 'desc'\n  null_order: 'nulls-first' | 'nulls-last'\n}\n\nexport interface SortOrder {\n  'order-id': number\n  fields: SortField[]\n}\n\nexport interface CreateTableRequest {\n  name: string\n  schema: TableSchema\n  'partition-spec'?: PartitionSpec\n  'write-order'?: SortOrder\n  properties?: Record<string, string>\n  'stage-create'?: boolean\n}\n\nexport interface UpdateTableRequest {\n  schema?: TableSchema\n  'partition-spec'?: PartitionSpec\n  properties?: Record<string, string>\n}\n\nexport interface DropTableRequest {\n  purge?: boolean\n}\n\nexport interface TableMetadata {\n  name?: string\n  location: string\n  schemas: TableSchema[]\n  'current-schema-id': number\n  'partition-specs': PartitionSpec[]\n  'default-spec-id'?: number\n  'sort-orders': SortOrder[]\n  'default-sort-order-id'?: number\n  properties: Record<string, string>\n  'metadata-location'?: string\n  'current-snapshot-id'?: number\n  snapshots?: unknown[]\n  'snapshot-log'?: unknown[]\n  'metadata-log'?: unknown[]\n  refs?: Record<string, unknown>\n  'last-updated-ms'?: number\n  'last-column-id'?: number\n  'last-sequence-number'?: number\n  'table-uuid'?: string\n  'format-version'?: number\n  'last-partition-id'?: number\n}\n\nexport interface CreateNamespaceRequest {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface CreateNamespaceResponse {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface GetNamespaceResponse {\n  namespace: string[]\n  properties: Record<string, string>\n}\n\nexport interface ListNamespacesResponse {\n  namespaces: string[][]\n  'next-page-token'?: string\n}\n\nexport interface ListTablesResponse {\n  identifiers: TableIdentifier[]\n  'next-page-token'?: string\n}\n\nexport interface LoadTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n  config?: Record<string, string>\n}\n\nexport interface CommitTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n}\n\n/**\n * Gets the current (active) schema from table metadata.\n *\n * @param metadata - Table metadata containing schemas array and current-schema-id\n * @returns The current table schema, or undefined if not found\n */\nexport function getCurrentSchema(metadata: TableMetadata): TableSchema | undefined {\n  return metadata.schemas.find((s) => s['schema-id'] === metadata['current-schema-id'])\n}\n"],"names":["namespaceToPath"],"mappings":";;;;;;;;;;;;;;;;;;;AASO,IAAM,YAAA,GAAN,cAA2B,KAAA,CAAM;IAOtC,WAAA,CACE,OAAA,EACA,IAAA,CAMA;QACA,KAAA,CAAM,OAAO,CAAA;QACb,IAAA,CAAK,IAAA,GAAO,cAAA;QACZ,IAAA,CAAK,MAAA,GAAS,IAAA,CAAK,MAAA;QACnB,IAAA,CAAK,WAAA,GAAc,IAAA,CAAK,WAAA;QACxB,IAAA,CAAK,WAAA,GAAc,IAAA,CAAK,WAAA;QACxB,IAAA,CAAK,OAAA,GAAU,IAAA,CAAK,OAAA;QAGpB,IAAA,CAAK,oBAAA,GACH,IAAA,CAAK,WAAA,KAAgB,6BAAA,IACpB;YAAC;YAAK,GAAA;YAAK,GAAG;SAAA,CAAE,QAAA,CAAS,KAAK,MAAM,CAAA,IAAK,KAAK,WAAA,EAAa,QAAA,CAAS,aAAa,CAAA,KAAM,IAAA;IAC5F;IAAA;;GAAA,GAKA,UAAA,GAAsB;QACpB,OAAO,IAAA,CAAK,MAAA,KAAW,GAAA;IACzB;IAAA;;GAAA,GAKA,UAAA,GAAsB;QACpB,OAAO,IAAA,CAAK,MAAA,KAAW,GAAA;IACzB;IAAA;;GAAA,GAKA,uBAAA,GAAmC;QACjC,OAAO,IAAA,CAAK,MAAA,KAAW,GAAA;IACzB;AACF;;AC1DO,SAAS,QAAA,CACd,OAAA,EACA,IAAA,EACA,KAAA,EACQ;IACR,MAAM,GAAA,GAAM,IAAI,GAAA,CAAI,IAAA,EAAM,OAAO,CAAA;IAEjC,IAAI,KAAA,EAAO;QACT,KAAA,MAAW,CAAC,GAAA,EAAK,KAAK,CAAA,IAAK,MAAA,CAAO,OAAA,CAAQ,KAAK,CAAA,CAAG;YAChD,IAAI,UAAU,KAAA,CAAA,EAAW;gBACvB,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,GAAA,EAAK,KAAK,CAAA;YACjC;QACF;IACF;IAEA,OAAO,IAAI,QAAA,EAAS;AACtB;;ACZA,eAAe,iBAAiB,IAAA,EAAoD;IAClF,IAAI,CAAC,IAAA,IAAQ,IAAA,CAAK,IAAA,KAAS,MAAA,EAAQ;QACjC,OAAO,CAAA,CAAC;IACV;IAEA,IAAI,IAAA,CAAK,IAAA,KAAS,QAAA,EAAU;QAC1B,OAAO;YAAE,aAAA,EAAe,CAAA,OAAA,EAAU,IAAA,CAAK,KAAK,CAAA,CAAA;QAAA,CAAG;IACjD;IAEA,IAAI,IAAA,CAAK,IAAA,KAAS,QAAA,EAAU;QAC1B,OAAO;YAAE,CAAC,IAAA,CAAK,IAAI,CAAA,EAAG,KAAK,KAAA;QAAA,CAAM;IACnC;IAEA,IAAI,IAAA,CAAK,IAAA,KAAS,QAAA,EAAU;QAC1B,OAAO,MAAM,KAAK,UAAA,EAAW;IAC/B;IAEA,OAAO,CAAA,CAAC;AACV;AAEO,SAAS,kBAAkB,OAAA,EAInB;IACb,MAAM,OAAA,GAAU,OAAA,CAAQ,SAAA,IAAa,UAAA,CAAW,KAAA;IAEhD,OAAO;QACL,MAAM,OAAA,EAAW,EACf,MAAA,EACA,IAAA,EACA,KAAA,EACA,IAAA,EACA,OAAA,EACF,EAA0C;YACxC,MAAM,GAAA,GAAM,QAAA,CAAS,OAAA,CAAQ,OAAA,EAAS,MAAM,KAAK,CAAA;YACjD,MAAM,WAAA,GAAc,MAAM,gBAAA,CAAiB,OAAA,CAAQ,IAAI,CAAA;YAEvD,MAAM,GAAA,GAAM,MAAM,OAAA,CAAQ,GAAA,EAAK;gBAC7B,MAAA;gBACA,OAAA,EAAS;oBACP,GAAI,IAAA,GAAO;wBAAE,cAAA,EAAgB,kBAAA;oBAAA,IAAuB,CAAA,CAAC;oBACrD,GAAG,WAAA;oBACH,GAAG,OAAA;gBAAA,CACL;gBACA,IAAA,EAAM,IAAA,GAAO,IAAA,CAAK,SAAA,CAAU,IAAI,CAAA,GAAI,KAAA;YAAA,CACrC,CAAA;YAED,MAAM,IAAA,GAAO,MAAM,GAAA,CAAI,IAAA,EAAK;YAC5B,MAAM,MAAA,GAAA,CAAU,IAAI,OAAA,CAAQ,GAAA,CAAI,cAAc,CAAA,IAAK,EAAA,EAAI,QAAA,CAAS,kBAAkB,CAAA;YAClF,MAAM,OAAO,MAAA,IAAU,IAAA,GAAQ,IAAA,CAAK,KAAA,CAAM,IAAI,CAAA,GAAW,IAAA;YAEzD,IAAI,CAAC,IAAI,EAAA,EAAI;gBACX,MAAM,OAAA,GAAU,SAAU,IAAA,GAAgC,KAAA,CAAA;gBAC1D,MAAM,cAAc,OAAA,EAAS,KAAA;gBAC7B,MAAM,IAAI,YAAA,CACR,WAAA,EAAa,OAAA,IAAW,CAAA,2BAAA,EAA8B,GAAA,CAAI,MAAM,CAAA,CAAA,EAChE;oBACE,QAAQ,GAAA,CAAI,MAAA;oBACZ,aAAa,WAAA,EAAa,IAAA;oBAC1B,aAAa,WAAA,EAAa,IAAA;oBAC1B,OAAA,EAAS;gBAAA;YAGf;YAEA,OAAO;gBAAE,MAAA,EAAQ,GAAA,CAAI,MAAA;gBAAQ,OAAA,EAAS,GAAA,CAAI,OAAA;gBAAS,IAAA;YAAA,CAAgB;QACrE;IAAA,CACF;AACF;;AC9DA,SAAS,gBAAgB,SAAA,EAA6B;IACpD,OAAO,SAAA,CAAU,IAAA,CAAK,GAAM,CAAA;AAC9B;AAEO,IAAM,sBAAN,MAA0B;IAC/B,WAAA,CACmB,MAAA,EACA,MAAA,GAAiB,EAAA,CAClC;QAFiB,IAAA,CAAA,MAAA,GAAA,MAAA;QACA,IAAA,CAAA,MAAA,GAAA,MAAA;IAChB;IAEH,MAAM,eAAe,MAAA,EAA8D;QACjF,MAAM,KAAA,GAAQ,SAAS;YAAE,MAAA,EAAQ,gBAAgB,MAAA,CAAO,SAAS;QAAA,CAAE,GAAI,KAAA,CAAA;QAEvE,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAgC;YACjE,MAAA,EAAQ,KAAA;YACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,WAAA,CAAA;YACpB;QAAA,CACD,CAAA;QAED,OAAO,QAAA,CAAS,IAAA,CAAK,UAAA,CAAW,GAAA,CAAI,CAAC,EAAA,GAAA,CAAQ;gBAAE,SAAA,EAAW,EAAA;YAAA,CAAG,CAAE,CAAA;IACjE;IAEA,MAAM,eAAA,CACJ,EAAA,EACA,QAAA,EACkC;QAClC,MAAM,OAAA,GAAkC;YACtC,WAAW,EAAA,CAAG,SAAA;YACd,YAAY,QAAA,EAAU;QAAA,CACxB;QAEA,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAiC;YAClE,MAAA,EAAQ,MAAA;YACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,WAAA,CAAA;YACpB,IAAA,EAAM;QAAA,CACP,CAAA;QAED,OAAO,QAAA,CAAS,IAAA;IAClB;IAEA,MAAM,cAAc,EAAA,EAAwC;QAC1D,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc;YAC9B,MAAA,EAAQ,QAAA;YACR,IAAA,EAAM,GAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,eAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,CAAA;QAAA,CACjE,CAAA;IACH;IAEA,MAAM,sBAAsB,EAAA,EAAqD;QAC/E,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA8B;YAC/D,MAAA,EAAQ,KAAA;YACR,IAAA,EAAM,GAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,eAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,CAAA;QAAA,CACjE,CAAA;QAED,OAAO;YACL,UAAA,EAAY,SAAS,IAAA,CAAK,UAAA;QAAA,CAC5B;IACF;IAEA,MAAM,gBAAgB,EAAA,EAA2C;QAC/D,IAAI;YACF,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc;gBAC9B,MAAA,EAAQ,MAAA;gBACR,IAAA,EAAM,GAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,eAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,CAAA;YAAA,CACjE,CAAA;YACD,OAAO,IAAA;QACT,EAAA,OAAS,KAAA,EAAO;YACd,IAAI,KAAA,YAAiB,YAAA,IAAgB,KAAA,CAAM,MAAA,KAAW,GAAA,EAAK;gBACzD,OAAO,KAAA;YACT;YACA,MAAM,KAAA;QACR;IACF;IAEA,MAAM,0BAAA,CACJ,EAAA,EACA,QAAA,EACyC;QACzC,IAAI;YACF,OAAO,MAAM,IAAA,CAAK,eAAA,CAAgB,EAAA,EAAI,QAAQ,CAAA;QAChD,EAAA,OAAS,KAAA,EAAO;YACd,IAAI,KAAA,YAAiB,YAAA,IAAgB,KAAA,CAAM,MAAA,KAAW,GAAA,EAAK;gBACzD;YACF;YACA,MAAM,KAAA;QACR;IACF;AACF,CAAA;;ACnFA,SAASA,iBAAgB,SAAA,EAA6B;IACpD,OAAO,SAAA,CAAU,IAAA,CAAK,GAAM,CAAA;AAC9B;AAEO,IAAM,kBAAN,MAAsB;IAC3B,WAAA,CACmB,MAAA,EACA,MAAA,GAAiB,EAAA,EACjB,gBAAA,CACjB;QAHiB,IAAA,CAAA,MAAA,GAAA,MAAA;QACA,IAAA,CAAA,MAAA,GAAA,MAAA;QACA,IAAA,CAAA,gBAAA,GAAA,gBAAA;IAChB;IAEH,MAAM,WAAW,SAAA,EAA4D;QAC3E,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA4B;YAC7D,MAAA,EAAQ,KAAA;YACR,IAAA,EAAM,GAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,SAAA,CAAU,SAAS,CAAC,CAAA,OAAA,CAAA;QAAA,CACxE,CAAA;QAED,OAAO,SAAS,IAAA,CAAK,WAAA;IACvB;IAEA,MAAM,WAAA,CACJ,SAAA,EACA,OAAA,EACwB;QACxB,MAAM,UAAkC,CAAA,CAAC;QACzC,IAAI,IAAA,CAAK,gBAAA,EAAkB;YACzB,OAAA,CAAQ,6BAA6B,CAAA,GAAI,IAAA,CAAK,gBAAA;QAChD;QAEA,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B;YAC5D,MAAA,EAAQ,MAAA;YACR,IAAA,EAAM,GAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,SAAA,CAAU,SAAS,CAAC,CAAA,OAAA,CAAA;YACvE,IAAA,EAAM,OAAA;YACN;QAAA,CACD,CAAA;QAED,OAAO,SAAS,IAAA,CAAK,QAAA;IACvB;IAEA,MAAM,WAAA,CAAY,EAAA,EAAqB,OAAA,EAA2D;QAChG,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B;YAC5D,MAAA,EAAQ,MAAA;YACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,QAAA,EAAW,EAAA,CAAG,IAAI,CAAA,CAAA;YAClF,IAAA,EAAM;QAAA,CACP,CAAA;QAED,OAAO;YACL,mBAAA,EAAqB,QAAA,CAAS,IAAA,CAAK,mBAAmB,CAAA;YACtD,QAAA,EAAU,SAAS,IAAA,CAAK,QAAA;QAAA,CAC1B;IACF;IAEA,MAAM,SAAA,CAAU,EAAA,EAAqB,OAAA,EAA2C;QAC9E,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc;YAC9B,MAAA,EAAQ,QAAA;YACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,QAAA,EAAW,EAAA,CAAG,IAAI,CAAA,CAAA;YAClF,OAAO;gBAAE,cAAA,EAAgB,OAAO,OAAA,EAAS,KAAA,IAAS,KAAK,CAAA;YAAA;QAAE,CAC1D,CAAA;IACH;IAEA,MAAM,UAAU,EAAA,EAA6C;QAC3D,MAAM,UAAkC,CAAA,CAAC;QACzC,IAAI,IAAA,CAAK,gBAAA,EAAkB;YACzB,OAAA,CAAQ,6BAA6B,CAAA,GAAI,IAAA,CAAK,gBAAA;QAChD;QAEA,MAAM,QAAA,GAAW,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B;YAC5D,MAAA,EAAQ,KAAA;YACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,QAAA,EAAW,EAAA,CAAG,IAAI,CAAA,CAAA;YAClF;QAAA,CACD,CAAA;QAED,OAAO,SAAS,IAAA,CAAK,QAAA;IACvB;IAEA,MAAM,YAAY,EAAA,EAAuC;QACvD,MAAM,UAAkC,CAAA,CAAC;QACzC,IAAI,IAAA,CAAK,gBAAA,EAAkB;YACzB,OAAA,CAAQ,6BAA6B,CAAA,GAAI,IAAA,CAAK,gBAAA;QAChD;QAEA,IAAI;YACF,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc;gBAC9B,MAAA,EAAQ,MAAA;gBACR,IAAA,EAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,gBAAAA,CAAgB,EAAA,CAAG,SAAS,CAAC,CAAA,QAAA,EAAW,EAAA,CAAG,IAAI,CAAA,CAAA;gBAClF;YAAA,CACD,CAAA;YACD,OAAO,IAAA;QACT,EAAA,OAAS,KAAA,EAAO;YACd,IAAI,KAAA,YAAiB,YAAA,IAAgB,KAAA,CAAM,MAAA,KAAW,GAAA,EAAK;gBACzD,OAAO,KAAA;YACT;YACA,MAAM,KAAA;QACR;IACF;IAEA,MAAM,sBAAA,CACJ,SAAA,EACA,OAAA,EACwB;QACxB,IAAI;YACF,OAAO,MAAM,IAAA,CAAK,WAAA,CAAY,SAAA,EAAW,OAAO,CAAA;QAClD,EAAA,OAAS,KAAA,EAAO;YACd,IAAI,KAAA,YAAiB,YAAA,IAAgB,KAAA,CAAM,MAAA,KAAW,GAAA,EAAK;gBACzD,OAAO,MAAM,IAAA,CAAK,SAAA,CAAU;oBAAE,SAAA,EAAW,UAAU,SAAA;oBAAW,IAAA,EAAM,OAAA,CAAQ,IAAA;gBAAA,CAAM,CAAA;YACpF;YACA,MAAM,KAAA;QACR;IACF;AACF,CAAA;;AClDO,IAAM,qBAAN,MAAyB;IAAA;;;;GAAA,GAW9B,YAAY,OAAA,CAAoC;QAC9C,IAAI,MAAA,GAAS,IAAA;QACb,IAAI,QAAQ,WAAA,EAAa;YACvB,MAAA,IAAU,CAAA,CAAA,EAAI,QAAQ,WAAW,CAAA,CAAA;QACnC;QAEA,MAAM,OAAA,GAAU,OAAA,CAAQ,OAAA,CAAQ,QAAA,CAAS,GAAG,IAAI,OAAA,CAAQ,OAAA,GAAU,CAAA,EAAG,OAAA,CAAQ,OAAO,CAAA,CAAA,CAAA;QAEpF,IAAA,CAAK,MAAA,GAAS,iBAAA,CAAkB;YAC9B,OAAA;YACA,MAAM,OAAA,CAAQ,IAAA;YACd,WAAW,OAAA,CAAQ,KAAA;QAAA,CACpB,CAAA;QAGD,IAAA,CAAK,gBAAA,GAAmB,OAAA,CAAQ,gBAAA,EAAkB,IAAA,CAAK,GAAG,CAAA;QAE1D,IAAA,CAAK,YAAA,GAAe,IAAI,mBAAA,CAAoB,IAAA,CAAK,MAAA,EAAQ,MAAM,CAAA;QAC/D,IAAA,CAAK,QAAA,GAAW,IAAI,eAAA,CAAgB,IAAA,CAAK,MAAA,EAAQ,MAAA,EAAQ,IAAA,CAAK,gBAAgB,CAAA;IAChF;IAAA;;;;;;;;;;;;;;GAAA,GAiBA,MAAM,eAAe,MAAA,EAA8D;QACjF,OAAO,IAAA,CAAK,YAAA,CAAa,cAAA,CAAe,MAAM,CAAA;IAChD;IAAA;;;;;;;;;;;;;;;;GAAA,GAmBA,MAAM,eAAA,CAAgB,EAAA,EAAyB,QAAA,EAAgE;QAC7G,OAAO,IAAA,CAAK,YAAA,CAAa,eAAA,CAAgB,EAAA,EAAI,QAAQ,CAAA;IACvD;IAAA;;;;;;;;;;;GAAA,GAcA,MAAM,cAAc,EAAA,EAAwC;QAC1D,MAAM,IAAA,CAAK,YAAA,CAAa,aAAA,CAAc,EAAE,CAAA;IAC1C;IAAA;;;;;;;;;;;GAAA,GAcA,MAAM,sBAAsB,EAAA,EAAqD;QAC/E,OAAO,IAAA,CAAK,YAAA,CAAa,qBAAA,CAAsB,EAAE,CAAA;IACnD;IAAA;;;;;;;;;;;GAAA,GAcA,MAAM,WAAW,SAAA,EAA4D;QAC3E,OAAO,IAAA,CAAK,QAAA,CAAS,UAAA,CAAW,SAAS,CAAA;IAC3C;IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GAAA,GAiCA,MAAM,WAAA,CACJ,SAAA,EACA,OAAA,EACwB;QACxB,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,SAAA,EAAW,OAAO,CAAA;IACrD;IAAA;;;;;;;;;;;;;;;;;;;;GAAA,GAuBA,MAAM,WAAA,CAAY,EAAA,EAAqB,OAAA,EAA2D;QAChG,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAA,EAAI,OAAO,CAAA;IAC9C;IAAA;;;;;;;;;GAAA,GAYA,MAAM,SAAA,CAAU,EAAA,EAAqB,OAAA,EAA2C;QAC9E,MAAM,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,EAAA,EAAI,OAAO,CAAA;IAC3C;IAAA;;;;;;;;;;;;GAAA,GAeA,MAAM,UAAU,EAAA,EAA6C;QAC3D,OAAO,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,EAAE,CAAA;IACnC;IAAA;;;;;;;;;;;GAAA,GAcA,MAAM,gBAAgB,EAAA,EAA2C;QAC/D,OAAO,IAAA,CAAK,YAAA,CAAa,eAAA,CAAgB,EAAE,CAAA;IAC7C;IAAA;;;;;;;;;;;GAAA,GAcA,MAAM,YAAY,EAAA,EAAuC;QACvD,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAE,CAAA;IACrC;IAAA;;;;;;;;;;;;;;;;;;;;;GAAA,GAwBA,MAAM,0BAAA,CACJ,EAAA,EACA,QAAA,EACyC;QACzC,OAAO,IAAA,CAAK,YAAA,CAAa,0BAAA,CAA2B,EAAA,EAAI,QAAQ,CAAA;IAClE;IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;GAAA,GA6BA,MAAM,sBAAA,CACJ,SAAA,EACA,OAAA,EACwB;QACxB,OAAO,IAAA,CAAK,QAAA,CAAS,sBAAA,CAAuB,SAAA,EAAW,OAAO,CAAA;IAChE;AACF;;ACpVA,IAAM,aAAA,GAAgB,yCAAA;AACtB,IAAM,WAAA,GAAc,2BAAA;AASb,SAAS,iBAAiB,IAAA,EAA2D;IAC1F,MAAM,KAAA,GAAQ,IAAA,CAAK,KAAA,CAAM,aAAa,CAAA;IACtC,IAAI,CAAC,OAAO,OAAO,IAAA;IACnB,OAAO;QACL,SAAA,EAAW,QAAA,CAAS,KAAA,CAAM,CAAC,CAAA,EAAG,EAAE,CAAA;QAChC,KAAA,EAAO,QAAA,CAAS,KAAA,CAAM,CAAC,CAAA,EAAG,EAAE;IAAA,CAC9B;AACF;AASO,SAAS,eAAe,IAAA,EAAyC;IACtE,MAAM,KAAA,GAAQ,IAAA,CAAK,KAAA,CAAM,WAAW,CAAA;IACpC,IAAI,CAAC,OAAO,OAAO,IAAA;IACnB,OAAO;QACL,MAAA,EAAQ,QAAA,CAAS,KAAA,CAAM,CAAC,CAAA,EAAG,EAAE;IAAA,CAC/B;AACF;AAKO,SAAS,cAAc,IAAA,EAAuB;IACnD,OAAO,aAAA,CAAc,IAAA,CAAK,IAAI,CAAA;AAChC;AAKO,SAAS,YAAY,IAAA,EAAuB;IACjD,OAAO,WAAA,CAAY,IAAA,CAAK,IAAI,CAAA;AAC9B;AAWO,SAAS,UAAA,CAAW,CAAA,EAAW,CAAA,EAAoB;IAExD,MAAM,QAAA,GAAW,iBAAiB,CAAC,CAAA;IACnC,MAAM,QAAA,GAAW,iBAAiB,CAAC,CAAA;IACnC,IAAI,YAAY,QAAA,EAAU;QACxB,OAAO,SAAS,SAAA,KAAc,QAAA,CAAS,SAAA,IAAa,QAAA,CAAS,KAAA,KAAU,QAAA,CAAS,KAAA;IAClF;IAGA,MAAM,MAAA,GAAS,eAAe,CAAC,CAAA;IAC/B,MAAM,MAAA,GAAS,eAAe,CAAC,CAAA;IAC/B,IAAI,UAAU,MAAA,EAAQ;QACpB,OAAO,MAAA,CAAO,MAAA,KAAW,MAAA,CAAO,MAAA;IAClC;IAGA,OAAO,CAAA,KAAM,CAAA;AACf;AA4LO,SAAS,iBAAiB,QAAA,EAAkD;IACjF,OAAO,QAAA,CAAS,OAAA,CAAQ,IAAA,CAAK,CAAC,CAAA,GAAM,CAAA,CAAE,WAAW,CAAA,KAAM,QAAA,CAAS,mBAAmB,CAAC,CAAA;AACtF"}},
    {"offset": {"line": 2812, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/dist/index.mjs","sources":["turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/common/errors.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/common/helpers.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/common/fetch.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/common/BaseApiClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/StreamDownloadBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/BlobDownloadBuilder.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/StorageFileApi.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/version.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/lib/constants.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/StorageBucketApi.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/StorageAnalyticsClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/VectorIndexApi.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/VectorDataApi.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/VectorBucketApi.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/packages/StorageVectorsClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+storage-js@2.95.3/node_modules/@supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["/**\n * Namespace type for error classes\n * Determines the error class names and type guards\n */\nexport type ErrorNamespace = 'storage' | 'vectors'\n\n/**\n * Base error class for all Storage errors\n * Supports both 'storage' and 'vectors' namespaces\n */\nexport class StorageError extends Error {\n  protected __isStorageError = true\n  protected namespace: ErrorNamespace\n  status?: number\n  statusCode?: string\n\n  constructor(\n    message: string,\n    namespace: ErrorNamespace = 'storage',\n    status?: number,\n    statusCode?: string\n  ) {\n    super(message)\n    this.namespace = namespace\n    this.name = namespace === 'vectors' ? 'StorageVectorsError' : 'StorageError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageError\n * @param error - The error to check\n * @returns True if the error is a StorageError\n */\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\n/**\n * API error returned from Storage service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageApiError extends StorageError {\n  override status: number\n  override statusCode: string\n\n  constructor(\n    message: string,\n    status: number,\n    statusCode: string,\n    namespace: ErrorNamespace = 'storage'\n  ) {\n    super(message, namespace, status, statusCode)\n    this.name = namespace === 'vectors' ? 'StorageVectorsApiError' : 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown, namespace: ErrorNamespace = 'storage') {\n    super(message, namespace)\n    this.name = namespace === 'vectors' ? 'StorageVectorsUnknownError' : 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n\n// ============================================================================\n// Backward Compatibility Exports for Vectors\n// ============================================================================\n\n/**\n * @deprecated Use StorageError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsError extends StorageError {\n  constructor(message: string) {\n    super(message, 'vectors')\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return isStorageError(error) && (error as StorageError)['namespace'] === 'vectors'\n}\n\n/**\n * @deprecated Use StorageApiError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsApiError extends StorageApiError {\n  constructor(message: string, status: number, statusCode: string) {\n    super(message, status, statusCode, 'vectors')\n  }\n}\n\n/**\n * @deprecated Use StorageUnknownError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsUnknownError extends StorageUnknownError {\n  constructor(message: string, originalError: unknown) {\n    super(message, originalError, 'vectors')\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Recursively converts object keys from snake_case to camelCase\n * Used for normalizing API responses\n *\n * @param item - Object to convert\n * @returns Converted object with camelCase keys\n */\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageApiError, StorageUnknownError, ErrorNamespace } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from '../types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to Storage error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n * @param namespace - Error namespace ('storage' or 'vectors')\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options: FetchOptions | undefined,\n  namespace: ErrorNamespace\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const responseError = error as any\n    const status = responseError.status || 500\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace))\n        })\n        .catch(() => {\n          // If JSON parsing fails for vectors, create ApiError with HTTP status\n          if (namespace === 'vectors') {\n            const statusCode = status + ''\n            const message = responseError.statusText || `HTTP ${status} error`\n            reject(new StorageApiError(message, status, statusCode, namespace))\n          } else {\n            const statusCode = status + ''\n            const message = responseError.statusText || `HTTP ${status} error`\n            reject(new StorageApiError(message, status, statusCode, namespace))\n          }\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageApiError(message, status, statusCode, namespace))\n    }\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error, namespace))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || method === 'HEAD' || !body) {\n    return { ...params, ...parameters }\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @param namespace - Error namespace ('storage' or 'vectors')\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options: FetchOptions | undefined,\n  parameters: FetchParameters | undefined,\n  body: object | undefined,\n  namespace: ErrorNamespace\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n\n        // AWS S3 Vectors API returns 200 OK with content-length: 0 for successful mutations\n        // (putVectors, deleteVectors) instead of 204 or JSON response. This is AWS's design choice\n        // for performance optimization of bulk operations (up to 500 vectors per request).\n        // We handle this to prevent \"Unexpected end of JSON input\" errors when calling result.json()\n        if (namespace === 'vectors') {\n          const contentType = result.headers.get('content-type')\n          const contentLength = result.headers.get('content-length')\n\n          // Return empty object for explicitly empty responses\n          if (contentLength === '0' || result.status === 204) {\n            return {}\n          }\n\n          // Return empty object if no JSON content type\n          if (!contentType || !contentType.includes('application/json')) {\n            return {}\n          }\n        }\n\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options, namespace))\n  })\n}\n\n/**\n * Creates a fetch API with the specified namespace\n * @param namespace - Error namespace ('storage' or 'vectors')\n * @returns Object with HTTP method functions\n */\nexport function createFetchApi(namespace: ErrorNamespace = 'storage') {\n  return {\n    /**\n     * Performs a GET request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    get: async (\n      fetcher: Fetch,\n      url: string,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'GET', url, options, parameters, undefined, namespace)\n    },\n\n    /**\n     * Performs a POST request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    post: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'POST', url, options, parameters, body, namespace)\n    },\n\n    /**\n     * Performs a PUT request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    put: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'PUT', url, options, parameters, body, namespace)\n    },\n\n    /**\n     * Performs a HEAD request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with Response object (not JSON parsed)\n     */\n    head: async (\n      fetcher: Fetch,\n      url: string,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(\n        fetcher,\n        'HEAD',\n        url,\n        {\n          ...options,\n          noResolveJson: true,\n        },\n        parameters,\n        undefined,\n        namespace\n      )\n    },\n\n    /**\n     * Performs a DELETE request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    remove: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'DELETE', url, options, parameters, body, namespace)\n    },\n  }\n}\n\n// Default exports for backward compatibility with 'storage' namespace\nconst defaultApi = createFetchApi('storage')\nexport const { get, post, put, head, remove } = defaultApi\n\n// Vectors API with 'vectors' namespace for proper error handling\nexport const vectorsApi = createFetchApi('vectors')\n","import { ErrorNamespace, isStorageError, StorageError } from './errors'\nimport { Fetch } from './fetch'\nimport { resolveFetch } from './helpers'\n\n/**\n * @ignore\n * Base API client class for all Storage API classes\n * Provides common infrastructure for error handling and configuration\n *\n * @typeParam TError - The error type (StorageError or subclass)\n */\nexport default abstract class BaseApiClient<TError extends StorageError = StorageError> {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n  protected namespace: ErrorNamespace\n\n  /**\n   * Creates a new BaseApiClient instance\n   * @param url - Base URL for API requests\n   * @param headers - Default headers for API requests\n   * @param fetch - Optional custom fetch implementation\n   * @param namespace - Error namespace ('storage' or 'vectors')\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    namespace: ErrorNamespace = 'storage'\n  ) {\n    this.url = url\n    this.headers = headers\n    this.fetch = resolveFetch(fetch)\n    this.namespace = namespace\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   * When enabled, errors are thrown instead of returned in { data, error } format.\n   *\n   * @returns this - For method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Handles API operation with standardized error handling\n   * Eliminates repetitive try-catch blocks across all API methods\n   *\n   * This wrapper:\n   * 1. Executes the operation\n   * 2. Returns { data, error: null } on success\n   * 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\n   * 4. Throws error on failure (if shouldThrowOnError is true)\n   *\n   * @typeParam T - The expected data type from the operation\n   * @param operation - Async function that performs the API call\n   * @returns Promise with { data, error } tuple\n   *\n   * @example\n   * ```typescript\n   * async listBuckets() {\n   *   return this.handleOperation(async () => {\n   *     return await get(this.fetch, `${this.url}/bucket`, {\n   *       headers: this.headers,\n   *     })\n   *   })\n   * }\n   * ```\n   */\n  protected async handleOperation<T>(\n    operation: () => Promise<T>\n  ): Promise<{ data: T; error: null } | { data: null; error: TError }> {\n    try {\n      const data = await operation()\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error: error as TError }\n      }\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/common/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/common/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { StorageError, StorageUnknownError, isStorageError } from '../lib/common/errors'\nimport { get, head, post, put, remove, Fetch } from '../lib/common/fetch'\nimport { recursiveToCamel } from '../lib/common/helpers'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi extends BaseApiClient<StorageError> {\n  protected bucketId?: string\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch, 'storage')\n    this.bucketId = bucketId\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return { path: cleanPath, id: data.Id, fullPath: data.Key }\n    })\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    return this.handleOperation(async () => {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return { path: cleanPath, fullPath: data.Key }\n    })\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { signedUrl: url.toString(), path, token }\n    })\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { path: data.Key }\n    })\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      return { signedUrl }\n    })\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return data.map((datum: { signedURL: string }) => ({\n        ...datum,\n        signedUrl: datum.signedURL\n          ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n          : null,\n      }))\n    })\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   *\n   * @example Download with cache control (useful in Edge Functions)\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {}, { cache: 'no-store' })\n   * ```\n   *\n   * @example Download with abort signal\n   * ```js\n   * const controller = new AbortController()\n   * setTimeout(() => controller.abort(), 5000)\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {}, { signal: controller.signal })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options,\n    parameters?: FetchParameters\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(\n        this.fetch,\n        `${this.url}/${renderPath}/${_path}${queryString}`,\n        {\n          headers: this.headers,\n          noResolveJson: true,\n        },\n        parameters\n      )\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    return this.handleOperation(async () => {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return recursiveToCamel(data) as Camelize<FileObjectV2>\n    })\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      return await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n    })\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const body = { ...options }\n      return await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n    })\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.95.3'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, get, post, put, remove } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi extends BaseApiClient<StorageError> {\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    const finalUrl = baseUrl.href.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, ...headers }\n\n    super(finalUrl, finalHeaders, fetch, 'storage')\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      return await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n    })\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(this.fetch, `${this.url}/bucket/${id}/empty`, {}, { headers: this.headers })\n    })\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(this.fetch, `${this.url}/bucket/${id}`, {}, { headers: this.headers })\n    })\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, get, post, remove } from '../lib/common/fetch'\nimport { isValidBucketName } from '../lib/common/helpers'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient extends BaseApiClient<StorageError> {\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, ...headers }\n    super(finalUrl, finalHeaders, fetch, 'storage')\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      return await get(this.fetch, url, { headers: this.headers })\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from '../lib/types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from '../lib/types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    // Validate batch size\n    if (options.vectors.length < 1 || options.vectors.length > 500) {\n      throw new Error('Vector batch size must be between 1 and 500 items')\n    }\n\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    // Validate segment configuration\n    if (options.segmentCount !== undefined) {\n      if (options.segmentCount < 1 || options.segmentCount > 16) {\n        throw new Error('segmentCount must be between 1 and 16')\n      }\n      if (options.segmentIndex !== undefined) {\n        if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n          throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n        }\n      }\n    }\n\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    // Validate batch size\n    if (options.keys.length < 1 || options.keys.length > 500) {\n      throw new Error('Keys batch size must be between 1 and 500 items')\n    }\n\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from '../lib/types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from '../lib/common/fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from '../lib/types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/common/fetch'\nimport { StorageVectorsClient } from './packages/StorageVectorsClient'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"names":["result: Record<string, any>","params: { [k: string]: any }","fetch","this","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","this","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","this","DEFAULT_FILE_OPTIONS: FileOptions","fetch","this","headers: Record<string, string>","_queryString: string[]","params: string[]","fetch","this","params: Record<string, string>","fetch","this","fetch","this","fetch","this","fetch","this","fetch","this","fetch"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AMwoCe;;;;;;;GN9nCf,IAAa,eAAb,cAAkC,MAAM;IAMtC,YACE,OAAA,EACA,YAA4B,SAAA,EAC5B,MAAA,EACA,UAAA,CACA;QACA,KAAA,CAAM,QAAQ;aAXN,gBAAA,GAAmB;QAY3B,IAAA,CAAK,SAAA,GAAY;QACjB,IAAA,CAAK,IAAA,GAAO,cAAc,YAAY,wBAAwB;QAC9D,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,UAAA,GAAa;;;;;;;GAStB,SAAgB,eAAe,KAAA,EAAuC;IACpE,OAAO,OAAO,UAAU,YAAY,UAAU,QAAQ,sBAAsB;;;;;GAO9E,IAAa,kBAAb,cAAqC,aAAa;IAIhD,YACE,OAAA,EACA,MAAA,EACA,UAAA,EACA,YAA4B,SAAA,CAC5B;QACA,KAAA,CAAM,SAAS,WAAW,QAAQ,WAAW;QAC7C,IAAA,CAAK,IAAA,GAAO,cAAc,YAAY,2BAA2B;QACjE,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,UAAA,GAAa;;IAGpB,SAAS;QACP,OAAO;YACL,MAAM,IAAA,CAAK,IAAA;YACX,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,YAAY,IAAA,CAAK,UAAA;SAClB;;;;;;GAQL,IAAa,sBAAb,cAAyC,aAAa;IAGpD,YAAY,OAAA,EAAiB,aAAA,EAAwB,YAA4B,SAAA,CAAW;QAC1F,KAAA,CAAM,SAAS,UAAU;QACzB,IAAA,CAAK,IAAA,GAAO,cAAc,YAAY,+BAA+B;QACrE,IAAA,CAAK,aAAA,GAAgB;;;;;;GAYzB,IAAa,sBAAb,cAAyC,aAAa;IACpD,YAAY,OAAA,CAAiB;QAC3B,KAAA,CAAM,SAAS,UAAU;;;;;;;GAS7B,SAAgB,sBAAsB,KAAA,EAA8C;IAClF,OAAO,eAAe,MAAM,IAAK,KAAA,CAAuB,YAAA,KAAiB;;;;;GAO3E,IAAa,yBAAb,cAA4C,gBAAgB;IAC1D,YAAY,OAAA,EAAiB,MAAA,EAAgB,UAAA,CAAoB;QAC/D,KAAA,CAAM,SAAS,QAAQ,YAAY,UAAU;;;;;;GAQjD,IAAa,6BAAb,cAAgD,oBAAoB;IAClE,YAAY,OAAA,EAAiB,aAAA,CAAwB;QACnD,KAAA,CAAM,SAAS,eAAe,UAAU;;;;;;GAQ5C,IAAY,0BAAA,aAAA,GAAA,SAAA,yBAAA,EAAL;4CAEL,yBAAA,CAAA,gBAAA,GAAA;yDAEA,yBAAA,CAAA,4BAAA,GAAA;yCAEA,yBAAA,CAAA,4BAAA,GAAA;oDAEA,yBAAA,CAAA,yBAAA,GAAA;iDAEA,yBAAA,CAAA,6BAAA,GAAA;gDAEA,yBAAA,CAAA,6BAAA,GAAA;;;;;;;;;;;GCrIF,MAAa,eAAA,CAAgB,gBAA+B;IAC1D,IAAI,YACF,CAAA,OAAA,CAAQ,GAAG,OAAS,YAAY,GAAG,KAAK;IAE1C,OAAA,CAAQ,GAAG,OAAS,MAAM,GAAG,KAAK;;;;;;;;;GAqBpC,MAAa,gBAAA,CAAiB,UAA2B;IACvD,IAAI,OAAO,UAAU,YAAY,UAAU,KACzC,CAAA,OAAO;IAGT,MAAM,YAAY,OAAO,cAAA,CAAe,MAAM;IAC9C,OAAA,CACG,cAAc,QACb,cAAc,OAAO,SAAA,IACrB,OAAO,cAAA,CAAe,UAAU,KAAK,IAAA,KACvC,CAAA,CAAE,OAAO,WAAA,IAAe,KAAA,KACxB,CAAA,CAAE,OAAO,QAAA,IAAY,KAAA;;;;;;;;GAWzB,MAAa,mBAAA,CAAoB,SAAuC;IACtE,IAAI,MAAM,OAAA,CAAQ,KAAK,CACrB,CAAA,OAAO,KAAK,GAAA,CAAA,CAAK,KAAO,iBAAiB,GAAG,CAAC;aACpC,OAAO,SAAS,cAAc,SAAS,OAAO,KAAK,CAC5D,CAAA,OAAO;IAGT,MAAMA,SAA8B,CAAA,CAAE;IACtC,OAAO,OAAA,CAAQ,KAAK,CAAC,OAAA,CAAA,CAAS,CAAC,KAAK,MAAA,KAAW;QAC7C,MAAM,SAAS,IAAI,OAAA,CAAQ,iBAAA,CAAkB,IAAM,EAAE,WAAA,EAAa,CAAC,OAAA,CAAQ,SAAS,GAAG,CAAC;QACxF,MAAA,CAAO,OAAA,GAAU,iBAAiB,MAAM;MACxC;IAEF,OAAO;;;;;;;;;;;;;;;;GAkBT,MAAa,oBAAA,CAAqB,eAAgC;IAChE,IAAI,CAAC,cAAc,OAAO,eAAe,SACvC,CAAA,OAAO;IAIT,IAAI,WAAW,MAAA,KAAW,KAAK,WAAW,MAAA,GAAS,IACjD,CAAA,OAAO;IAIT,IAAI,WAAW,IAAA,EAAM,KAAK,WACxB,CAAA,OAAO;IAMT,IAAI,WAAW,QAAA,CAAS,IAAI,IAAI,WAAW,QAAA,CAAS,KAAK,CACvD,CAAA,OAAO;IAOT,OADwB,4BACD,IAAA,CAAK,WAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCtFzC,MAAM,mBAAA,CAAoB,QACxB;;eAAI,GAAA,IACJ,IAAI,OAAA,IACJ,IAAI,iBAAA,IAAA,CACH,OAAO,IAAI,KAAA,KAAU,WAAW,IAAI,KAAA,GAAA,CAAA,aAAQ,IAAI,KAAA,MAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAA,WAAO,OAAA,KACxD,KAAK,SAAA,CAAU,IAAI;;;;;;;;GASrB,MAAM,cAAc,OAClB,OACA,QACA,SACA,cACG;IAUH,IANE,SACA,OAAO,UAAU,YACjB,YAAY,SACZ,QAAQ,SACR,OAAQ,MAAc,MAAA,KAAW,YAEb,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAC,QAAS,aAAA,GAAe;QAC7C,MAAM,gBAAgB;QACtB,MAAM,SAAS,cAAc,MAAA,IAAU;QAGvC,IAAI,OAAO,cAAc,IAAA,KAAS,WAChC,CAAA,cACG,IAAA,EAAM,CACN,IAAA,CAAA,CAAM,QAAa;YAClB,MAAM,aAAA,CAAA,QAAA,QAAA,QAAA,KAAA,IAAA,KAAA,IAAa,IAAK,UAAA,KAAA,CAAA,QAAA,QAAA,QAAA,KAAA,IAAA,KAAA,IAAc,IAAK,IAAA,KAAQ,SAAS;YAC5D,OAAO,IAAI,gBAAgB,iBAAiB,IAAI,EAAE,QAAQ,YAAY,UAAU,CAAC;UACjF,CACD,KAAA,CAAA,MAAY;YAEX,IAAI,cAAc,WAAW;gBAC3B,MAAM,aAAa,SAAS;gBAE5B,OAAO,IAAI,gBADK,cAAc,UAAA,IAAc,CAAA,KAAA,EAAQ,OAAO,MAAA,CAAA,EACvB,QAAQ,YAAY,UAAU,CAAC;mBAC9D;gBACL,MAAM,aAAa,SAAS;gBAE5B,OAAO,IAAI,gBADK,cAAc,UAAA,IAAc,CAAA,KAAA,EAAQ,OAAO,MAAA,CAAA,EACvB,QAAQ,YAAY,UAAU,CAAC;;UAErE;aACC;YAEL,MAAM,aAAa,SAAS;YAE5B,OAAO,IAAI,gBADK,cAAc,UAAA,IAAc,CAAA,KAAA,EAAQ,OAAO,MAAA,CAAA,EACvB,QAAQ,YAAY,UAAU,CAAC;;UAGrE,CAAA,OAAO,IAAI,oBAAoB,iBAAiB,MAAM,EAAE,OAAO,UAAU,CAAC;;;;;;;;;GAY9E,MAAM,oBAAA,CACJ,QACA,SACA,YACA,SACG;IACH,MAAMC,SAA+B;QAAE;QAAQ,SAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAS,QAAS,OAAA,KAAW,CAAA,CAAE;KAAE;IAEhF,IAAI,WAAW,SAAS,WAAW,UAAU,CAAC,KAC5C,CAAA,OAAA,eAAA,eAAA,CAAA,GAAY,SAAW;IAGzB,IAAI,cAAc,KAAK,EAAE;QACvB,OAAO,OAAA,GAAA,eAAA;YAAY,gBAAgB;QAAA,GAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAuB,QAAS,OAAA;QACnE,OAAO,IAAA,GAAO,KAAK,SAAA,CAAU,KAAK;UAElC,CAAA,OAAO,IAAA,GAAO;IAGhB,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CACX,CAAA,OAAO,MAAA,GAAS,QAAQ,MAAA;IAG1B,OAAA,eAAA,eAAA,CAAA,GAAY,SAAW;;;;;;;;;;;;GAczB,eAAe,eACb,OAAA,EACA,MAAA,EACA,GAAA,EACA,OAAA,EACA,UAAA,EACA,IAAA,EACA,SAAA,EACc;IACd,OAAO,IAAI,QAAA,CAAS,SAAS,WAAW;QACtC,QAAQ,KAAK,kBAAkB,QAAQ,SAAS,YAAY,KAAK,CAAC,CAC/D,IAAA,CAAA,CAAM,WAAW;YAChB,IAAI,CAAC,OAAO,EAAA,CAAI,CAAA,MAAM;YACtB,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,aAAA,CAAe,CAAA,OAAO;YAMnC,IAAI,cAAc,WAAW;gBAC3B,MAAM,cAAc,OAAO,OAAA,CAAQ,GAAA,CAAI,eAAe;gBAItD,IAHsB,OAAO,OAAA,CAAQ,GAAA,CAAI,iBAAiB,KAGpC,OAAO,OAAO,MAAA,KAAW,IAC7C,CAAA,OAAO,CAAA,CAAE;gBAIX,IAAI,CAAC,eAAe,CAAC,YAAY,QAAA,CAAS,mBAAmB,CAC3D,CAAA,OAAO,CAAA,CAAE;;YAIb,OAAO,OAAO,IAAA,EAAM;UACpB,CACD,IAAA,CAAA,CAAM,OAAS,QAAQ,KAAK,CAAC,CAC7B,KAAA,CAAA,CAAO,QAAU,YAAY,OAAO,QAAQ,SAAS,UAAU,CAAC;MACnE;;;;;;GAQJ,SAAgB,eAAe,YAA4B,SAAA,EAAW;IACpE,OAAO;QASL,KAAK,OACH,SACA,KACA,SACA,eACiB;YACjB,OAAO,eAAe,SAAS,OAAO,KAAK,SAAS,YAAY,KAAA,GAAW,UAAU;;QAYvF,MAAM,OACJ,SACA,KACA,MACA,SACA,eACiB;YACjB,OAAO,eAAe,SAAS,QAAQ,KAAK,SAAS,YAAY,MAAM,UAAU;;QAYnF,KAAK,OACH,SACA,KACA,MACA,SACA,eACiB;YACjB,OAAO,eAAe,SAAS,OAAO,KAAK,SAAS,YAAY,MAAM,UAAU;;QAWlF,MAAM,OACJ,SACA,KACA,SACA,eACiB;YACjB,OAAO,eACL,SACA,QACA,KAAA,eAAA,eAAA,CAAA,GAEK,UAAA,CAAA,GAAA;gBACH,eAAe;YAAA,IAEjB,YACA,KAAA,GACA,UACD;;QAYH,QAAQ,OACN,SACA,KACA,MACA,SACA,eACiB;YACjB,OAAO,eAAe,SAAS,UAAU,KAAK,SAAS,YAAY,MAAM,UAAU;;KAEtF;;AAIH,MAAM,aAAa,eAAe,UAAU;AAC5C,MAAa,EAAE,GAAA,EAAK,IAAA,EAAM,GAAA,EAAK,IAAA,EAAM,MAAA,EAAA,GAAW;AAGhD,MAAa,aAAa,eAAe,UAAU;;;;;;;;;GC1RnD,IAA8B,gBAA9B,MAAwF;;;;;;;IActF,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,OAAA,EACA,YAA4B,SAAA,CAC5B;aAfQ,kBAAA,GAAqB;QAgB7B,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,KAAA,GAAQ,aAAaC,QAAM;QAChC,IAAA,CAAK,SAAA,GAAY;;;;;;;IASZ,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BT,MAAgB,gBACd,SAAA,EACmE;;QACnE,IAAI;YAEF,OAAO;gBAAE,MADI,MAAM,WAAW;gBACf,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIC,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAa;aAAiB;YAE/C,MAAM;;;;;;ACnFZ,IAAqB,wBAArB,MAAkG;IAChG,YACUC,UAAAA,EACAC,kBAAAA,CACR;QAFQ,IAAA,CAAA,UAAA,GAAA;QACA,IAAA,CAAA,kBAAA,GAAA;;IAGV,KACE,WAAA,EAGA,UAAA,EAC8B;QAC9B,OAAO,IAAA,CAAK,OAAA,EAAS,CAAC,IAAA,CAAK,aAAa,WAAW;;IAGrD,MAAc,UAAmD;;QAC/D,IAAI;YAGF,OAAO;gBACL,MAAA,CAHa,MAAMC,MAAK,UAAA,EAAY,EAGvB,IAAA;gBACb,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAGR,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;sBC9BA,OAAO,WAAA;AADnB,IAAqB,sBAArB,MAAkF;IAIhF,YACUC,UAAAA,EACAC,kBAAAA,CACR;QAFQ,IAAA,CAAA,UAAA,GAAA;QACA,IAAA,CAAA,kBAAA,GAAA;oCAL8B;aAChC,OAAA,GAAgD;;IAOxD,WAAkC;QAChC,OAAO,IAAI,sBAAsB,IAAA,CAAK,UAAA,EAAY,IAAA,CAAK,kBAAA,CAAmB;;IAG5E,KACE,WAAA,EACA,UAAA,EAC8B;QAC9B,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,IAAA,CAAK,aAAa,WAAW;;IAGxD,MACE,UAAA,EACyC;QACzC,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,KAAA,CAAM,WAAW;;IAG5C,QAAQ,SAAA,EAAgE;QACtE,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,OAAA,CAAQ,UAAU;;IAGrC,aAA4C;QAClD,IAAI,CAAC,IAAA,CAAK,OAAA,CACR,CAAA,IAAA,CAAK,OAAA,GAAU,IAAA,CAAK,OAAA,EAAS;QAE/B,OAAO,IAAA,CAAK,OAAA;;IAGd,MAAc,UAAyC;;QACrD,IAAI;YAGF,OAAO;gBACL,MAAM,MAAA,CAHO,MAAMC,MAAK,UAAA,EAAY,EAGjB,IAAA,EAAM;gBACzB,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAGR,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;ACxCZ,MAAM,yBAAyB;IAC7B,OAAO;IACP,QAAQ;IACR,QAAQ;QACN,QAAQ;QACR,OAAO;KACR;CACF;AAED,MAAMC,uBAAoC;IACxC,cAAc;IACd,aAAa;IACb,QAAQ;CACT;AAcD,IAAqB,iBAArB,cAA4C,cAA4B;IAGtE,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,QAAA,EACA,OAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASC,SAAO,UAAU;QACrC,IAAA,CAAK,QAAA,GAAW;;;;;;;;IAUlB,MAAc,eACZ,MAAA,EACA,IAAA,EACA,QAAA,EACA,WAAA,EAUA;;QACA,OAAOC,MAAK,eAAA,CAAgB,YAAY;YACtC,IAAI;YACJ,MAAM,UAAA,eAAA,eAAA,CAAA,GAAe,uBAAyB;YAC9C,IAAIC,UAAAA,eAAAA,eAAAA,CAAAA,GACCD,MAAK,OAAA,GACJ,WAAW,UAAU;gBAAE,YAAY,OAAO,QAAQ,MAAA,CAAkB;YAAA,CAAE;YAG5E,MAAM,WAAW,QAAQ,QAAA;YAEzB,IAAI,OAAO,SAAS,eAAe,oBAAoB,MAAM;gBAC3D,OAAO,IAAI,UAAU;gBACrB,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAC3D,IAAI,SACF,CAAA,KAAK,MAAA,CAAO,YAAYA,MAAK,cAAA,CAAe,SAAS,CAAC;gBAExD,KAAK,MAAA,CAAO,IAAI,SAAS;uBAChB,OAAO,aAAa,eAAe,oBAAoB,UAAU;gBAC1E,OAAO;gBAEP,IAAI,CAAC,KAAK,GAAA,CAAI,eAAe,CAC3B,CAAA,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAE7D,IAAI,YAAY,CAAC,KAAK,GAAA,CAAI,WAAW,CACnC,CAAA,KAAK,MAAA,CAAO,YAAYA,MAAK,cAAA,CAAe,SAAS,CAAC;mBAEnD;gBACL,OAAO;gBACP,OAAA,CAAQ,gBAAA,GAAmB,CAAA,QAAA,EAAW,QAAQ,YAAA,EAAA;gBAC9C,OAAA,CAAQ,eAAA,GAAkB,QAAQ,WAAA;gBAElC,IAAI,SACF,CAAA,OAAA,CAAQ,aAAA,GAAgBA,MAAK,QAAA,CAASA,MAAK,cAAA,CAAe,SAAS,CAAC;gBAStE,IAAA,CAHG,OAAO,mBAAmB,eAAe,gBAAgB,kBACzD,QAAQ,OAAO,SAAS,YAAY,UAAU,QAAQ,OAAO,KAAK,IAAA,KAAS,UAAA,KAE9D,CAAC,QAAQ,MAAA,CACvB,CAAA,QAAQ,MAAA,GAAS;;YAIrB,IAAA,gBAAA,QAAA,gBAAA,KAAA,IAAA,KAAA,IAAI,YAAa,OAAA,CACf,CAAA,UAAA,eAAA,eAAA,CAAA,GAAe,UAAY,YAAY,OAAA;YAGzC,MAAM,YAAYA,MAAK,mBAAA,CAAoB,KAAK;YAChD,MAAM,QAAQA,MAAK,aAAA,CAAc,UAAU;YAC3C,MAAM,OAAO,MAAA,CAAO,UAAU,QAAQ,MAAM,IAAA,EAC1CA,MAAK,KAAA,EACL,GAAGA,MAAK,GAAA,CAAI,QAAA,EAAU,OAAA,EACtB,MAAA,eAAA;gBACE;YAAA,GAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAa,QAAS,MAAA,IAAS;gBAAE,QAAQ,QAAQ,MAAA;YAAA,CAAQ,GAAG,CAAA,CAAE,EACjE;YAED,OAAO;gBAAE,MAAM;gBAAW,IAAI,KAAK,EAAA;gBAAI,UAAU,KAAK,GAAA;aAAK;UAC3D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA+CJ,MAAM,OACJ,IAAA,EACA,QAAA,EACA,WAAA,EAUA;QACA,OAAA,IAAA,CAAY,cAAA,CAAe,QAAQ,MAAM,UAAU,YAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkCjE,MAAM,kBACJ,IAAA,EACA,KAAA,EACA,QAAA,EACA,WAAA,EACA;;QACA,MAAM,YAAYA,OAAK,mBAAA,CAAoB,KAAK;QAChD,MAAM,QAAQA,OAAK,aAAA,CAAc,UAAU;QAE3C,MAAM,MAAM,IAAI,IAAIA,OAAK,GAAA,GAAM,CAAA,oBAAA,EAAuB,OAAA,CAAQ;QAC9D,IAAI,YAAA,CAAa,GAAA,CAAI,SAAS,MAAM;QAEpC,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,IAAI;YACJ,MAAM,UAAA,eAAA;gBAAY,QAAQ,qBAAqB,MAAA;YAAA,GAAW;YAC1D,MAAMC,UAAAA,eAAAA,eAAAA,CAAAA,GACDD,OAAK,OAAA,GACL;gBAAE,YAAY,OAAO,QAAQ,MAAA,CAAkB;YAAA,CAAE;YAGtD,IAAI,OAAO,SAAS,eAAe,oBAAoB,MAAM;gBAC3D,OAAO,IAAI,UAAU;gBACrB,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAC3D,KAAK,MAAA,CAAO,IAAI,SAAS;uBAChB,OAAO,aAAa,eAAe,oBAAoB,UAAU;gBAC1E,OAAO;gBACP,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;mBACtD;gBACL,OAAO;gBACP,OAAA,CAAQ,gBAAA,GAAmB,CAAA,QAAA,EAAW,QAAQ,YAAA,EAAA;gBAC9C,OAAA,CAAQ,eAAA,GAAkB,QAAQ,WAAA;;YAKpC,OAAO;gBAAE,MAAM;gBAAW,UAAA,CAFb,MAAM,IAAIA,OAAK,KAAA,EAAO,IAAI,QAAA,EAAU,EAAE,MAAgB;oBAAE;gBAAA,CAAS,CAAC,EAEtC,GAAA;aAAK;UAC9C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAiCJ,MAAM,sBACJ,IAAA,EACA,OAAA,EAUA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,IAAI,QAAQA,OAAK,aAAA,CAAc,KAAK;YAEpC,MAAM,UAAA,eAAA,CAAA,GAAeA,OAAK,OAAA;YAE1B,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CACX,CAAA,OAAA,CAAQ,WAAA,GAAc;YAGxB,MAAM,OAAO,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,oBAAA,EAAsB,OAAA,EAClC,CAAA,CAAE,EACF;gBAAE;YAAA,CAAS,CACZ;YAED,MAAM,MAAM,IAAI,IAAIA,OAAK,GAAA,GAAM,KAAK,GAAA,CAAI;YAExC,MAAM,QAAQ,IAAI,YAAA,CAAa,GAAA,CAAI,QAAQ;YAE3C,IAAI,CAAC,MACH,CAAA,MAAM,IAAI,aAAa,2BAA2B;YAGpD,OAAO;gBAAE,WAAW,IAAI,QAAA,EAAU;gBAAE;gBAAM;aAAO;UACjD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA+CJ,MAAM,OACJ,IAAA,EACA,QAAA,EAWA,WAAA,EAUA;QACA,OAAA,IAAA,CAAY,cAAA,CAAe,OAAO,MAAM,UAAU,YAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8BhE,MAAM,KACJ,QAAA,EACA,MAAA,EACA,OAAA,EAUA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,KACXA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;gBACE,UAAUA,OAAK,QAAA;gBACf,WAAW;gBACX,gBAAgB;gBAChB,mBAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAmB,QAAS,iBAAA;aAC7B,EACD;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8BJ,MAAM,KACJ,QAAA,EACA,MAAA,EACA,OAAA,EAUA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YAYtC,OAAO;gBAAE,MAAA,CAXI,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;oBACE,UAAUA,OAAK,QAAA;oBACf,WAAW;oBACX,gBAAgB;oBAChB,mBAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAmB,QAAS,iBAAA;iBAC7B,EACD;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B,EACmB,GAAA;YAAA,CAAK;UACzB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAsDJ,MAAM,gBACJ,IAAA,EACA,SAAA,EACA,OAAA,EAUA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,IAAI,QAAQA,OAAK,aAAA,CAAc,KAAK;YAEpC,IAAI,OAAO,MAAM,KACfA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,aAAA,EAAe,OAAA,EAAA,eAAA;gBACzB;YAAA,GAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAe,QAAS,SAAA,IAAY;gBAAE,WAAW,QAAQ,SAAA;YAAA,CAAW,GAAG,CAAA,CAAE,GAC3E;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;YACD,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,UAAA,EAAa,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACtD;YAEJ,OAAO;gBAAE,WADS,UAAU,GAAGA,OAAK,GAAA,GAAM,KAAK,SAAA,GAAY,oBAAA,CAAqB;YAAA,CAC5D;UACpB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAyCJ,MAAM,iBACJ,KAAA,EACA,SAAA,EACA,OAAA,EAUA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,MAAM,OAAO,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,aAAA,EAAeA,OAAK,QAAA,EAAA,EAChC;gBAAE;gBAAW;aAAO,EACpB;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;YAED,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,UAAA,EAAa,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACtD;YACJ,OAAO,KAAK,GAAA,CAAA,CAAK,QAAA,eAAA,eAAA,CAAA,GACZ,QAAA,CAAA,GAAA;oBACH,WAAW,MAAM,SAAA,GACb,UAAU,GAAGA,OAAK,GAAA,GAAM,MAAM,SAAA,GAAY,oBAAA,CAAqB,GAC/D;gBAAA,GACH;UACH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6DJ,SACE,IAAA,EACA,OAAA,EACA,UAAA,EACqB;QAErB,MAAM,aADsB,OAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAO,QAAS,SAAA,MAAc,cACjB,+BAA+B;QACxE,MAAM,sBAAsB,IAAA,CAAK,0BAAA,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAA2B,QAAS,SAAA,KAAa,CAAA,CAAE,CAAC;QACrF,MAAM,cAAc,sBAAsB,CAAA,CAAA,EAAI,qBAAA,GAAwB;QACtE,MAAM,QAAQ,IAAA,CAAK,aAAA,CAAc,KAAK;QACtC,MAAM,aAAA,IACJ,IACE,IAAA,CAAK,KAAA,EACL,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,WAAW,CAAA,EAAG,QAAQ,aAAA,EACrC;gBACE,SAAS,IAAA,CAAK,OAAA;gBACd,eAAe;aAChB,EACD,WACD;QACH,OAAO,IAAI,oBAAoB,YAAY,IAAA,CAAK,kBAAA,CAAmB;;;;;;;;;;;;;;;;IAkBrE,MAAM,KAAK,IAAA,EAST;;QACA,MAAM,QAAQA,QAAK,aAAA,CAAc,KAAK;QAEtC,OAAOA,QAAK,eAAA,CAAgB,YAAY;YAKtC,OAAO,iBAJM,MAAM,IAAIA,QAAK,KAAA,EAAO,GAAGA,QAAK,GAAA,CAAI,aAAA,EAAe,OAAA,EAAS;gBACrE,SAASA,QAAK,OAAA;YAAA,CACf,CAAC,CAE2B;UAC7B;;;;;;;;;;;;;;;;IAkBJ,MAAM,OAAO,IAAA,EASX;;QACA,MAAM,QAAQA,QAAK,aAAA,CAAc,KAAK;QAEtC,IAAI;YACF,MAAM,KAAKA,QAAK,KAAA,EAAO,GAAGA,QAAK,GAAA,CAAI,QAAA,EAAU,OAAA,EAAS;gBACpD,SAASA,QAAK,OAAA;YAAA,CACf,CAAC;YAEF,OAAO;gBAAE,MAAM;gBAAM,OAAO;aAAM;iBAC3B,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,IAAI,iBAAiB,qBAAqB;gBACjE,MAAM,gBAAgB,MAAM,aAAA;gBAE5B,IAAI;oBAAC;oBAAK;iBAAI,CAAC,QAAA,CAAA,kBAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IAAS,cAAe,MAAA,CAAO,CAC5C,CAAA,OAAO;oBAAE,MAAM;oBAAO;iBAAO;;YAIjC,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAsDV,aACE,IAAA,EACA,OAAA,EACiC;QACjC,MAAM,QAAQ,IAAA,CAAK,aAAA,CAAc,KAAK;QACtC,MAAME,eAAyB,EAAE;QAEjC,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,SAAA,EAAY,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACrD;QAEJ,IAAI,uBAAuB,GACzB,CAAA,aAAa,IAAA,CAAK,mBAAmB;QAIvC,MAAM,aADsB,OAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAO,QAAS,SAAA,MAAc,cACjB,iBAAiB;QAC1D,MAAM,sBAAsB,IAAA,CAAK,0BAAA,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAA2B,QAAS,SAAA,KAAa,CAAA,CAAE,CAAC;QAErF,IAAI,wBAAwB,GAC1B,CAAA,aAAa,IAAA,CAAK,oBAAoB;QAGxC,IAAI,cAAc,aAAa,IAAA,CAAK,IAAI;QACxC,IAAI,gBAAgB,GAClB,CAAA,cAAc,CAAA,CAAA,EAAI,aAAA;QAGpB,OAAO;YACL,MAAM;gBAAE,WAAW,UAAU,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,WAAW,QAAA,EAAU,QAAQ,aAAA,CAAc;YAAA,CAAE;QAAA,CAC1F;;;;;;;;;;;;;;;;;;;;;;;;IA0BH,MAAM,OAAO,KAAA,EASX;;QACA,OAAOF,QAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,OACXA,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,QAAA,EAAUA,QAAK,QAAA,EAAA,EAC3B;gBAAE,UAAU;YAAA,CAAO,EACnB;gBAAE,SAASA,QAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6HJ,MAAM,KACJ,IAAA,EACA,OAAA,EACA,UAAA,EAUA;;QACA,OAAOA,QAAK,eAAA,CAAgB,YAAY;YACtC,MAAM,OAAA,eAAA,eAAA,eAAA,CAAA,GAAY,yBAA2B,UAAA,CAAA,GAAA;gBAAS,QAAQ,QAAQ;YAAA;YACtE,OAAO,MAAM,KACXA,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,aAAA,EAAeA,QAAK,QAAA,EAAA,EAChC,MACA;gBAAE,SAASA,QAAK,OAAA;YAAA,CAAS,EACzB,WACD;UACD;;;;;;;;IAUJ,MAAM,OACJ,OAAA,EACA,UAAA,EAUA;;QACA,OAAOA,QAAK,eAAA,CAAgB,YAAY;YACtC,MAAM,OAAA,eAAA,CAAA,GAAY;YAClB,OAAO,MAAM,KACXA,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,gBAAA,EAAkBA,QAAK,QAAA,EAAA,EACnC,MACA;gBAAE,SAASA,QAAK,OAAA;YAAA,CAAS,EACzB,WACD;UACD;;IAGM,eAAe,QAAA,EAA+B;QACtD,OAAO,KAAK,SAAA,CAAU,SAAS;;IAGjC,SAAS,IAAA,EAAc;QACrB,IAAI,sIAAO,KAAW,YACpB,CAAA,OAAO,+HAAA,CAAO,IAAA,CAAK,KAAK,CAAC,QAAA,CAAS,SAAS;QAE7C,OAAO,KAAK,KAAK;;IAGX,cAAc,IAAA,EAAc;QAClC,OAAO,GAAG,IAAA,CAAK,QAAA,CAAS,CAAA,EAAG,KAAK,OAAA,CAAQ,QAAQ,GAAG,EAAA;;IAG7C,oBAAoB,IAAA,EAAc;QACxC,OAAO,KAAK,OAAA,CAAQ,YAAY,GAAG,CAAC,OAAA,CAAQ,QAAQ,IAAI;;IAGlD,2BAA2B,SAAA,EAA6B;QAC9D,MAAMG,SAAmB,EAAE;QAC3B,IAAI,UAAU,KAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,MAAA,EAAS,UAAU,KAAA,EAAA,CAAQ;QAGzC,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,OAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,QAAA,EAAW,UAAU,OAAA,EAAA,CAAU;QAG7C,OAAO,OAAO,IAAA,CAAK,IAAI;;;;;ACtqC3B,MAAa,UAAU;;;ACLvB,MAAa,kBAAkB;IAC7B,iBAAiB,CAAA,WAAA,EAAc,SAAA;AAAA,CAChC;;;ACID,IAAqB,mBAArB,cAA8C,cAA4B;IACxE,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,OAAA,EACA,IAAA,CACA;QACA,MAAM,UAAU,IAAI,IAAI,IAAI;QAI5B,IAAA,SAAA,QAAA,SAAA,KAAA,IAAA,KAAA,IAAI,KAAM,cAAA,EAER;gBADuB,yBAAyB,IAAA,CAAK,QAAQ,QAAA,CAAS,IAChD,CAAC,QAAQ,QAAA,CAAS,QAAA,CAAS,oBAAoB,CACnE,CAAA,QAAQ,QAAA,GAAW,QAAQ,QAAA,CAAS,OAAA,CAAQ,aAAa,oBAAoB;;QAIjF,MAAM,WAAW,QAAQ,IAAA,CAAK,OAAA,CAAQ,OAAO,GAAG;QAChD,MAAM,eAAA,eAAA,eAAA,CAAA,GAAoB,kBAAoB;QAE9C,KAAA,CAAM,UAAU,cAAcC,SAAO,UAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAmCjD,MAAM,YAAY,OAAA,EAShB;;QACA,OAAOC,MAAK,eAAA,CAAgB,YAAY;YACtC,MAAM,cAAcA,MAAK,8BAAA,CAA+B,QAAQ;YAChE,OAAO,MAAM,IAAIA,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,OAAA,EAAS,aAAA,EAAe;gBAC/D,SAASA,MAAK,OAAA;YAAA,CACf,CAAC;UACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAoCJ,MAAM,UAAU,EAAA,EASd;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,IAAIA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EAAM;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAAC;UACnF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAwCJ,MAAM,aACJ,EAAA,EACA,UAKI;QACF,QAAQ;IAAA,CACT,EAUD;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,KACXA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,OAAA,CAAA,EACZ;gBACE;gBACA,MAAM;gBACN,MAAM,QAAQ,IAAA;gBACd,QAAQ,QAAQ,MAAA;gBAChB,iBAAiB,QAAQ,aAAA;gBACzB,oBAAoB,QAAQ,gBAAA;aAC7B,EACD;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAsCJ,MAAM,aACJ,EAAA,EACA,OAAA,EAcA;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,IACXA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EACtB;gBACE;gBACA,MAAM;gBACN,QAAQ,QAAQ,MAAA;gBAChB,iBAAiB,QAAQ,aAAA;gBACzB,oBAAoB,QAAQ,gBAAA;aAC7B,EACD;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;;;;;;;;;;;;;;;;;;;;;;;;IA2BJ,MAAM,YAAY,EAAA,EAShB;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,GAAG,MAAA,CAAA,EAAS,CAAA,CAAE,EAAE;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAAC;UAC9F;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BJ,MAAM,aAAa,EAAA,EASjB;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,OAAOA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EAAM,CAAA,CAAE,EAAE;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAAC;UAC1F;;IAGI,+BAA+B,OAAA,EAAqC;QAC1E,MAAMC,SAAiC,CAAA,CAAE;QACzC,IAAI,SAAS;YACX,IAAI,WAAW,QACb,CAAA,OAAO,KAAA,GAAQ,OAAO,QAAQ,KAAA,CAAM;YAEtC,IAAI,YAAY,QACd,CAAA,OAAO,MAAA,GAAS,OAAO,QAAQ,MAAA,CAAO;YAExC,IAAI,QAAQ,MAAA,CACV,CAAA,OAAO,MAAA,GAAS,QAAQ,MAAA;YAE1B,IAAI,QAAQ,UAAA,CACV,CAAA,OAAO,UAAA,GAAa,QAAQ,UAAA;YAE9B,IAAI,QAAQ,SAAA,CACV,CAAA,OAAO,SAAA,GAAY,QAAQ,SAAA;;QAG/B,OAAO,OAAO,IAAA,CAAK,OAAO,CAAC,MAAA,GAAS,IAAI,MAAM,IAAI,gBAAgB,OAAO,CAAC,QAAA,EAAU,GAAG;;;;;;;;GC7V3F,IAAqB,yBAArB,cAAoD,cAA4B;;;;;;;;;;;;;;;;;IAkB9E,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;QAC/E,MAAM,WAAW,IAAI,OAAA,CAAQ,OAAO,GAAG;QACvC,MAAM,eAAA,eAAA,eAAA,CAAA,GAAoB,kBAAoB;QAC9C,KAAA,CAAM,UAAU,cAAcC,SAAO,UAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAqCjD,MAAM,aAAa,IAAA,EASjB;;QACA,OAAOC,MAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,KAAKA,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,OAAA,CAAA,EAAU;gBAAE;YAAA,CAAM,EAAE;gBAAE,SAASA,MAAK,OAAA;YAAA,CAAS,CAAC;UACxF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAiDJ,MAAM,YAAY,OAAA,EAehB;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YAEtC,MAAM,cAAc,IAAI,iBAAiB;YACzC,IAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,KAAA,MAAU,KAAA,EAAW,CAAA,YAAY,GAAA,CAAI,SAAS,QAAQ,KAAA,CAAM,QAAA,EAAU,CAAC;YACpF,IAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,MAAW,KAAA,EAAW,CAAA,YAAY,GAAA,CAAI,UAAU,QAAQ,MAAA,CAAO,QAAA,EAAU,CAAC;YACvF,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,UAAA,CAAY,CAAA,YAAY,GAAA,CAAI,cAAc,QAAQ,UAAA,CAAW;YAC1E,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,SAAA,CAAW,CAAA,YAAY,GAAA,CAAI,aAAa,QAAQ,SAAA,CAAU;YACvE,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CAAQ,CAAA,YAAY,GAAA,CAAI,UAAU,QAAQ,MAAA,CAAO;YAE9D,MAAM,cAAc,YAAY,QAAA,EAAU;YAC1C,MAAM,MAAM,cAAc,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,aAAA,GAAgB,GAAGA,OAAK,GAAA,CAAI,OAAA,CAAA;YAE5E,OAAO,MAAM,IAAIA,OAAK,KAAA,EAAO,KAAK;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAAC;UAC5D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkCJ,MAAM,aAAa,UAAA,EASjB;;QACA,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,OACXA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,YAAA,EACtB,CAAA,CAAE,EACF;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8HJ,KAAK,UAAA,EAA+C;;QAElD,IAAI,CAAC,kBAAkB,WAAW,CAChC,CAAA,MAAM,IAAI,aACR,qJAED;QAOH,MAAM,UAAU,IAAI,sOAAA,CAAmB;YACrC,SAAS,IAAA,CAAK,GAAA;YACd,aAAa;YACb,MAAM;gBACJ,MAAM;gBACN,YAAY,UAAYA,OAAK,OAAA;aAC9B;YACD,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;QAEF,MAAM,qBAAqB,IAAA,CAAK,kBAAA;QAuBhC,OArBuB,IAAI,MAAM,SAAS;YACxC,KAAI,MAAA,EAAQ,IAAA,EAAgC;gBAC1C,MAAM,QAAQ,MAAA,CAAO,KAAA;gBACrB,IAAI,OAAO,UAAU,WACnB,CAAA,OAAO;gBAGT,OAAO,OAAO,GAAG,SAAoB;oBACnC,IAAI;wBAEF,OAAO;4BAAE,MADI,MAAO,MAAmB,KAAA,CAAM,QAAQ,KAAK;4BAC3C,OAAO;yBAAM;6BACrB,OAAO;wBACd,IAAI,mBACF,CAAA,MAAM;wBAER,OAAO;4BAAE,MAAM;4BAAa;yBAAuB;;;;SAI1D,CAAC;;;;;;;;;GClWN,IAAqB,iBAArB,cAA4C,cAA4B;iDAEtE,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;QAC/E,MAAM,WAAW,IAAI,OAAA,CAAQ,OAAO,GAAG;QACvC,MAAM,eAAA,eAAA,eAAA,CAAA,GAAoB,kBAAA,CAAA,GAAA;YAAiB,gBAAgB;QAAA,GAAuB;QAClF,KAAA,CAAM,UAAU,cAAcC,SAAO,UAAU;;sDAIjD,MAAM,YAAY,OAAA,EAA8D;;QAC9E,OAAOC,MAAK,eAAA,CAAgB,YAAY;YAItC,OAHa,MAAM,WAAW,IAAA,CAAKA,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;gBACjF,SAASA,MAAK,OAAA;YAAA,CACf,CAAC,IACa,CAAA,CAAE;UACjB;;0DAIJ,MAAM,SACJ,gBAAA,EACA,SAAA,EAC8C;;QAC9C,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CACtBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,SAAA,CAAA,EACZ;gBAAE;gBAAkB;aAAW,EAC/B;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;uFAIJ,MAAM,YAAY,OAAA,EAAwE;;QACxF,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;gBAC3E,SAASA,OAAK,OAAA;YAAA,CACf,CAAC;UACF;;mDAIJ,MAAM,YAAY,gBAAA,EAA0B,SAAA,EAAoD;;QAC9F,OAAOA,OAAK,eAAA,CAAgB,YAAY;YAOtC,OANa,MAAM,WAAW,IAAA,CAC5BA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;gBAAE;gBAAkB;aAAW,EAC/B;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B,IACc,CAAA,CAAE;UACjB;;;;;;;;;GClEN,IAAqB,gBAArB,cAA2C,cAA4B;gDAErE,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;QAC/E,MAAM,WAAW,IAAI,OAAA,CAAQ,OAAO,GAAG;QACvC,MAAM,eAAA,eAAA,eAAA,CAAA,GAAoB,kBAAA,CAAA,GAAA;YAAiB,gBAAgB;QAAA,GAAuB;QAClF,KAAA,CAAM,UAAU,cAAcC,SAAO,UAAU;;mEAIjD,MAAM,WAAW,OAAA,EAA6D;;QAE5E,IAAI,QAAQ,OAAA,CAAQ,MAAA,GAAS,KAAK,QAAQ,OAAA,CAAQ,MAAA,GAAS,IACzD,CAAA,MAAM,IAAI,MAAM,oDAAoD;QAGtE,OAAOC,MAAK,eAAA,CAAgB,YAAY;YAItC,OAHa,MAAM,WAAW,IAAA,CAAKA,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,WAAA,CAAA,EAAc,SAAS;gBAChF,SAASA,MAAK,OAAA;YAAA,CACf,CAAC,IACa,CAAA,CAAE;UACjB;;oDAIJ,MAAM,WAAW,OAAA,EAAsE;;QACrF,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,WAAA,CAAA,EAAc,SAAS;gBAC1E,SAASA,OAAK,OAAA;YAAA,CACf,CAAC;UACF;;qDAIJ,MAAM,YAAY,OAAA,EAAwE;;QAExF,IAAI,QAAQ,YAAA,KAAiB,KAAA,GAAW;YACtC,IAAI,QAAQ,YAAA,GAAe,KAAK,QAAQ,YAAA,GAAe,GACrD,CAAA,MAAM,IAAI,MAAM,wCAAwC;YAE1D,IAAI,QAAQ,YAAA,KAAiB,KAAA,GAC3B;oBAAI,QAAQ,YAAA,GAAe,KAAK,QAAQ,YAAA,IAAgB,QAAQ,YAAA,CAC9D,CAAA,MAAM,IAAI,MAAM,CAAA,mCAAA,EAAsC,QAAQ,YAAA,GAAe,GAAA,CAAI;;;QAKvF,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;gBAC3E,SAASA,OAAK,OAAA;YAAA,CACf,CAAC;UACF;;iFAIJ,MAAM,aAAa,OAAA,EAA0E;;QAC3F,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,aAAA,CAAA,EAAgB,SAAS;gBAC5E,SAASA,OAAK,OAAA;YAAA,CACf,CAAC;UACF;;sEAIJ,MAAM,cAAc,OAAA,EAAgE;;QAElF,IAAI,QAAQ,IAAA,CAAK,MAAA,GAAS,KAAK,QAAQ,IAAA,CAAK,MAAA,GAAS,IACnD,CAAA,MAAM,IAAI,MAAM,kDAAkD;QAGpE,OAAOA,OAAK,eAAA,CAAgB,YAAY;YAItC,OAHa,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,cAAA,CAAA,EAAiB,SAAS;gBACnF,SAASA,OAAK,OAAA;YAAA,CACf,CAAC,IACa,CAAA,CAAE;UACjB;;;;;;;;;GC/EN,IAAqB,kBAArB,cAA6C,cAA4B;kDAEvE,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;QAC/E,MAAM,WAAW,IAAI,OAAA,CAAQ,OAAO,GAAG;QACvC,MAAM,eAAA,eAAA,eAAA,CAAA,GAAoB,kBAAA,CAAA,GAAA;YAAiB,gBAAgB;QAAA,GAAuB;QAClF,KAAA,CAAM,UAAU,cAAcC,SAAO,UAAU;;uCAIjD,MAAM,aAAa,gBAAA,EAA2D;;QAC5E,OAAOC,MAAK,eAAA,CAAgB,YAAY;YAOtC,OANa,MAAM,WAAW,IAAA,CAC5BA,MAAK,KAAA,EACL,GAAGA,MAAK,GAAA,CAAI,mBAAA,CAAA,EACZ;gBAAE;YAAA,CAAkB,EACpB;gBAAE,SAASA,MAAK,OAAA;YAAA,CAAS,CAC1B,IACc,CAAA,CAAE;UACjB;;2DAIJ,MAAM,UAAU,gBAAA,EAAgF;;QAC9F,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CACtBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,gBAAA,CAAA,EACZ;gBAAE;YAAA,CAAkB,EACpB;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;UACD;;uEAIJ,MAAM,YACJ,UAAoC,CAAA,CAAE,EACW;;QACjD,OAAOA,OAAK,eAAA,CAAgB,YAAY;YACtC,OAAO,MAAM,WAAW,IAAA,CAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,kBAAA,CAAA,EAAqB,SAAS;gBACjF,SAASA,OAAK,OAAA;YAAA,CACf,CAAC;UACF;;yDAIJ,MAAM,aAAa,gBAAA,EAA2D;;QAC5E,OAAOA,OAAK,eAAA,CAAgB,YAAY;YAOtC,OANa,MAAM,WAAW,IAAA,CAC5BA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,mBAAA,CAAA,EACZ;gBAAE;YAAA,CAAkB,EACpB;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B,IACc,CAAA,CAAE;UACjB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCSN,IAAa,uBAAb,cAA0C,gBAAgB;;;;;;;;;;;;;;;;;IAkBxD,YAAY,GAAA,EAAa,UAAuC,CAAA,CAAE,CAAE;QAClE,KAAA,CAAM,KAAK,QAAQ,OAAA,IAAW,CAAA,CAAE,EAAE,QAAQ,KAAA,CAAM;;;;;;;;;;;;;;;;;;;IAqBlD,KAAK,gBAAA,EAA6C;QAChD,OAAO,IAAI,kBAAkB,IAAA,CAAK,GAAA,EAAK,IAAA,CAAK,OAAA,EAAS,kBAAkB,IAAA,CAAK,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;;;IAwBpF,MAAM,aAAa,gBAAA,EAA2D;6CACrE,KAAA,CAAM,cAAA,QAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,OAA0B;;;;;;;;;;;;;;;;;;;;;;;IAyB5B,MAAM,UAAU,gBAAA,EAAgF;0CACvF,KAAA,CAAM,WAAA,SAAA,IAAA;QAAb,OAAA,0BAAA,IAAA,CAAA,QAAuB;;;;;;;;;;;;;;;;;;;;;;;;;IA2BzB,MAAM,YACJ,UAAoC,CAAA,CAAE,EACW;4CAC1C,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAyB;;;;;;;;;;;;;;;;;;;;;;IAwB3B,MAAM,aAAa,gBAAA,EAA2D;6CACrE,KAAA,CAAM,cAAA,SAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,QAA0B;;;;;;;;;;;GAa9B,IAAa,oBAAb,cAAuC,eAAe;;;;;;;;;;;;;IAgBpD,YACE,GAAA,EACA,OAAA,EACA,gBAAA,EACA,OAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASC,QAAM;QAC1B,IAAA,CAAK,gBAAA,GAAmB;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8B1B,MAAe,YAAY,OAAA,EAAuD;4CACzE,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBC,OAAK,gBAAA;QAAA;;;;;;;;;;;;;;;;;;;;IAuB3B,MAAe,YAAY,UAAwD,CAAA,CAAE,EAAE;4CAC9E,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,OAAK,gBAAA;QAAA;;;;;;;;;;;;;;;;;;;;;IAwB3B,MAAe,SAAS,SAAA,EAAmB;yCAClC,KAAA,CAAM,UAAA,SAAA,IAAA;QAAb,OAAA,yBAAA,IAAA,CAAA,QAAsBA,OAAK,gBAAA,EAAkB;;;;;;;;;;;;;;;;;;;;IAsB/C,MAAe,YAAY,SAAA,EAAmB;4CACrC,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAyBA,OAAK,gBAAA,EAAkB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkClD,MAAM,SAAA,EAAqC;QACzC,OAAO,IAAI,iBACT,IAAA,CAAK,GAAA,EACL,IAAA,CAAK,OAAA,EACL,IAAA,CAAK,gBAAA,EACL,WACA,IAAA,CAAK,KAAA,CACN;;;;;;;;;;;GAaL,IAAa,mBAAb,cAAsC,cAAc;;;;;;;;;;;;;;IAkBlD,YACE,GAAA,EACA,OAAA,EACA,gBAAA,EACA,SAAA,EACA,OAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASD,QAAM;QAC1B,IAAA,CAAK,gBAAA,GAAmB;QACxB,IAAA,CAAK,SAAA,GAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8BnB,MAAe,WAAW,OAAA,EAAoE;2CACrF,KAAA,CAAM,YAAA,SAAA,IAAA;QAAb,OAAA,2BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBC,OAAK,gBAAA;YACvB,WAAWA,OAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;IA0BpB,MAAe,WAAW,OAAA,EAAoE;2CACrF,KAAA,CAAM,YAAA,UAAA,IAAA;QAAb,OAAA,2BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;IA0BpB,MAAe,YACb,UAAsE,CAAA,CAAE,EACxE;4CACO,KAAA,CAAM,aAAA,UAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6BpB,MAAe,aACb,OAAA,EACA;6CACO,KAAA,CAAM,cAAA,UAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;IAyBpB,MAAe,cACb,OAAA,EACA;8CACO,KAAA,CAAM,eAAA,UAAA,IAAA;QAAb,OAAA,8BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;AC1lBtB,IAAa,gBAAb,cAAmC,iBAAiB;;;;;;;;;;;;;;IAelD,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,OAAA,EACA,IAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASC,SAAO,KAAK;;;;;;;;;;;;IAclC,KAAK,EAAA,EAA4B;QAC/B,OAAO,IAAI,eAAe,IAAA,CAAK,GAAA,EAAK,IAAA,CAAK,OAAA,EAAS,IAAI,IAAA,CAAK,KAAA,CAAM;;;;;;;;;;;;IAcnE,IAAI,UAAgC;QAClC,OAAO,IAAI,qBAAqB,IAAA,CAAK,GAAA,GAAM,WAAW;YACpD,SAAS,IAAA,CAAK,OAAA;YACd,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;;;;;;;;;;;;IAcJ,IAAI,YAAoC;QACtC,OAAO,IAAI,uBAAuB,IAAA,CAAK,GAAA,GAAM,YAAY,IAAA,CAAK,OAAA,EAAS,IAAA,CAAK,KAAA,CAAM"}},
    {"offset": {"line": 5490, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/dist/index.mjs","sources":["turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/lib/version.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/lib/constants.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/lib/fetch.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/lib/helpers.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/lib/SupabaseAuthClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/SupabaseClient.ts","turbopack:///[project]/node_modules/.bun/@supabase+supabase-js@2.95.3/node_modules/@supabase/supabase-js/src/index.ts"],"sourcesContent":["// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.95.3'\n","// constants.ts\nimport { RealtimeClientOptions } from '@supabase/realtime-js'\nimport { SupabaseAuthClientOptions } from './types'\nimport { version } from './version'\n\nlet JS_ENV = ''\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n  JS_ENV = 'deno'\n} else if (typeof document !== 'undefined') {\n  JS_ENV = 'web'\n} else if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n  JS_ENV = 'react-native'\n} else {\n  JS_ENV = 'node'\n}\n\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${version}` }\n\nexport const DEFAULT_GLOBAL_OPTIONS = {\n  headers: DEFAULT_HEADERS,\n}\n\nexport const DEFAULT_DB_OPTIONS = {\n  schema: 'public',\n}\n\nexport const DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions = {\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n  flowType: 'implicit',\n}\n\nexport const DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions = {}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args: Parameters<Fetch>) => customFetch(...args)\n  }\n  return (...args: Parameters<Fetch>) => fetch(...args)\n}\n\nexport const resolveHeadersConstructor = () => {\n  return Headers\n}\n\nexport const fetchWithAuth = (\n  supabaseKey: string,\n  getAccessToken: () => Promise<string | null>,\n  customFetch?: Fetch\n): Fetch => {\n  const fetch = resolveFetch(customFetch)\n  const HeadersConstructor = resolveHeadersConstructor()\n\n  return async (input, init) => {\n    const accessToken = (await getAccessToken()) ?? supabaseKey\n    let headers = new HeadersConstructor(init?.headers)\n\n    if (!headers.has('apikey')) {\n      headers.set('apikey', supabaseKey)\n    }\n\n    if (!headers.has('Authorization')) {\n      headers.set('Authorization', `Bearer ${accessToken}`)\n    }\n\n    return fetch(input, { ...init, headers })\n  }\n}\n","// helpers.ts\nimport { SupabaseClientOptions } from './types'\n\nexport function uuid() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    var r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8\n    return v.toString(16)\n  })\n}\n\nexport function ensureTrailingSlash(url: string): string {\n  return url.endsWith('/') ? url : url + '/'\n}\n\nexport const isBrowser = () => typeof window !== 'undefined'\n\nexport function applySettingDefaults<\n  Database = any,\n  SchemaName extends string & keyof Database = 'public' extends keyof Database\n    ? 'public'\n    : string & keyof Database,\n>(\n  options: SupabaseClientOptions<SchemaName>,\n  defaults: SupabaseClientOptions<any>\n): Required<SupabaseClientOptions<SchemaName>> {\n  const {\n    db: dbOptions,\n    auth: authOptions,\n    realtime: realtimeOptions,\n    global: globalOptions,\n  } = options\n  const {\n    db: DEFAULT_DB_OPTIONS,\n    auth: DEFAULT_AUTH_OPTIONS,\n    realtime: DEFAULT_REALTIME_OPTIONS,\n    global: DEFAULT_GLOBAL_OPTIONS,\n  } = defaults\n\n  const result: Required<SupabaseClientOptions<SchemaName>> = {\n    db: {\n      ...DEFAULT_DB_OPTIONS,\n      ...dbOptions,\n    },\n    auth: {\n      ...DEFAULT_AUTH_OPTIONS,\n      ...authOptions,\n    },\n    realtime: {\n      ...DEFAULT_REALTIME_OPTIONS,\n      ...realtimeOptions,\n    },\n    storage: {},\n    global: {\n      ...DEFAULT_GLOBAL_OPTIONS,\n      ...globalOptions,\n      headers: {\n        ...(DEFAULT_GLOBAL_OPTIONS?.headers ?? {}),\n        ...(globalOptions?.headers ?? {}),\n      },\n    },\n    accessToken: async () => '',\n  }\n\n  if (options.accessToken) {\n    result.accessToken = options.accessToken\n  } else {\n    // hack around Required<>\n    delete (result as any).accessToken\n  }\n\n  return result\n}\n\n/**\n * Validates a Supabase client URL\n *\n * @param {string} supabaseUrl - The Supabase client URL string.\n * @returns {URL} - The validated base URL.\n * @throws {Error}\n */\nexport function validateSupabaseUrl(supabaseUrl: string): URL {\n  const trimmedUrl = supabaseUrl?.trim()\n\n  if (!trimmedUrl) {\n    throw new Error('supabaseUrl is required.')\n  }\n\n  if (!trimmedUrl.match(/^https?:\\/\\//i)) {\n    throw new Error('Invalid supabaseUrl: Must be a valid HTTP or HTTPS URL.')\n  }\n\n  try {\n    return new URL(ensureTrailingSlash(trimmedUrl))\n  } catch {\n    throw Error('Invalid supabaseUrl: Provided URL is malformed.')\n  }\n}\n","import { AuthClient } from '@supabase/auth-js'\nimport { SupabaseAuthClientOptions } from './types'\n\nexport class SupabaseAuthClient extends AuthClient {\n  constructor(options: SupabaseAuthClientOptions) {\n    super(options)\n  }\n}\n","import type { AuthChangeEvent } from '@supabase/auth-js'\nimport { FunctionsClient } from '@supabase/functions-js'\nimport {\n  PostgrestClient,\n  type PostgrestFilterBuilder,\n  type PostgrestQueryBuilder,\n} from '@supabase/postgrest-js'\nimport {\n  type RealtimeChannel,\n  type RealtimeChannelOptions,\n  RealtimeClient,\n  type RealtimeClientOptions,\n} from '@supabase/realtime-js'\nimport { StorageClient as SupabaseStorageClient } from '@supabase/storage-js'\nimport {\n  DEFAULT_AUTH_OPTIONS,\n  DEFAULT_DB_OPTIONS,\n  DEFAULT_GLOBAL_OPTIONS,\n  DEFAULT_REALTIME_OPTIONS,\n} from './lib/constants'\nimport { fetchWithAuth } from './lib/fetch'\nimport { applySettingDefaults, validateSupabaseUrl } from './lib/helpers'\nimport { SupabaseAuthClient } from './lib/SupabaseAuthClient'\nimport type {\n  Fetch,\n  GenericSchema,\n  SupabaseAuthClientOptions,\n  SupabaseClientOptions,\n} from './lib/types'\nimport { GetRpcFunctionFilterBuilderByArgs } from './lib/rest/types/common/rpc'\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nexport default class SupabaseClient<\n  Database = any,\n  // The second type parameter is also used for specifying db_schema, so we\n  // support both cases.\n  // TODO: Allow setting db_schema from ClientOptions.\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n  Schema extends Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never = Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never,\n  ClientOptions extends { PostgrestVersion: string } = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? // If the version isn't explicitly set, look for it in the __InternalSupabase object to infer the right version\n      Database extends { __InternalSupabase: { PostgrestVersion: string } }\n      ? Database['__InternalSupabase']\n      : // otherwise default to 12\n        { PostgrestVersion: '12' }\n    : SchemaNameOrClientOptions extends { PostgrestVersion: string }\n      ? SchemaNameOrClientOptions\n      : never,\n> {\n  /**\n   * Supabase Auth allows you to create and manage user sessions for access to data that is secured by access policies.\n   */\n  auth: SupabaseAuthClient\n  realtime: RealtimeClient\n  /**\n   * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n   */\n  storage: SupabaseStorageClient\n\n  protected realtimeUrl: URL\n  protected authUrl: URL\n  protected storageUrl: URL\n  protected functionsUrl: URL\n  protected rest: PostgrestClient<Database, ClientOptions, SchemaName>\n  protected storageKey: string\n  protected fetch?: Fetch\n  protected changedAccessToken?: string\n  protected accessToken?: () => Promise<string | null>\n\n  protected headers: Record<string, string>\n\n  /**\n   * Create a new client for use in the browser.\n   * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n   * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n   * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n   * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n   * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n   * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n   * @param options.realtime Options passed along to realtime-js constructor.\n   * @param options.storage Options passed along to the storage-js constructor.\n   * @param options.global.fetch A custom fetch implementation.\n   * @param options.global.headers Any additional headers to send with each network request.\n   * @example\n   * ```ts\n   * import { createClient } from '@supabase/supabase-js'\n   *\n   * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n   * const { data } = await supabase.from('profiles').select('*')\n   * ```\n   */\n  constructor(\n    protected supabaseUrl: string,\n    protected supabaseKey: string,\n    options?: SupabaseClientOptions<SchemaName>\n  ) {\n    const baseUrl = validateSupabaseUrl(supabaseUrl)\n    if (!supabaseKey) throw new Error('supabaseKey is required.')\n\n    this.realtimeUrl = new URL('realtime/v1', baseUrl)\n    this.realtimeUrl.protocol = this.realtimeUrl.protocol.replace('http', 'ws')\n    this.authUrl = new URL('auth/v1', baseUrl)\n    this.storageUrl = new URL('storage/v1', baseUrl)\n    this.functionsUrl = new URL('functions/v1', baseUrl)\n\n    // default storage key uses the supabase project ref as a namespace\n    const defaultStorageKey = `sb-${baseUrl.hostname.split('.')[0]}-auth-token`\n    const DEFAULTS = {\n      db: DEFAULT_DB_OPTIONS,\n      realtime: DEFAULT_REALTIME_OPTIONS,\n      auth: { ...DEFAULT_AUTH_OPTIONS, storageKey: defaultStorageKey },\n      global: DEFAULT_GLOBAL_OPTIONS,\n    }\n\n    const settings = applySettingDefaults(options ?? {}, DEFAULTS)\n\n    this.storageKey = settings.auth.storageKey ?? ''\n    this.headers = settings.global.headers ?? {}\n\n    if (!settings.accessToken) {\n      this.auth = this._initSupabaseAuthClient(\n        settings.auth ?? {},\n        this.headers,\n        settings.global.fetch\n      )\n    } else {\n      this.accessToken = settings.accessToken\n\n      this.auth = new Proxy<SupabaseAuthClient>({} as any, {\n        get: (_, prop) => {\n          throw new Error(\n            `@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(\n              prop\n            )} is not possible`\n          )\n        },\n      })\n    }\n\n    this.fetch = fetchWithAuth(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch)\n    this.realtime = this._initRealtimeClient({\n      headers: this.headers,\n      accessToken: this._getAccessToken.bind(this),\n      ...settings.realtime,\n    })\n    if (this.accessToken) {\n      // Start auth immediately to avoid race condition with channel subscriptions\n      // Wrap Promise to avoid Firefox extension cross-context Promise access errors\n      Promise.resolve(this.accessToken())\n        .then((token) => this.realtime.setAuth(token))\n        .catch((e) => console.warn('Failed to set initial Realtime auth token:', e))\n    }\n\n    this.rest = new PostgrestClient(new URL('rest/v1', baseUrl).href, {\n      headers: this.headers,\n      schema: settings.db.schema,\n      fetch: this.fetch,\n      timeout: settings.db.timeout,\n      urlLengthLimit: settings.db.urlLengthLimit,\n    })\n\n    this.storage = new SupabaseStorageClient(\n      this.storageUrl.href,\n      this.headers,\n      this.fetch,\n      options?.storage\n    )\n\n    if (!settings.accessToken) {\n      this._listenForAuthEvents()\n    }\n  }\n\n  /**\n   * Supabase Functions allows you to deploy and invoke edge functions.\n   */\n  get functions(): FunctionsClient {\n    return new FunctionsClient(this.functionsUrl.href, {\n      headers: this.headers,\n      customFetch: this.fetch,\n    })\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.from\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any> {\n    return this.rest.from(relation)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.schema\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return this.rest.schema<DynamicSchema>(schema)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    options: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {\n      head: false,\n      get: false,\n      count: undefined,\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    return this.rest.rpc(fn, args, options) as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      FilterBuilder['Row'],\n      FilterBuilder['Result'],\n      FilterBuilder['RelationName'],\n      FilterBuilder['Relationships'],\n      'RPC'\n    >\n  }\n\n  /**\n   * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n   *\n   * @param {string} name - The name of the Realtime channel.\n   * @param {Object} opts - The options to pass to the Realtime channel.\n   *\n   */\n  channel(name: string, opts: RealtimeChannelOptions = { config: {} }): RealtimeChannel {\n    return this.realtime.channel(name, opts)\n  }\n\n  /**\n   * Returns all Realtime channels.\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.realtime.getChannels()\n  }\n\n  /**\n   * Unsubscribes and removes Realtime channel from Realtime client.\n   *\n   * @param {RealtimeChannel} channel - The name of the Realtime channel.\n   *\n   */\n  removeChannel(channel: RealtimeChannel): Promise<'ok' | 'timed out' | 'error'> {\n    return this.realtime.removeChannel(channel)\n  }\n\n  /**\n   * Unsubscribes and removes all Realtime channels from Realtime client.\n   */\n  removeAllChannels(): Promise<('ok' | 'timed out' | 'error')[]> {\n    return this.realtime.removeAllChannels()\n  }\n\n  private async _getAccessToken() {\n    if (this.accessToken) {\n      return await this.accessToken()\n    }\n\n    const { data } = await this.auth.getSession()\n\n    return data.session?.access_token ?? this.supabaseKey\n  }\n\n  private _initSupabaseAuthClient(\n    {\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      storageKey,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n    }: SupabaseAuthClientOptions,\n    headers?: Record<string, string>,\n    fetch?: Fetch\n  ) {\n    const authHeaders = {\n      Authorization: `Bearer ${this.supabaseKey}`,\n      apikey: `${this.supabaseKey}`,\n    }\n    return new SupabaseAuthClient({\n      url: this.authUrl.href,\n      headers: { ...authHeaders, ...headers },\n      storageKey: storageKey,\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n      fetch,\n      // auth checks if there is a custom authorizaiton header using this flag\n      // so it knows whether to return an error when getUser is called with no session\n      hasCustomAuthorizationHeader: Object.keys(this.headers).some(\n        (key) => key.toLowerCase() === 'authorization'\n      ),\n    })\n  }\n\n  private _initRealtimeClient(options: RealtimeClientOptions) {\n    return new RealtimeClient(this.realtimeUrl.href, {\n      ...options,\n      params: { ...{ apikey: this.supabaseKey }, ...options?.params },\n    })\n  }\n\n  private _listenForAuthEvents() {\n    const data = this.auth.onAuthStateChange((event, session) => {\n      this._handleTokenChanged(event, 'CLIENT', session?.access_token)\n    })\n    return data\n  }\n\n  private _handleTokenChanged(\n    event: AuthChangeEvent,\n    source: 'CLIENT' | 'STORAGE',\n    token?: string\n  ) {\n    if (\n      (event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n      this.changedAccessToken !== token\n    ) {\n      this.changedAccessToken = token\n      this.realtime.setAuth(token)\n    } else if (event === 'SIGNED_OUT') {\n      this.realtime.setAuth()\n      if (source == 'STORAGE') this.auth.signOut()\n      this.changedAccessToken = undefined\n    }\n  }\n}\n","import SupabaseClient from './SupabaseClient'\nimport type { SupabaseClientOptions } from './lib/types'\n\nexport * from '@supabase/auth-js'\nexport type { User as AuthUser, Session as AuthSession } from '@supabase/auth-js'\nexport type {\n  PostgrestResponse,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from '@supabase/postgrest-js'\nexport { PostgrestError } from '@supabase/postgrest-js'\nexport type { FunctionInvokeOptions } from '@supabase/functions-js'\nexport {\n  FunctionsHttpError,\n  FunctionsFetchError,\n  FunctionsRelayError,\n  FunctionsError,\n  FunctionRegion,\n} from '@supabase/functions-js'\nexport * from '@supabase/realtime-js'\nexport { default as SupabaseClient } from './SupabaseClient'\nexport type {\n  SupabaseClientOptions,\n  QueryResult,\n  QueryData,\n  QueryError,\n  DatabaseWithoutInternals,\n} from './lib/types'\n\n/**\n * Creates a new Supabase Client.\n *\n * @example\n * ```ts\n * import { createClient } from '@supabase/supabase-js'\n *\n * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n * const { data, error } = await supabase.from('profiles').select('*')\n * ```\n */\nexport const createClient = <\n  Database = any,\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName>\n): SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName> => {\n  return new SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName>(\n    supabaseUrl,\n    supabaseKey,\n    options\n  )\n}\n\n// Check for Node.js <= 18 deprecation\nfunction shouldShowDeprecationWarning(): boolean {\n  // Skip in browser environments\n  if (typeof window !== 'undefined') {\n    return false\n  }\n\n  // Skip if process is not available (e.g., Edge Runtime)\n  // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n  const _process = (globalThis as any)['process']\n  if (!_process) {\n    return false\n  }\n\n  const processVersion = _process['version']\n  if (processVersion === undefined || processVersion === null) {\n    return false\n  }\n\n  const versionMatch = processVersion.match(/^v(\\d+)\\./)\n  if (!versionMatch) {\n    return false\n  }\n\n  const majorVersion = parseInt(versionMatch[1], 10)\n  return majorVersion <= 18\n}\n\nif (shouldShowDeprecationWarning()) {\n  console.warn(\n    `  Node.js 18 and below are deprecated and will no longer be supported in future versions of @supabase/supabase-js. ` +\n      `Please upgrade to Node.js 20 or later. ` +\n      `For more information, visit: https://github.com/orgs/supabase/discussions/37217`\n  )\n}\n"],"names":["DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions","DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions","fetch","DEFAULT_DB_OPTIONS","DEFAULT_AUTH_OPTIONS","DEFAULT_REALTIME_OPTIONS","DEFAULT_GLOBAL_OPTIONS","result: Required<SupabaseClientOptions<SchemaName>>","supabaseUrl: string","supabaseKey: string","SupabaseStorageClient","this"],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAMA,MAAa,UAAU;;;ACDvB,IAAI,SAAS;AAEb,IAAI,OAAO,SAAS,YAClB,CAAA,SAAS;SACA,OAAO,aAAa,YAC7B,CAAA,SAAS;SACA,OAAO,cAAc,eAAe,UAAU,OAAA,KAAY,cACnE,CAAA,SAAS;KAET,SAAS;AAGX,MAAa,kBAAkB;IAAE,iBAAiB,CAAA,YAAA,EAAe,OAAO,CAAA,EAAG,SAAA;AAAA,CAAW;AAEtF,MAAa,yBAAyB;IACpC,SAAS;AAAA,CACV;AAED,MAAa,qBAAqB;IAChC,QAAQ;AAAA,CACT;AAED,MAAaA,uBAAkD;IAC7D,kBAAkB;IAClB,gBAAgB;IAChB,oBAAoB;IACpB,UAAU;CACX;AAED,MAAaC,2BAAkD,CAAA,CAAE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChCjE,MAAa,eAAA,CAAgB,gBAA+B;IAC1D,IAAI,YACF,CAAA,OAAA,CAAQ,GAAG,OAA4B,YAAY,GAAG,KAAK;IAE7D,OAAA,CAAQ,GAAG,OAA4B,MAAM,GAAG,KAAK;;AAGvD,MAAa,4BAAA,MAAkC;IAC7C,OAAO;;AAGT,MAAa,gBAAA,CACX,aACA,gBACA,gBACU;IACV,MAAMC,UAAQ,aAAa,YAAY;IACvC,MAAM,qBAAqB,2BAA2B;IAEtD,OAAO,OAAO,OAAO,SAAS;;QAC5B,MAAM,cAAA,CAAA,wBAAe,MAAM,gBAAgB,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAK;QAChD,IAAI,UAAU,IAAI,mBAAA,SAAA,QAAA,SAAA,KAAA,IAAA,KAAA,IAAmB,KAAM,OAAA,CAAQ;QAEnD,IAAI,CAAC,QAAQ,GAAA,CAAI,SAAS,CACxB,CAAA,QAAQ,GAAA,CAAI,UAAU,YAAY;QAGpC,IAAI,CAAC,QAAQ,GAAA,CAAI,gBAAgB,CAC/B,CAAA,QAAQ,GAAA,CAAI,iBAAiB,CAAA,OAAA,EAAU,aAAA,CAAc;QAGvD,OAAOA,QAAM,OAAA,eAAA,eAAA,CAAA,GAAY,OAAA,CAAA,GAAA;YAAM;QAAA,GAAU;;;;;ACtB7C,SAAgB,oBAAoB,GAAA,EAAqB;IACvD,OAAO,IAAI,QAAA,CAAS,IAAI,GAAG,MAAM,MAAM;;AAKzC,SAAgB,qBAMd,OAAA,EACA,QAAA,EAC6C;;IAC7C,MAAM,EACJ,IAAI,SAAA,EACJ,MAAM,WAAA,EACN,UAAU,eAAA,EACV,QAAQ,aAAA,EAAA,GACN;IACJ,MAAM,EACJ,IAAIC,oBAAAA,EACJ,MAAMC,sBAAAA,EACN,UAAUC,0BAAAA,EACV,QAAQC,wBAAAA,EAAAA,GACN;IAEJ,MAAMC,SAAsD;QAC1D,IAAA,eAAA,eAAA,CAAA,GACKJ,uBACA;QAEL,MAAA,eAAA,eAAA,CAAA,GACKC,yBACA;QAEL,UAAA,eAAA,eAAA,CAAA,GACKC,6BACA;QAEL,SAAS,CAAA,CAAE;QACX,QAAA,eAAA,eAAA,eAAA,CAAA,GACKC,2BACA,gBAAA,CAAA,GAAA;YACH,SAAA,eAAA,eAAA,CAAA,GAAA,CAAA,wBAAA,6BAAA,QAAA,6BAAA,KAAA,IAAA,KAAA,IACMA,yBAAwB,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE,GAAA,CAAA,wBAAA,kBAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IACrC,cAAe,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE;QAAA;QAGpC,aAAa,UAAY;KAC1B;IAED,IAAI,QAAQ,WAAA,CACV,CAAA,OAAO,WAAA,GAAc,QAAQ,WAAA;SAG7B,OAAQ,OAAe,WAAA;IAGzB,OAAO;;;;;;;;GAUT,SAAgB,oBAAoB,WAAA,EAA0B;IAC5D,MAAM,aAAA,gBAAA,QAAA,gBAAA,KAAA,IAAA,KAAA,IAAa,YAAa,IAAA,EAAM;IAEtC,IAAI,CAAC,WACH,CAAA,MAAM,IAAI,MAAM,2BAA2B;IAG7C,IAAI,CAAC,WAAW,KAAA,CAAM,gBAAgB,CACpC,CAAA,MAAM,IAAI,MAAM,0DAA0D;IAG5E,IAAI;QACF,OAAO,IAAI,IAAI,oBAAoB,WAAW,CAAC;sBACzC;QACN,MAAM,MAAM,kDAAkD;;;;;AC5FlE,IAAa,qBAAb,cAAwC,4SAAA,CAAW;IACjD,YAAY,OAAA,CAAoC;QAC9C,KAAA,CAAM,QAAQ;;;;;;;;;GC+BlB,IAAqB,iBAArB,MAgCE;;;;;;;;;;;;;;;;;;;;IA2CA,YACYE,WAAAA,EACAC,WAAAA,EACV,OAAA,CACA;;QAHU,IAAA,CAAA,WAAA,GAAA;QACA,IAAA,CAAA,WAAA,GAAA;QAGV,MAAM,UAAU,oBAAoB,YAAY;QAChD,IAAI,CAAC,YAAa,CAAA,MAAM,IAAI,MAAM,2BAA2B;QAE7D,IAAA,CAAK,WAAA,GAAc,IAAI,IAAI,eAAe,QAAQ;QAClD,IAAA,CAAK,WAAA,CAAY,QAAA,GAAW,IAAA,CAAK,WAAA,CAAY,QAAA,CAAS,OAAA,CAAQ,QAAQ,KAAK;QAC3E,IAAA,CAAK,OAAA,GAAU,IAAI,IAAI,WAAW,QAAQ;QAC1C,IAAA,CAAK,UAAA,GAAa,IAAI,IAAI,cAAc,QAAQ;QAChD,IAAA,CAAK,YAAA,GAAe,IAAI,IAAI,gBAAgB,QAAQ;QAGpD,MAAM,oBAAoB,CAAA,GAAA,EAAM,QAAQ,QAAA,CAAS,KAAA,CAAM,IAAI,CAAC,EAAA,CAAG,WAAA,CAAA;QAC/D,MAAM,WAAW;YACf,IAAI;YACJ,UAAU;YACV,MAAA,eAAA,eAAA,CAAA,GAAW,uBAAA,CAAA,GAAA;gBAAsB,YAAY;YAAA;YAC7C,QAAQ;SACT;QAED,MAAM,WAAW,qBAAqB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,CAAA,CAAE,EAAE,SAAS;QAE9D,IAAA,CAAK,UAAA,GAAA,CAAA,wBAAa,SAAS,IAAA,CAAK,UAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAc;QAC9C,IAAA,CAAK,OAAA,GAAA,CAAA,wBAAU,SAAS,MAAA,CAAO,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE;QAE5C,IAAI,CAAC,SAAS,WAAA,EAAa;;YACzB,IAAA,CAAK,IAAA,GAAO,IAAA,CAAK,uBAAA,CAAA,CAAA,iBACf,SAAS,IAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,iBAAQ,CAAA,CAAE,EACnB,IAAA,CAAK,OAAA,EACL,SAAS,MAAA,CAAO,KAAA,CACjB;eACI;YACL,IAAA,CAAK,WAAA,GAAc,SAAS,WAAA;YAE5B,IAAA,CAAK,IAAA,GAAO,IAAI,MAA0B,CAAA,CAAE,EAAS;gBACnD,KAAA,CAAM,GAAG,SAAS;oBAChB,MAAM,IAAI,MACR,CAAA,0GAAA,EAA6G,OAC3G,KACD,CAAC,gBAAA,CAAA,CACH;;aAEJ,CAAC;;QAGJ,IAAA,CAAK,KAAA,GAAQ,cAAc,aAAa,IAAA,CAAK,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK,EAAE,SAAS,MAAA,CAAO,KAAA,CAAM;QAC/F,IAAA,CAAK,QAAA,GAAW,IAAA,CAAK,mBAAA,CAAA,eAAA;YACnB,SAAS,IAAA,CAAK,OAAA;YACd,aAAa,IAAA,CAAK,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK;WACzC,SAAS,QAAA,EACZ;QACF,IAAI,IAAA,CAAK,WAAA,CAGP,CAAA,QAAQ,OAAA,CAAQ,IAAA,CAAK,WAAA,EAAa,CAAC,CAChC,IAAA,CAAA,CAAM,QAAU,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM,CAAC,CAC7C,KAAA,CAAA,CAAO,IAAM,QAAQ,IAAA,CAAK,8CAA8C,EAAE,CAAC;QAGhF,IAAA,CAAK,IAAA,GAAO,IAAI,oQAAA,CAAgB,IAAI,IAAI,WAAW,QAAQ,CAAC,IAAA,EAAM;YAChE,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,SAAS,EAAA,CAAG,MAAA;YACpB,OAAO,IAAA,CAAK,KAAA;YACZ,SAAS,SAAS,EAAA,CAAG,OAAA;YACrB,gBAAgB,SAAS,EAAA,CAAG,cAAA;SAC7B,CAAC;QAEF,IAAA,CAAK,OAAA,GAAU,IAAIC,8PAAAA,CACjB,IAAA,CAAK,UAAA,CAAW,IAAA,EAChB,IAAA,CAAK,OAAA,EACL,IAAA,CAAK,KAAA,EAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IACL,QAAS,OAAA,CACV;QAED,IAAI,CAAC,SAAS,WAAA,CACZ,CAAA,IAAA,CAAK,oBAAA,EAAsB;;;;IAO/B,IAAI,YAA6B;QAC/B,OAAO,IAAI,uRAAA,CAAgB,IAAA,CAAK,YAAA,CAAa,IAAA,EAAM;YACjD,SAAS,IAAA,CAAK,OAAA;YACd,aAAa,IAAA,CAAK,KAAA;SACnB,CAAC;;;;;;IAgBJ,KAAK,QAAA,EAAqE;QACxE,OAAO,IAAA,CAAK,IAAA,CAAK,IAAA,CAAK,SAAS;;;;;;;;IAWjC,OACE,MAAA,EAMA;QACA,OAAO,IAAA,CAAK,IAAA,CAAK,MAAA,CAAsB,OAAO;;;;;;;;;;;;;;;;;;;;;;;;IA2BhD,IASE,EAAA,EACA,OAAa,CAAA,CAAE,EACf,UAII;QACF,MAAM;QACN,KAAK;QACL,OAAO,KAAA;KACR,EASD;QACA,OAAO,IAAA,CAAK,IAAA,CAAK,GAAA,CAAI,IAAI,MAAM,QAAQ;;;;;;;;IAkBzC,QAAQ,IAAA,EAAc,OAA+B;QAAE,QAAQ,CAAA,CAAE;IAAA,CAAE,EAAmB;QACpF,OAAO,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM,KAAK;;;;IAM1C,cAAiC;QAC/B,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,EAAa;;;;;;;IASpC,cAAc,OAAA,EAAiE;QAC7E,OAAO,IAAA,CAAK,QAAA,CAAS,aAAA,CAAc,QAAQ;;;;IAM7C,oBAA+D;QAC7D,OAAO,IAAA,CAAK,QAAA,CAAS,iBAAA,EAAmB;;IAG1C,MAAc,kBAAkB;;;QAC9B,IAAIC,MAAK,WAAA,CACP,CAAA,OAAO,MAAMA,MAAK,WAAA,EAAa;QAGjC,MAAM,EAAE,IAAA,EAAA,GAAS,MAAMA,MAAK,IAAA,CAAK,UAAA,EAAY;QAE7C,OAAA,CAAA,wBAAA,CAAA,gBAAO,KAAK,OAAA,MAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IAAA,cAAS,YAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAgBA,MAAK,WAAA;;IAGpC,wBACN,EACE,gBAAA,EACA,cAAA,EACA,kBAAA,EACA,OAAA,EACA,WAAA,EACA,UAAA,EACA,QAAA,EACA,IAAA,EACA,KAAA,EACA,YAAA,EAAA,EAEF,OAAA,EACA,OAAA,EACA;QACA,MAAM,cAAc;YAClB,eAAe,CAAA,OAAA,EAAU,IAAA,CAAK,WAAA,EAAA;YAC9B,QAAQ,GAAG,IAAA,CAAK,WAAA,EAAA;SACjB;QACD,OAAO,IAAI,mBAAmB;YAC5B,KAAK,IAAA,CAAK,OAAA,CAAQ,IAAA;YAClB,SAAA,eAAA,eAAA,CAAA,GAAc,cAAgB;YAClB;YACZ;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,OAAA;YAGA,8BAA8B,OAAO,IAAA,CAAK,IAAA,CAAK,OAAA,CAAQ,CAAC,IAAA,CAAA,CACrD,MAAQ,IAAI,WAAA,EAAa,KAAK,gBAChC;SACF,CAAC;;IAGI,oBAAoB,OAAA,EAAgC;QAC1D,OAAO,IAAI,gUAAA,CAAe,IAAA,CAAK,WAAA,CAAY,IAAA,EAAA,eAAA,eAAA,CAAA,GACtC,UAAA,CAAA,GAAA;YACH,QAAA,eAAA,eAAA,CAAA,GAAa;gBAAE,QAAQ,IAAA,CAAK,WAAA;YAAA,CAAa,GAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAK,QAAS,MAAA;QAAA,GACvD;;IAGI,uBAAuB;QAI7B,OAHa,IAAA,CAAK,IAAA,CAAK,iBAAA,CAAA,CAAmB,OAAO,YAAY;YAC3D,IAAA,CAAK,mBAAA,CAAoB,OAAO,UAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAU,QAAS,YAAA,CAAa;UAChE;;IAII,oBACN,KAAA,EACA,MAAA,EACA,KAAA,EACA;QACA,IAAA,CACG,UAAU,qBAAqB,UAAU,WAAA,KAC1C,IAAA,CAAK,kBAAA,KAAuB,OAC5B;YACA,IAAA,CAAK,kBAAA,GAAqB;YAC1B,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM;mBACnB,UAAU,cAAc;YACjC,IAAA,CAAK,QAAA,CAAS,OAAA,EAAS;YACvB,IAAI,UAAU,UAAW,CAAA,IAAA,CAAK,IAAA,CAAK,OAAA,EAAS;YAC5C,IAAA,CAAK,kBAAA,GAAqB,KAAA;;;;;;;;;;;;;;;;GC1XhC,MAAa,eAAA,CAeX,aACA,aACA,YACoE;IACpE,OAAO,IAAI,eACT,aACA,aACA,QACD;;AAIH,SAAS,+BAAwC;IAE/C,IAAI,OAAO,WAAW,YACpB,QAAO;;IAKT,MAAM,WAAY,UAAA,CAAmB,UAAA;IACrC,IAAI,CAAC,SACH,CAAA,OAAO;IAGT,MAAM,iBAAiB,QAAA,CAAS,UAAA;IAChC,IAAI,mBAAmB,KAAA,KAAa,mBAAmB,KACrD,CAAA,OAAO;IAGT,MAAM,eAAe,eAAe,KAAA,CAAM,YAAY;IACtD,IAAI,CAAC,aACH,CAAA,OAAO;IAIT,OADqB,SAAS,YAAA,CAAa,EAAA,EAAI,GAAG,IAC3B;;AAGzB,IAAI,8BAA8B,CAChC,CAAA,QAAQ,IAAA,CACN,8OAGD"}},
    {"offset": {"line": 5909, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/version.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/version.ts"],"sourcesContent":["export const VERSION = '0.6.1';\n"],"names":[],"mappings":";;;;AAAO,MAAM,OAAO,GAAG,OAAO,CAAC"}},
    {"offset": {"line": 5918, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/utils/helpers.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/utils/helpers.ts"],"sourcesContent":["import type { SerializeOptions } from \"cookie\";\nimport { parse as cookieParse, serialize as cookieSerialize } from \"cookie\";\n\n/**\n * @deprecated Since v0.4.0: Please use {@link parseCookieHeader}. `parse` will\n * not be available for import starting v1.0.0 of `@supabase/ssr`.\n */\nexport const parse = cookieParse;\n\n/**\n * @deprecated Since v0.4.0: Please use {@link serializeCookieHeader}.\n * `serialize` will not be available for import starting v1.0.0 of\n * `@supabase/ssr`.\n */\nexport const serialize = cookieSerialize;\n\n/**\n * Parses the `Cookie` HTTP header into an array of cookie name-value objects.\n *\n * @param header The `Cookie` HTTP header. Decodes cookie names and values from\n * URI encoding first.\n */\nexport function parseCookieHeader(\n  header: string,\n): { name: string; value?: string }[] {\n  const parsed = cookieParse(header);\n\n  return Object.keys(parsed ?? {}).map((name) => ({\n    name,\n    value: parsed[name],\n  }));\n}\n\n/**\n * Converts the arguments to a valid `Set-Cookie` header. Non US-ASCII chars\n * and other forbidden cookie chars will be URI encoded.\n *\n * @param name Name of cookie.\n * @param value Value of cookie.\n */\nexport function serializeCookieHeader(\n  name: string,\n  value: string,\n  options: SerializeOptions,\n): string {\n  return cookieSerialize(name, value, options);\n}\n\nexport function isBrowser() {\n  return (\n    typeof window !== \"undefined\" && typeof window.document !== \"undefined\"\n  );\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AACA,OAAO,EAAE,KAAK,IAAI,WAAW,EAAE,SAAS,IAAI,eAAe,EAAE,MAAM,QAAQ,CAAC;;AAMrE,MAAM,KAAK,GAAG,0MAAW,CAAC;AAO1B,MAAM,SAAS,GAAG,8MAAe,CAAC;AAQnC,SAAU,iBAAiB,CAC/B,MAAc;IAEd,MAAM,MAAM,OAAG,0MAAW,EAAC,MAAM,CAAC,CAAC;IAEnC,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,IAAI,CAAA,CAAE,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;YAC9C,IAAI;YACJ,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC;SACpB,CAAC,CAAC,CAAC;AACN,CAAC;AASK,SAAU,qBAAqB,CACnC,IAAY,EACZ,KAAa,EACb,OAAyB;IAEzB,WAAO,8MAAe,EAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;AAC/C,CAAC;AAEK,SAAU,SAAS;IACvB,OAAO,AACL,OAAO,MAAM,qCAAK,WAAW,IAAI,OAAO,MAAM,CAAC,QAAQ,KAAK,WAAW,CACxE,CAAC;AACJ,CAAC"}},
    {"offset": {"line": 5951, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/utils/constants.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/utils/constants.ts"],"sourcesContent":["import { CookieOptions } from \"../types\";\n\nexport const DEFAULT_COOKIE_OPTIONS: CookieOptions = {\n  path: \"/\",\n  sameSite: \"lax\",\n  httpOnly: false,\n  // https://developer.chrome.com/blog/cookie-max-age-expires\n  // https://httpwg.org/http-extensions/draft-ietf-httpbis-rfc6265bis.html#name-cookie-lifetime-limits\n  maxAge: 400 * 24 * 60 * 60,\n};\n"],"names":[],"mappings":";;;;AAEO,MAAM,sBAAsB,GAAkB;IACnD,IAAI,EAAE,GAAG;IACT,QAAQ,EAAE,KAAK;IACf,QAAQ,EAAE,KAAK;IACf,2DAA2D;IAC3D,oGAAoG;IACpG,MAAM,EAAE,GAAG,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE;CAC3B,CAAC"}},
    {"offset": {"line": 5967, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/utils/chunker.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/utils/chunker.ts"],"sourcesContent":["interface Chunk {\n  name: string;\n  value: string;\n}\n\nexport const MAX_CHUNK_SIZE = 3180;\n\nconst CHUNK_LIKE_REGEX = /^(.*)[.](0|[1-9][0-9]*)$/;\nexport function isChunkLike(cookieName: string, key: string) {\n  if (cookieName === key) {\n    return true;\n  }\n\n  const chunkLike = cookieName.match(CHUNK_LIKE_REGEX);\n  if (chunkLike && chunkLike[1] === key) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * create chunks from a string and return an array of object\n */\nexport function createChunks(\n  key: string,\n  value: string,\n  chunkSize?: number,\n): Chunk[] {\n  const resolvedChunkSize = chunkSize ?? MAX_CHUNK_SIZE;\n\n  let encodedValue = encodeURIComponent(value);\n\n  if (encodedValue.length <= resolvedChunkSize) {\n    return [{ name: key, value }];\n  }\n\n  const chunks: string[] = [];\n\n  while (encodedValue.length > 0) {\n    let encodedChunkHead = encodedValue.slice(0, resolvedChunkSize);\n\n    const lastEscapePos = encodedChunkHead.lastIndexOf(\"%\");\n\n    // Check if the last escaped character is truncated.\n    if (lastEscapePos > resolvedChunkSize - 3) {\n      // If so, reslice the string to exclude the whole escape sequence.\n      // We only reduce the size of the string as the chunk must\n      // be smaller than the chunk size.\n      encodedChunkHead = encodedChunkHead.slice(0, lastEscapePos);\n    }\n\n    let valueHead: string = \"\";\n\n    // Check if the chunk was split along a valid unicode boundary.\n    while (encodedChunkHead.length > 0) {\n      try {\n        // Try to decode the chunk back and see if it is valid.\n        // Stop when the chunk is valid.\n        valueHead = decodeURIComponent(encodedChunkHead);\n        break;\n      } catch (error) {\n        if (\n          error instanceof URIError &&\n          encodedChunkHead.at(-3) === \"%\" &&\n          encodedChunkHead.length > 3\n        ) {\n          encodedChunkHead = encodedChunkHead.slice(\n            0,\n            encodedChunkHead.length - 3,\n          );\n        } else {\n          throw error;\n        }\n      }\n    }\n\n    chunks.push(valueHead);\n    encodedValue = encodedValue.slice(encodedChunkHead.length);\n  }\n\n  return chunks.map((value, i) => ({ name: `${key}.${i}`, value }));\n}\n\n// Get fully constructed chunks\nexport async function combineChunks(\n  key: string,\n  retrieveChunk: (\n    name: string,\n  ) => Promise<string | null | undefined> | string | null | undefined,\n) {\n  const value = await retrieveChunk(key);\n\n  if (value) {\n    return value;\n  }\n\n  let values: string[] = [];\n\n  for (let i = 0; ; i++) {\n    const chunkName = `${key}.${i}`;\n    const chunk = await retrieveChunk(chunkName);\n\n    if (!chunk) {\n      break;\n    }\n\n    values.push(chunk);\n  }\n\n  if (values.length > 0) {\n    return values.join(\"\");\n  }\n\n  return null;\n}\n\nexport async function deleteChunks(\n  key: string,\n  retrieveChunk: (\n    name: string,\n  ) => Promise<string | null | undefined> | string | null | undefined,\n  removeChunk: (name: string) => Promise<void> | void,\n) {\n  const value = await retrieveChunk(key);\n\n  if (value) {\n    await removeChunk(key);\n  }\n\n  for (let i = 0; ; i++) {\n    const chunkName = `${key}.${i}`;\n    const chunk = await retrieveChunk(chunkName);\n\n    if (!chunk) {\n      break;\n    }\n\n    await removeChunk(chunkName);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAKO,MAAM,cAAc,GAAG,IAAI,CAAC;AAEnC,MAAM,gBAAgB,GAAG,0BAA0B,CAAC;AAC9C,SAAU,WAAW,CAAC,UAAkB,EAAE,GAAW;IACzD,IAAI,UAAU,KAAK,GAAG,EAAE,CAAC;QACvB,OAAO,IAAI,CAAC;IACd,CAAC;IAED,MAAM,SAAS,GAAG,UAAU,CAAC,KAAK,CAAC,gBAAgB,CAAC,CAAC;IACrD,IAAI,SAAS,IAAI,SAAS,CAAC,CAAC,CAAC,KAAK,GAAG,EAAE,CAAC;QACtC,OAAO,IAAI,CAAC;IACd,CAAC;IAED,OAAO,KAAK,CAAC;AACf,CAAC;AAKK,SAAU,YAAY,CAC1B,GAAW,EACX,KAAa,EACb,SAAkB;IAElB,MAAM,iBAAiB,GAAG,SAAS,IAAI,cAAc,CAAC;IAEtD,IAAI,YAAY,GAAG,kBAAkB,CAAC,KAAK,CAAC,CAAC;IAE7C,IAAI,YAAY,CAAC,MAAM,IAAI,iBAAiB,EAAE,CAAC;QAC7C,OAAO;YAAC;gBAAE,IAAI,EAAE,GAAG;gBAAE,KAAK;YAAA,CAAE;SAAC,CAAC;IAChC,CAAC;IAED,MAAM,MAAM,GAAa,EAAE,CAAC;IAE5B,MAAO,YAAY,CAAC,MAAM,GAAG,CAAC,CAAE,CAAC;QAC/B,IAAI,gBAAgB,GAAG,YAAY,CAAC,KAAK,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC;QAEhE,MAAM,aAAa,GAAG,gBAAgB,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAExD,oDAAoD;QACpD,IAAI,aAAa,GAAG,iBAAiB,GAAG,CAAC,EAAE,CAAC;YAC1C,kEAAkE;YAClE,0DAA0D;YAC1D,kCAAkC;YAClC,gBAAgB,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC,EAAE,aAAa,CAAC,CAAC;QAC9D,CAAC;QAED,IAAI,SAAS,GAAW,EAAE,CAAC;QAE3B,+DAA+D;QAC/D,MAAO,gBAAgB,CAAC,MAAM,GAAG,CAAC,CAAE,CAAC;YACnC,IAAI,CAAC;gBACH,uDAAuD;gBACvD,gCAAgC;gBAChC,SAAS,GAAG,kBAAkB,CAAC,gBAAgB,CAAC,CAAC;gBACjD,MAAM;YACR,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;gBACf,IACE,KAAK,YAAY,QAAQ,IACzB,gBAAgB,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,GAAG,IAC/B,gBAAgB,CAAC,MAAM,GAAG,CAAC,EAC3B,CAAC;oBACD,gBAAgB,GAAG,gBAAgB,CAAC,KAAK,CACvC,CAAC,EACD,gBAAgB,CAAC,MAAM,GAAG,CAAC,CAC5B,CAAC;gBACJ,CAAC,MAAM,CAAC;oBACN,MAAM,KAAK,CAAC;gBACd,CAAC;YACH,CAAC;QACH,CAAC;QAED,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QACvB,YAAY,GAAG,YAAY,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC;IAC7D,CAAC;IAED,OAAO,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,CAAC,EAAE,CAAG,CAAD,AAAE;YAAE,IAAI,EAAE,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE;YAAE,KAAK;QAAA,CAAE,CAAC,CAAC,CAAC;AACpE,CAAC;AAGM,KAAK,UAAU,aAAa,CACjC,GAAW,EACX,aAEmE;IAEnE,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,CAAC;IAEvC,IAAI,KAAK,EAAE,CAAC;QACV,OAAO,KAAK,CAAC;IACf,CAAC;IAED,IAAI,MAAM,GAAa,EAAE,CAAC;IAE1B,IAAK,IAAI,CAAC,GAAG,CAAC,GAAI,CAAC,EAAE,CAAE,CAAC;QACtB,MAAM,SAAS,GAAG,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;QAChC,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,SAAS,CAAC,CAAC;QAE7C,IAAI,CAAC,KAAK,EAAE,CAAC;YACX,MAAM;QACR,CAAC;QAED,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;IACrB,CAAC;IAED,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;QACtB,OAAO,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;IACzB,CAAC;IAED,OAAO,IAAI,CAAC;AACd,CAAC;AAEM,KAAK,UAAU,YAAY,CAChC,GAAW,EACX,aAEmE,EACnE,WAAmD;IAEnD,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,CAAC;IAEvC,IAAI,KAAK,EAAE,CAAC;QACV,MAAM,WAAW,CAAC,GAAG,CAAC,CAAC;IACzB,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,GAAI,CAAC,EAAE,CAAE,CAAC;QACtB,MAAM,SAAS,GAAG,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;QAChC,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,SAAS,CAAC,CAAC;QAE7C,IAAI,CAAC,KAAK,EAAE,CAAC;YACX,MAAM;QACR,CAAC;QAED,MAAM,WAAW,CAAC,SAAS,CAAC,CAAC;IAC/B,CAAC;AACH,CAAC"}},
    {"offset": {"line": 6074, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/utils/base64url.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/utils/base64url.ts"],"sourcesContent":["/**\n * Avoid modifying this file. It's part of\n * https://github.com/supabase-community/base64url-js.  Submit all fixes on\n * that repo!\n */\n\n/**\n * An array of characters that encode 6 bits into a Base64-URL alphabet\n * character.\n */\nconst TO_BASE64URL =\n  \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_\".split(\"\");\n\n/**\n * An array of characters that can appear in a Base64-URL encoded string but\n * should be ignored.\n */\nconst IGNORE_BASE64URL = \" \\t\\n\\r=\".split(\"\");\n\n/**\n * An array of 128 numbers that map a Base64-URL character to 6 bits, or if -2\n * used to skip the character, or if -1 used to error out.\n */\nconst FROM_BASE64URL = (() => {\n  const charMap: number[] = new Array(128);\n\n  for (let i = 0; i < charMap.length; i += 1) {\n    charMap[i] = -1;\n  }\n\n  for (let i = 0; i < IGNORE_BASE64URL.length; i += 1) {\n    charMap[IGNORE_BASE64URL[i].charCodeAt(0)] = -2;\n  }\n\n  for (let i = 0; i < TO_BASE64URL.length; i += 1) {\n    charMap[TO_BASE64URL[i].charCodeAt(0)] = i;\n  }\n\n  return charMap;\n})();\n\n/**\n * Converts a JavaScript string (which may include any valid character) into a\n * Base64-URL encoded string. The string is first encoded in UTF-8 which is\n * then encoded as Base64-URL.\n *\n * @param str The string to convert.\n */\nexport function stringToBase64URL(str: string) {\n  const base64: string[] = [];\n\n  let queue = 0;\n  let queuedBits = 0;\n\n  const emitter = (byte: number) => {\n    queue = (queue << 8) | byte;\n    queuedBits += 8;\n\n    while (queuedBits >= 6) {\n      const pos = (queue >> (queuedBits - 6)) & 63;\n      base64.push(TO_BASE64URL[pos]);\n      queuedBits -= 6;\n    }\n  };\n\n  stringToUTF8(str, emitter);\n\n  if (queuedBits > 0) {\n    queue = queue << (6 - queuedBits);\n    queuedBits = 6;\n\n    while (queuedBits >= 6) {\n      const pos = (queue >> (queuedBits - 6)) & 63;\n      base64.push(TO_BASE64URL[pos]);\n      queuedBits -= 6;\n    }\n  }\n\n  return base64.join(\"\");\n}\n\n/**\n * Converts a Base64-URL encoded string into a JavaScript string. It is assumed\n * that the underlying string has been encoded as UTF-8.\n *\n * @param str The Base64-URL encoded string.\n */\nexport function stringFromBase64URL(str: string) {\n  const conv: string[] = [];\n\n  const emit = (codepoint: number) => {\n    conv.push(String.fromCodePoint(codepoint));\n  };\n\n  const state = {\n    utf8seq: 0,\n    codepoint: 0,\n  };\n\n  let queue = 0;\n  let queuedBits = 0;\n\n  for (let i = 0; i < str.length; i += 1) {\n    const codepoint = str.charCodeAt(i);\n    const bits = FROM_BASE64URL[codepoint];\n\n    if (bits > -1) {\n      // valid Base64-URL character\n      queue = (queue << 6) | bits;\n      queuedBits += 6;\n\n      while (queuedBits >= 8) {\n        stringFromUTF8((queue >> (queuedBits - 8)) & 0xff, state, emit);\n        queuedBits -= 8;\n      }\n    } else if (bits === -2) {\n      // ignore spaces, tabs, newlines, =\n      continue;\n    } else {\n      throw new Error(\n        `Invalid Base64-URL character \"${str.at(i)}\" at position ${i}`,\n      );\n    }\n  }\n\n  return conv.join(\"\");\n}\n\n/**\n * Converts a Unicode codepoint to a multi-byte UTF-8 sequence.\n *\n * @param codepoint The Unicode codepoint.\n * @param emit      Function which will be called for each UTF-8 byte that represents the codepoint.\n */\nexport function codepointToUTF8(\n  codepoint: number,\n  emit: (byte: number) => void,\n) {\n  if (codepoint <= 0x7f) {\n    emit(codepoint);\n    return;\n  } else if (codepoint <= 0x7ff) {\n    emit(0xc0 | (codepoint >> 6));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  } else if (codepoint <= 0xffff) {\n    emit(0xe0 | (codepoint >> 12));\n    emit(0x80 | ((codepoint >> 6) & 0x3f));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  } else if (codepoint <= 0x10ffff) {\n    emit(0xf0 | (codepoint >> 18));\n    emit(0x80 | ((codepoint >> 12) & 0x3f));\n    emit(0x80 | ((codepoint >> 6) & 0x3f));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  }\n\n  throw new Error(`Unrecognized Unicode codepoint: ${codepoint.toString(16)}`);\n}\n\n/**\n * Converts a JavaScript string to a sequence of UTF-8 bytes.\n *\n * @param str  The string to convert to UTF-8.\n * @param emit Function which will be called for each UTF-8 byte of the string.\n */\nexport function stringToUTF8(str: string, emit: (byte: number) => void) {\n  for (let i = 0; i < str.length; i += 1) {\n    let codepoint = str.charCodeAt(i);\n\n    if (codepoint > 0xd7ff && codepoint <= 0xdbff) {\n      // most UTF-16 codepoints are Unicode codepoints, except values in this\n      // range where the next UTF-16 codepoint needs to be combined with the\n      // current one to get the Unicode codepoint\n      const highSurrogate = ((codepoint - 0xd800) * 0x400) & 0xffff;\n      const lowSurrogate = (str.charCodeAt(i + 1) - 0xdc00) & 0xffff;\n      codepoint = (lowSurrogate | highSurrogate) + 0x10000;\n      i += 1;\n    }\n\n    codepointToUTF8(codepoint, emit);\n  }\n}\n\n/**\n * Converts a UTF-8 byte to a Unicode codepoint.\n *\n * @param byte  The UTF-8 byte next in the sequence.\n * @param state The shared state between consecutive UTF-8 bytes in the\n *              sequence, an object with the shape `{ utf8seq: 0, codepoint: 0 }`.\n * @param emit  Function which will be called for each codepoint.\n */\nexport function stringFromUTF8(\n  byte: number,\n  state: { utf8seq: number; codepoint: number },\n  emit: (codepoint: number) => void,\n) {\n  if (state.utf8seq === 0) {\n    if (byte <= 0x7f) {\n      emit(byte);\n      return;\n    }\n\n    // count the number of 1 leading bits until you reach 0\n    for (let leadingBit = 1; leadingBit < 6; leadingBit += 1) {\n      if (((byte >> (7 - leadingBit)) & 1) === 0) {\n        state.utf8seq = leadingBit;\n        break;\n      }\n    }\n\n    if (state.utf8seq === 2) {\n      state.codepoint = byte & 31;\n    } else if (state.utf8seq === 3) {\n      state.codepoint = byte & 15;\n    } else if (state.utf8seq === 4) {\n      state.codepoint = byte & 7;\n    } else {\n      throw new Error(\"Invalid UTF-8 sequence\");\n    }\n\n    state.utf8seq -= 1;\n  } else if (state.utf8seq > 0) {\n    if (byte <= 0x7f) {\n      throw new Error(\"Invalid UTF-8 sequence\");\n    }\n\n    state.codepoint = (state.codepoint << 6) | (byte & 63);\n    state.utf8seq -= 1;\n\n    if (state.utf8seq === 0) {\n      emit(state.codepoint);\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;;;;GAIG,CAEH;;;GAGG,CACH,MAAM,YAAY,GAChB,kEAAkE,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;AAE/E;;;GAGG,CACH,MAAM,gBAAgB,GAAG,UAAU,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;AAE9C;;;GAGG,CACH,MAAM,cAAc,GAAG,CAAC,GAAG,EAAE;IAC3B,MAAM,OAAO,GAAa,IAAI,KAAK,CAAC,GAAG,CAAC,CAAC;IAEzC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QAC3C,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAClB,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACpD,OAAO,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAClD,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QAChD,OAAO,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;IAC7C,CAAC;IAED,OAAO,OAAO,CAAC;AACjB,CAAC,CAAC,EAAE,CAAC;AASC,SAAU,iBAAiB,CAAC,GAAW;IAC3C,MAAM,MAAM,GAAa,EAAE,CAAC;IAE5B,IAAI,KAAK,GAAG,CAAC,CAAC;IACd,IAAI,UAAU,GAAG,CAAC,CAAC;IAEnB,MAAM,OAAO,GAAG,CAAC,IAAY,EAAE,EAAE;QAC/B,KAAK,GAAG,AAAC,KAAK,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC;QAC5B,UAAU,IAAI,CAAC,CAAC;QAEhB,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;YACvB,MAAM,GAAG,GAAG,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,EAAE,CAAC;YAC7C,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC;YAC/B,UAAU,IAAI,CAAC,CAAC;QAClB,CAAC;IACH,CAAC,CAAC;IAEF,YAAY,CAAC,GAAG,EAAE,OAAO,CAAC,CAAC;IAE3B,IAAI,UAAU,GAAG,CAAC,EAAE,CAAC;QACnB,KAAK,GAAG,KAAK,IAAI,AAAC,CAAC,GAAG,UAAU,CAAC,CAAC;QAClC,UAAU,GAAG,CAAC,CAAC;QAEf,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;YACvB,MAAM,GAAG,GAAG,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,EAAE,CAAC;YAC7C,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC;YAC/B,UAAU,IAAI,CAAC,CAAC;QAClB,CAAC;IACH,CAAC;IAED,OAAO,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACzB,CAAC;AAQK,SAAU,mBAAmB,CAAC,GAAW;IAC7C,MAAM,IAAI,GAAa,EAAE,CAAC;IAE1B,MAAM,IAAI,GAAG,CAAC,SAAiB,EAAE,EAAE;QACjC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC,CAAC;IAC7C,CAAC,CAAC;IAEF,MAAM,KAAK,GAAG;QACZ,OAAO,EAAE,CAAC;QACV,SAAS,EAAE,CAAC;KACb,CAAC;IAEF,IAAI,KAAK,GAAG,CAAC,CAAC;IACd,IAAI,UAAU,GAAG,CAAC,CAAC;IAEnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACvC,MAAM,SAAS,GAAG,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,IAAI,GAAG,cAAc,CAAC,SAAS,CAAC,CAAC;QAEvC,IAAI,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC;YACd,6BAA6B;YAC7B,KAAK,GAAG,AAAC,KAAK,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC;YAC5B,UAAU,IAAI,CAAC,CAAC;YAEhB,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;gBACvB,cAAc,CAAC,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;gBAChE,UAAU,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC,MAAM,IAAI,IAAI,KAAK,CAAC,CAAC,EAAE,CAAC;YAEvB,SAAS;QACX,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,KAAK,CACb,CAAA,8BAAA,EAAiC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAA,cAAA,EAAiB,CAAC,EAAE,CAC/D,CAAC;QACJ,CAAC;IACH,CAAC;IAED,OAAO,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACvB,CAAC;AAQK,SAAU,eAAe,CAC7B,SAAiB,EACjB,IAA4B;IAE5B,IAAI,SAAS,IAAI,IAAI,EAAE,CAAC;QACtB,IAAI,CAAC,SAAS,CAAC,CAAC;QAChB,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,KAAK,EAAE,CAAC;QAC9B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,CAAC,CAAC,CAAC,CAAC;QAC9B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,EAAE,CAAC,CAAC,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAK,AAAD,AAAD,SAAW,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,QAAQ,EAAE,CAAC;QACjC,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,EAAE,CAAC,CAAC,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAG,AAAC,AAAC,SAAS,IAAI,EAAE,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACxC,IAAI,CAAC,IAAI,GAAK,AAAF,AAAC,SAAU,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,IAAI,GAAI,AAAD,SAAU,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC;IAED,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EAAmC,SAAS,CAAC,QAAQ,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;AAC/E,CAAC;AAQK,SAAU,YAAY,CAAC,GAAW,EAAE,IAA4B;IACpE,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACvC,IAAI,SAAS,GAAG,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QAElC,IAAI,SAAS,GAAG,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,CAAC;YAC9C,uEAAuE;YACvE,sEAAsE;YACtE,2CAA2C;YAC3C,MAAM,aAAa,GAAG,AAAC,CAAC,SAAS,GAAG,MAAM,CAAC,GAAG,KAAK,CAAC,EAAG,MAAM,CAAC;YAC9D,MAAM,YAAY,GAAG,AAAC,GAAG,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,EAAG,MAAM,CAAC;YAC/D,SAAS,GAAG,CAAC,YAAY,GAAG,aAAa,CAAC,GAAG,OAAO,CAAC;YACrD,CAAC,IAAI,CAAC,CAAC;QACT,CAAC;QAED,eAAe,CAAC,SAAS,EAAE,IAAI,CAAC,CAAC;IACnC,CAAC;AACH,CAAC;AAUK,SAAU,cAAc,CAC5B,IAAY,EACZ,KAA6C,EAC7C,IAAiC;IAEjC,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;QACxB,IAAI,IAAI,IAAI,IAAI,EAAE,CAAC;YACjB,IAAI,CAAC,IAAI,CAAC,CAAC;YACX,OAAO;QACT,CAAC;QAED,uDAAuD;QACvD,IAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,CAAC,EAAE,UAAU,IAAI,CAAC,CAAE,CAAC;YACzD,IAAI,CAAC,AAAC,IAAI,IAAI,AAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAG,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC;gBAC3C,KAAK,CAAC,OAAO,GAAG,UAAU,CAAC;gBAC3B,MAAM;YACR,CAAC;QACH,CAAC;QAED,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YACxB,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,EAAE,CAAC;QAC9B,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YAC/B,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,EAAE,CAAC;QAC9B,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YAC/B,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,CAAC,CAAC;QAC7B,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,KAAK,CAAC,wBAAwB,CAAC,CAAC;QAC5C,CAAC;QAED,KAAK,CAAC,OAAO,IAAI,CAAC,CAAC;IACrB,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,GAAG,CAAC,EAAE,CAAC;QAC7B,IAAI,IAAI,IAAI,IAAI,EAAE,CAAC;YACjB,MAAM,IAAI,KAAK,CAAC,wBAAwB,CAAC,CAAC;QAC5C,CAAC;QAED,KAAK,CAAC,SAAS,GAAG,AAAC,KAAK,CAAC,SAAS,IAAI,CAAC,CAAC,EAAI,CAAD,GAAK,GAAG,EAAE,CAAC,CAAC;QACvD,KAAK,CAAC,OAAO,IAAI,CAAC,CAAC;QAEnB,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YACxB,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;AACH,CAAC"}},
    {"offset": {"line": 6244, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/utils/index.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/utils/index.ts"],"sourcesContent":["export * from \"./helpers\";\nexport * from \"./constants\";\nexport * from \"./chunker\";\nexport * from \"./base64url\";\n"],"names":[],"mappings":";AAAA,cAAc,WAAW,CAAC;AAC1B,cAAc,aAAa,CAAC;AAC5B,cAAc,WAAW,CAAC;AAC1B,cAAc,aAAa,CAAC"}},
    {"offset": {"line": 6257, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/cookies.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/cookies.ts"],"sourcesContent":["import { parse, serialize } from \"cookie\";\n\nimport {\n  DEFAULT_COOKIE_OPTIONS,\n  combineChunks,\n  createChunks,\n  isBrowser,\n  isChunkLike,\n  stringFromBase64URL,\n  stringToBase64URL,\n} from \"./utils\";\n\nimport type {\n  CookieMethodsServer,\n  CookieMethodsServerDeprecated,\n  CookieMethodsBrowser,\n  CookieMethodsBrowserDeprecated,\n  CookieOptions,\n  CookieOptionsWithName,\n  GetAllCookies,\n  SetAllCookies,\n} from \"./types\";\n\nconst BASE64_PREFIX = \"base64-\";\n\n/**\n * Creates a storage client that handles cookies correctly for browser and\n * server clients with or without properly provided cookie methods.\n *\n * @param options The options passed to createBrowserClient or createServer client.\n *\n * @param isServerClient Whether it's called from createServerClient.\n */\nexport function createStorageFromOptions(\n  options: {\n    cookieEncoding: \"raw\" | \"base64url\";\n    cookies?:\n      | CookieMethodsBrowser\n      | CookieMethodsBrowserDeprecated\n      | CookieMethodsServer\n      | CookieMethodsServerDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n  },\n  isServerClient: boolean,\n) {\n  const cookies = options.cookies ?? null;\n  const cookieEncoding = options.cookieEncoding;\n\n  const setItems: { [key: string]: string } = {};\n  const removedItems: { [key: string]: boolean } = {};\n\n  let getAll: (keyHints: string[]) => ReturnType<GetAllCookies>;\n  let setAll: SetAllCookies;\n\n  if (cookies) {\n    if (\"get\" in cookies) {\n      // Just get is not enough, because the client needs to see what cookies\n      // are already set and unset them if necessary. To attempt to fix this\n      // behavior for most use cases, we pass \"hints\" which is the keys of the\n      // storage items. They are then converted to their corresponding cookie\n      // chunk names and are fetched with get. Only 5 chunks are fetched, which\n      // should be enough for the majority of use cases, but does not solve\n      // those with very large sessions.\n\n      const getWithHints = async (keyHints: string[]) => {\n        // optimistically find the first 5 potential chunks for the specified key\n        const chunkNames = keyHints.flatMap((keyHint) => [\n          keyHint,\n          ...Array.from({ length: 5 }).map((_, i) => `${keyHint}.${i}`),\n        ]);\n\n        const chunks: ReturnType<GetAllCookies> = [];\n\n        for (let i = 0; i < chunkNames.length; i += 1) {\n          const value = await cookies.get(chunkNames[i]);\n\n          if (!value && typeof value !== \"string\") {\n            continue;\n          }\n\n          chunks.push({ name: chunkNames[i], value });\n        }\n\n        // TODO: detect and log stale chunks error\n\n        return chunks;\n      };\n\n      getAll = async (keyHints: string[]) => await getWithHints(keyHints);\n\n      if (\"set\" in cookies && \"remove\" in cookies) {\n        setAll = async (setCookies) => {\n          for (let i = 0; i < setCookies.length; i += 1) {\n            const { name, value, options } = setCookies[i];\n\n            if (value) {\n              await cookies.set!(name, value, options);\n            } else {\n              await cookies.remove!(name, options);\n            }\n          }\n        };\n      } else if (isServerClient) {\n        setAll = async () => {\n          console.warn(\n            \"@supabase/ssr: createServerClient was configured without set and remove cookie methods, but the client needs to set cookies. This can lead to issues such as random logouts, early session termination or increased token refresh requests. If in NextJS, check your middleware.ts file, route handlers and server actions for correctness. Consider switching to the getAll and setAll cookie methods instead of get, set and remove which are deprecated and can be difficult to use correctly.\",\n          );\n        };\n      } else {\n        throw new Error(\n          \"@supabase/ssr: createBrowserClient requires configuring a getAll and setAll cookie method (deprecated: alternatively both get, set and remove can be used)\",\n        );\n      }\n    } else if (\"getAll\" in cookies) {\n      getAll = async () => await cookies.getAll!();\n\n      if (\"setAll\" in cookies) {\n        setAll = cookies.setAll!;\n      } else if (isServerClient) {\n        setAll = async () => {\n          console.warn(\n            \"@supabase/ssr: createServerClient was configured without the setAll cookie method, but the client needs to set cookies. This can lead to issues such as random logouts, early session termination or increased token refresh requests. If in NextJS, check your middleware.ts file, route handlers and server actions for correctness.\",\n          );\n        };\n      } else {\n        throw new Error(\n          \"@supabase/ssr: createBrowserClient requires configuring both getAll and setAll cookie methods (deprecated: alternatively both get, set and remove can be used)\",\n        );\n      }\n    } else {\n      // neither get nor getAll is present on cookies, only will occur if pure JavaScript is used, but cookies is an object\n      throw new Error(\n        `@supabase/ssr: ${isServerClient ? \"createServerClient\" : \"createBrowserClient\"} requires configuring getAll and setAll cookie methods (deprecated: alternatively use get, set and remove).${isBrowser() ? \" As this is called in a browser runtime, consider removing the cookies option object to use the document.cookie API automatically.\" : \"\"}`,\n      );\n    }\n  } else if (!isServerClient && isBrowser()) {\n    // The environment is browser, so use the document.cookie API to implement getAll and setAll.\n\n    const noHintGetAll = () => {\n      const parsed = parse(document.cookie);\n\n      return Object.keys(parsed).map((name) => ({\n        name,\n        value: parsed[name] ?? \"\",\n      }));\n    };\n\n    getAll = () => noHintGetAll();\n\n    setAll = (setCookies) => {\n      setCookies.forEach(({ name, value, options }) => {\n        document.cookie = serialize(name, value, options);\n      });\n    };\n  } else if (isServerClient) {\n    throw new Error(\n      \"@supabase/ssr: createServerClient must be initialized with cookie options that specify getAll and setAll functions (deprecated, not recommended: alternatively use get, set and remove)\",\n    );\n  } else {\n    // getting cookies when there's no window but we're in browser mode can be OK, because the developer probably is not using auth functions\n    getAll = () => {\n      return [];\n    };\n\n    // this is NOT OK because the developer is using auth functions that require setting some state, so that must error out\n    setAll = () => {\n      throw new Error(\n        \"@supabase/ssr: createBrowserClient in non-browser runtimes (including Next.js pre-rendering mode) was not initialized cookie options that specify getAll and setAll functions (deprecated: alternatively use get, set and remove), but they were needed\",\n      );\n    };\n  }\n\n  if (!isServerClient) {\n    // This is the storage client to be used in browsers. It only\n    // works on the cookies abstraction, unlike the server client\n    // which only uses cookies to read the initial state. When an\n    // item is set, cookies are both cleared and set to values so\n    // that stale chunks are not left remaining.\n    return {\n      getAll, // for type consistency\n      setAll, // for type consistency\n      setItems, // for type consistency\n      removedItems, // for type consistency\n      storage: {\n        isServer: false,\n        getItem: async (key: string) => {\n          const allCookies = await getAll([key]);\n          const chunkedCookie = await combineChunks(\n            key,\n            async (chunkName: string) => {\n              const cookie =\n                allCookies?.find(({ name }) => name === chunkName) || null;\n\n              if (!cookie) {\n                return null;\n              }\n\n              return cookie.value;\n            },\n          );\n\n          if (!chunkedCookie) {\n            return null;\n          }\n\n          let decoded = chunkedCookie;\n\n          if (chunkedCookie.startsWith(BASE64_PREFIX)) {\n            decoded = stringFromBase64URL(\n              chunkedCookie.substring(BASE64_PREFIX.length),\n            );\n          }\n\n          return decoded;\n        },\n        setItem: async (key: string, value: string) => {\n          const allCookies = await getAll([key]);\n          const cookieNames = allCookies?.map(({ name }) => name) || [];\n\n          const removeCookies = new Set(\n            cookieNames.filter((name) => isChunkLike(name, key)),\n          );\n\n          let encoded = value;\n\n          if (cookieEncoding === \"base64url\") {\n            encoded = BASE64_PREFIX + stringToBase64URL(value);\n          }\n\n          const setCookies = createChunks(key, encoded);\n\n          setCookies.forEach(({ name }) => {\n            removeCookies.delete(name);\n          });\n\n          const removeCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: 0,\n          };\n          const setCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: DEFAULT_COOKIE_OPTIONS.maxAge,\n          };\n\n          // the NextJS cookieStore API can get confused if the `name` from\n          // options.cookieOptions leaks\n          delete removeCookieOptions.name;\n          delete setCookieOptions.name;\n\n          const allToSet = [\n            ...[...removeCookies].map((name) => ({\n              name,\n              value: \"\",\n              options: removeCookieOptions,\n            })),\n            ...setCookies.map(({ name, value }) => ({\n              name,\n              value,\n              options: setCookieOptions,\n            })),\n          ];\n\n          if (allToSet.length > 0) {\n            await setAll(allToSet);\n          }\n        },\n        removeItem: async (key: string) => {\n          const allCookies = await getAll([key]);\n          const cookieNames = allCookies?.map(({ name }) => name) || [];\n          const removeCookies = cookieNames.filter((name) =>\n            isChunkLike(name, key),\n          );\n\n          const removeCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: 0,\n          };\n\n          // the NextJS cookieStore API can get confused if the `name` from\n          // options.cookieOptions leaks\n          delete removeCookieOptions.name;\n\n          if (removeCookies.length > 0) {\n            await setAll(\n              removeCookies.map((name) => ({\n                name,\n                value: \"\",\n                options: removeCookieOptions,\n              })),\n            );\n          }\n        },\n      },\n    };\n  }\n\n  // This is the server client. It only uses getAll to read the initial\n  // state. Any subsequent changes to the items is persisted in the\n  // setItems and removedItems objects. createServerClient *must* use\n  // getAll, setAll and the values in setItems and removedItems to\n  // persist the changes *at once* when appropriate (usually only when\n  // the TOKEN_REFRESHED, USER_UPDATED or SIGNED_OUT events are fired by\n  // the Supabase Auth client).\n  return {\n    getAll,\n    setAll,\n    setItems,\n    removedItems,\n    storage: {\n      // to signal to the libraries that these cookies are\n      // coming from a server environment and their value\n      // should not be trusted\n      isServer: true,\n      getItem: async (key: string) => {\n        if (typeof setItems[key] === \"string\") {\n          return setItems[key];\n        }\n\n        if (removedItems[key]) {\n          return null;\n        }\n\n        const allCookies = await getAll([key]);\n        const chunkedCookie = await combineChunks(\n          key,\n          async (chunkName: string) => {\n            const cookie =\n              allCookies?.find(({ name }) => name === chunkName) || null;\n\n            if (!cookie) {\n              return null;\n            }\n\n            return cookie.value;\n          },\n        );\n\n        if (!chunkedCookie) {\n          return null;\n        }\n\n        let decoded = chunkedCookie;\n\n        if (\n          typeof chunkedCookie === \"string\" &&\n          chunkedCookie.startsWith(BASE64_PREFIX)\n        ) {\n          decoded = stringFromBase64URL(\n            chunkedCookie.substring(BASE64_PREFIX.length),\n          );\n        }\n\n        return decoded;\n      },\n      setItem: async (key: string, value: string) => {\n        // We don't have an `onAuthStateChange` event that can let us know that\n        // the PKCE code verifier is being set. Therefore, if we see it being\n        // set, we need to apply the storage (call `setAll` so the cookie is\n        // set properly).\n        if (key.endsWith(\"-code-verifier\")) {\n          await applyServerStorage(\n            {\n              getAll,\n              setAll,\n              // pretend only that the code verifier was set\n              setItems: { [key]: value },\n              // pretend that nothing was removed\n              removedItems: {},\n            },\n            {\n              cookieOptions: options?.cookieOptions ?? null,\n              cookieEncoding,\n            },\n          );\n        }\n\n        setItems[key] = value;\n        delete removedItems[key];\n      },\n      removeItem: async (key: string) => {\n        // Intentionally not applying the storage when the key is the PKCE code\n        // verifier, as usually right after it's removed other items are set,\n        // so application of the storage will be handled by the\n        // `onAuthStateChange` callback that follows removal -- usually as part\n        // of the `exchangeCodeForSession` call.\n        delete setItems[key];\n        removedItems[key] = true;\n      },\n    },\n  };\n}\n\n/**\n * When createServerClient needs to apply the created storage to cookies, it\n * should call this function which handles correcly setting cookies for stored\n * and removed items in the storage.\n */\nexport async function applyServerStorage(\n  {\n    getAll,\n    setAll,\n    setItems,\n    removedItems,\n  }: {\n    getAll: (keyHints: string[]) => ReturnType<GetAllCookies>;\n    setAll: SetAllCookies;\n    setItems: { [name: string]: string };\n    removedItems: { [name: string]: boolean };\n  },\n  options: {\n    cookieEncoding: \"raw\" | \"base64url\";\n    cookieOptions?: CookieOptions | null;\n  },\n) {\n  const cookieEncoding = options.cookieEncoding;\n  const cookieOptions = options.cookieOptions ?? null;\n\n  const allCookies = await getAll([\n    ...(setItems ? (Object.keys(setItems) as string[]) : []),\n    ...(removedItems ? (Object.keys(removedItems) as string[]) : []),\n  ]);\n  const cookieNames = allCookies?.map(({ name }) => name) || [];\n\n  const removeCookies: string[] = Object.keys(removedItems).flatMap(\n    (itemName) => {\n      return cookieNames.filter((name) => isChunkLike(name, itemName));\n    },\n  );\n\n  const setCookies = Object.keys(setItems).flatMap((itemName) => {\n    const removeExistingCookiesForItem = new Set(\n      cookieNames.filter((name) => isChunkLike(name, itemName)),\n    );\n\n    let encoded = setItems[itemName];\n\n    if (cookieEncoding === \"base64url\") {\n      encoded = BASE64_PREFIX + stringToBase64URL(encoded);\n    }\n\n    const chunks = createChunks(itemName, encoded);\n\n    chunks.forEach((chunk) => {\n      removeExistingCookiesForItem.delete(chunk.name);\n    });\n\n    removeCookies.push(...removeExistingCookiesForItem);\n\n    return chunks;\n  });\n\n  const removeCookieOptions = {\n    ...DEFAULT_COOKIE_OPTIONS,\n    ...cookieOptions,\n    maxAge: 0,\n  };\n  const setCookieOptions = {\n    ...DEFAULT_COOKIE_OPTIONS,\n    ...cookieOptions,\n    maxAge: DEFAULT_COOKIE_OPTIONS.maxAge,\n  };\n\n  // the NextJS cookieStore API can get confused if the `name` from\n  // options.cookieOptions leaks\n  delete (removeCookieOptions as any).name;\n  delete (setCookieOptions as any).name;\n\n  await setAll([\n    ...removeCookies.map((name) => ({\n      name,\n      value: \"\",\n      options: removeCookieOptions,\n    })),\n    ...setCookies.map(({ name, value }) => ({\n      name,\n      value,\n      options: setCookieOptions,\n    })),\n  ]);\n}\n"],"names":[],"mappings":";;;;;;AAAA,OAAO,EAAE,KAAK,EAAE,SAAS,EAAE,MAAM,QAAQ,CAAC;;;;;AAE1C,OAAO,EACL,sBAAsB,EACtB,aAAa,EACb,YAAY,EACZ,SAAS,EACT,WAAW,EACX,mBAAmB,EACnB,iBAAiB,GAClB,MAAM,SAAS,CAAC;;;AAajB,MAAM,aAAa,GAAG,SAAS,CAAC;AAU1B,SAAU,wBAAwB,CACtC,OAQC,EACD,cAAuB;IAEvB,MAAM,OAAO,GAAG,OAAO,CAAC,OAAO,IAAI,IAAI,CAAC;IACxC,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc,CAAC;IAE9C,MAAM,QAAQ,GAA8B,CAAA,CAAE,CAAC;IAC/C,MAAM,YAAY,GAA+B,CAAA,CAAE,CAAC;IAEpD,IAAI,MAAyD,CAAC;IAC9D,IAAI,MAAqB,CAAC;IAE1B,IAAI,OAAO,EAAE,CAAC;QACZ,IAAI,KAAK,IAAI,OAAO,EAAE,CAAC;YACrB,uEAAuE;YACvE,sEAAsE;YACtE,wEAAwE;YACxE,uEAAuE;YACvE,yEAAyE;YACzE,qEAAqE;YACrE,kCAAkC;YAElC,MAAM,YAAY,GAAG,KAAK,EAAE,QAAkB,EAAE,EAAE;gBAChD,yEAAyE;gBACzE,MAAM,UAAU,GAAG,QAAQ,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,CAAG,CAAD;wBAC9C,OAAO;2BACJ,KAAK,CAAC,IAAI,CAAC;4BAAE,MAAM,EAAE,CAAC;wBAAA,CAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAG,CAAD,EAAI,OAAO,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;qBAC9D,CAAC,CAAC;gBAEH,MAAM,MAAM,GAA8B,EAAE,CAAC;gBAE7C,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;oBAC9C,MAAM,KAAK,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;oBAE/C,IAAI,CAAC,KAAK,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;wBACxC,SAAS;oBACX,CAAC;oBAED,MAAM,CAAC,IAAI,CAAC;wBAAE,IAAI,EAAE,UAAU,CAAC,CAAC,CAAC;wBAAE,KAAK;oBAAA,CAAE,CAAC,CAAC;gBAC9C,CAAC;gBAED,0CAA0C;gBAE1C,OAAO,MAAM,CAAC;YAChB,CAAC,CAAC;YAEF,MAAM,GAAG,KAAK,EAAE,QAAkB,EAAE,CAAG,CAAD,KAAO,YAAY,CAAC,QAAQ,CAAC,CAAC;YAEpE,IAAI,KAAK,IAAI,OAAO,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;gBAC5C,MAAM,GAAG,KAAK,EAAE,UAAU,EAAE,EAAE;oBAC5B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;wBAC9C,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;wBAE/C,IAAI,KAAK,EAAE,CAAC;4BACV,MAAM,OAAO,CAAC,GAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;wBAC3C,CAAC,MAAM,CAAC;4BACN,MAAM,OAAO,CAAC,MAAO,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;wBACvC,CAAC;oBACH,CAAC;gBACH,CAAC,CAAC;YACJ,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;gBAC1B,MAAM,GAAG,KAAK,IAAI,EAAE;oBAClB,OAAO,CAAC,IAAI,CACV,meAAme,CACpe,CAAC;gBACJ,CAAC,CAAC;YACJ,CAAC,MAAM,CAAC;gBACN,MAAM,IAAI,KAAK,CACb,4JAA4J,CAC7J,CAAC;YACJ,CAAC;QACH,CAAC,MAAM,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;YAC/B,MAAM,GAAG,KAAK,IAAI,CAAG,CAAD,KAAO,OAAO,CAAC,MAAO,EAAE,CAAC;YAE7C,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;gBACxB,MAAM,GAAG,OAAO,CAAC,MAAO,CAAC;YAC3B,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;gBAC1B,MAAM,GAAG,KAAK,IAAI,EAAE;oBAClB,OAAO,CAAC,IAAI,CACV,wUAAwU,CACzU,CAAC;gBACJ,CAAC,CAAC;YACJ,CAAC,MAAM,CAAC;gBACN,MAAM,IAAI,KAAK,CACb,gKAAgK,CACjK,CAAC;YACJ,CAAC;QACH,CAAC,MAAM,CAAC;YACN,qHAAqH;YACrH,MAAM,IAAI,KAAK,CACb,CAAA,eAAA,EAAkB,cAAc,CAAC,CAAC,CAAC,oBAAoB,CAAC,CAAC,CAAC,qBAAqB,CAAA,2GAAA,MAA8G,6QAAS,EAAE,CAAC,CAAC,EAAC,oIAAoI,CAAC,CAAC,CAAC,EAAE,EAAE,CACvV,CAAC;QACJ,CAAC;IACH,CAAC,MAAM,IAAI,CAAC,cAAc,QAAI,6QAAS,EAAE,GAAE,CAAC;QAC1C,6FAA6F;QAE7F,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,OAAG,0MAAK,EAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YAEtC,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;oBACxC,IAAI;oBACJ,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE;iBAC1B,CAAC,CAAC,CAAC;QACN,CAAC,CAAC;QAEF,MAAM,GAAG,GAAG,CAAG,CAAD,WAAa,EAAE,CAAC;QAE9B,MAAM,GAAG,CAAC,UAAU,EAAE,EAAE;YACtB,UAAU,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,EAAE,EAAE;gBAC9C,QAAQ,CAAC,MAAM,OAAG,8MAAS,EAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;YACpD,CAAC,CAAC,CAAC;QACL,CAAC,CAAC;IACJ,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;QAC1B,MAAM,IAAI,KAAK,CACb,yLAAyL,CAC1L,CAAC;IACJ,CAAC,MAAM,CAAC;QACN,yIAAyI;QACzI,MAAM,GAAG,GAAG,EAAE;YACZ,OAAO,EAAE,CAAC;QACZ,CAAC,CAAC;QAEF,uHAAuH;QACvH,MAAM,GAAG,GAAG,EAAE;YACZ,MAAM,IAAI,KAAK,CACb,yPAAyP,CAC1P,CAAC;QACJ,CAAC,CAAC;IACJ,CAAC;IAED,IAAI,CAAC,cAAc,EAAE,CAAC;QACpB,6DAA6D;QAC7D,6DAA6D;QAC7D,6DAA6D;QAC7D,6DAA6D;QAC7D,4CAA4C;QAC5C,OAAO;YACL,MAAM,EAAE,uBAAuB;YAC/B,MAAM,EAAE,uBAAuB;YAC/B,QAAQ,EAAE,uBAAuB;YACjC,YAAY,EAAE,uBAAuB;YACrC,OAAO,EAAE;gBACP,QAAQ,EAAE,KAAK;gBACf,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;oBAC7B,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,aAAa,GAAG,UAAM,iRAAa,EACvC,GAAG,EACH,KAAK,EAAE,SAAiB,EAAE,EAAE;wBAC1B,MAAM,MAAM,GACV,UAAU,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,KAAK,SAAS,CAAC,IAAI,IAAI,CAAC;wBAE7D,IAAI,CAAC,MAAM,EAAE,CAAC;4BACZ,OAAO,IAAI,CAAC;wBACd,CAAC;wBAED,OAAO,MAAM,CAAC,KAAK,CAAC;oBACtB,CAAC,CACF,CAAC;oBAEF,IAAI,CAAC,aAAa,EAAE,CAAC;wBACnB,OAAO,IAAI,CAAC;oBACd,CAAC;oBAED,IAAI,OAAO,GAAG,aAAa,CAAC;oBAE5B,IAAI,aAAa,CAAC,UAAU,CAAC,aAAa,CAAC,EAAE,CAAC;wBAC5C,OAAO,OAAG,yRAAmB,EAC3B,aAAa,CAAC,SAAS,CAAC,aAAa,CAAC,MAAM,CAAC,CAC9C,CAAC;oBACJ,CAAC;oBAED,OAAO,OAAO,CAAC;gBACjB,CAAC;gBACD,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,KAAa,EAAE,EAAE;oBAC5C,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;oBAE9D,MAAM,aAAa,GAAG,IAAI,GAAG,CAC3B,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,GAAC,+QAAW,EAAC,IAAI,EAAE,GAAG,CAAC,CAAC,CACrD,CAAC;oBAEF,IAAI,OAAO,GAAG,KAAK,CAAC;oBAEpB,IAAI,cAAc,KAAK,WAAW,EAAE,CAAC;wBACnC,OAAO,GAAG,aAAa,OAAG,uRAAiB,EAAC,KAAK,CAAC,CAAC;oBACrD,CAAC;oBAED,MAAM,UAAU,OAAG,gRAAY,EAAC,GAAG,EAAE,OAAO,CAAC,CAAC;oBAE9C,UAAU,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE;wBAC9B,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;oBAC7B,CAAC,CAAC,CAAC;oBAEH,MAAM,mBAAmB,GAAG;wBAC1B,GAAG,4RAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,CAAC;qBACV,CAAC;oBACF,MAAM,gBAAgB,GAAG;wBACvB,GAAG,4RAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,4RAAsB,CAAC,MAAM;qBACtC,CAAC;oBAEF,iEAAiE;oBACjE,8BAA8B;oBAC9B,OAAO,mBAAmB,CAAC,IAAI,CAAC;oBAChC,OAAO,gBAAgB,CAAC,IAAI,CAAC;oBAE7B,MAAM,QAAQ,GAAG;2BACZ,CAAC;+BAAG,aAAa;yBAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gCACnC,IAAI;gCACJ,KAAK,EAAE,EAAE;gCACT,OAAO,EAAE,mBAAmB;6BAC7B,CAAC,CAAC;2BACA,UAAU,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,EAAE,CAAG,CAAD,AAAE;gCACtC,IAAI;gCACJ,KAAK;gCACL,OAAO,EAAE,gBAAgB;6BAC1B,CAAC,CAAC;qBACJ,CAAC;oBAEF,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBACxB,MAAM,MAAM,CAAC,QAAQ,CAAC,CAAC;oBACzB,CAAC;gBACH,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;oBAChC,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;oBAC9D,MAAM,aAAa,GAAG,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,GAChD,+QAAW,EAAC,IAAI,EAAE,GAAG,CAAC,CACvB,CAAC;oBAEF,MAAM,mBAAmB,GAAG;wBAC1B,GAAG,4RAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,CAAC;qBACV,CAAC;oBAEF,iEAAiE;oBACjE,8BAA8B;oBAC9B,OAAO,mBAAmB,CAAC,IAAI,CAAC;oBAEhC,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBAC7B,MAAM,MAAM,CACV,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gCAC3B,IAAI;gCACJ,KAAK,EAAE,EAAE;gCACT,OAAO,EAAE,mBAAmB;6BAC7B,CAAC,CAAC,CACJ,CAAC;oBACJ,CAAC;gBACH,CAAC;aACF;SACF,CAAC;IACJ,CAAC;IAED,qEAAqE;IACrE,iEAAiE;IACjE,mEAAmE;IACnE,gEAAgE;IAChE,oEAAoE;IACpE,sEAAsE;IACtE,6BAA6B;IAC7B,OAAO;QACL,MAAM;QACN,MAAM;QACN,QAAQ;QACR,YAAY;QACZ,OAAO,EAAE;YACP,oDAAoD;YACpD,mDAAmD;YACnD,wBAAwB;YACxB,QAAQ,EAAE,IAAI;YACd,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;gBAC7B,IAAI,OAAO,QAAQ,CAAC,GAAG,CAAC,KAAK,QAAQ,EAAE,CAAC;oBACtC,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAC;gBACvB,CAAC;gBAED,IAAI,YAAY,CAAC,GAAG,CAAC,EAAE,CAAC;oBACtB,OAAO,IAAI,CAAC;gBACd,CAAC;gBAED,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;oBAAC,GAAG;iBAAC,CAAC,CAAC;gBACvC,MAAM,aAAa,GAAG,UAAM,iRAAa,EACvC,GAAG,EACH,KAAK,EAAE,SAAiB,EAAE,EAAE;oBAC1B,MAAM,MAAM,GACV,UAAU,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,KAAK,SAAS,CAAC,IAAI,IAAI,CAAC;oBAE7D,IAAI,CAAC,MAAM,EAAE,CAAC;wBACZ,OAAO,IAAI,CAAC;oBACd,CAAC;oBAED,OAAO,MAAM,CAAC,KAAK,CAAC;gBACtB,CAAC,CACF,CAAC;gBAEF,IAAI,CAAC,aAAa,EAAE,CAAC;oBACnB,OAAO,IAAI,CAAC;gBACd,CAAC;gBAED,IAAI,OAAO,GAAG,aAAa,CAAC;gBAE5B,IACE,OAAO,aAAa,KAAK,QAAQ,IACjC,aAAa,CAAC,UAAU,CAAC,aAAa,CAAC,EACvC,CAAC;oBACD,OAAO,OAAG,yRAAmB,EAC3B,aAAa,CAAC,SAAS,CAAC,aAAa,CAAC,MAAM,CAAC,CAC9C,CAAC;gBACJ,CAAC;gBAED,OAAO,OAAO,CAAC;YACjB,CAAC;YACD,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,KAAa,EAAE,EAAE;gBAC5C,uEAAuE;gBACvE,qEAAqE;gBACrE,oEAAoE;gBACpE,iBAAiB;gBACjB,IAAI,GAAG,CAAC,QAAQ,CAAC,gBAAgB,CAAC,EAAE,CAAC;oBACnC,MAAM,kBAAkB,CACtB;wBACE,MAAM;wBACN,MAAM;wBACN,8CAA8C;wBAC9C,QAAQ,EAAE;4BAAE,CAAC,GAAG,CAAC,EAAE,KAAK;wBAAA,CAAE;wBAC1B,mCAAmC;wBACnC,YAAY,EAAE,CAAA,CAAE;qBACjB,EACD;wBACE,aAAa,EAAE,OAAO,EAAE,aAAa,IAAI,IAAI;wBAC7C,cAAc;qBACf,CACF,CAAC;gBACJ,CAAC;gBAED,QAAQ,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC;gBACtB,OAAO,YAAY,CAAC,GAAG,CAAC,CAAC;YAC3B,CAAC;YACD,UAAU,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;gBAChC,uEAAuE;gBACvE,qEAAqE;gBACrE,uDAAuD;gBACvD,uEAAuE;gBACvE,wCAAwC;gBACxC,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAC;gBACrB,YAAY,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC;YAC3B,CAAC;SACF;KACF,CAAC;AACJ,CAAC;AAOM,KAAK,UAAU,kBAAkB,CACtC,EACE,MAAM,EACN,MAAM,EACN,QAAQ,EACR,YAAY,EAMb,EACD,OAGC;IAED,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc,CAAC;IAC9C,MAAM,aAAa,GAAG,OAAO,CAAC,aAAa,IAAI,IAAI,CAAC;IAEpD,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;WAC1B,QAAQ,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAc,CAAC,CAAC,CAAC,EAAE,CAAC;WACpD,YAAY,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,YAAY,CAAc,CAAC,CAAC,CAAC,EAAE,CAAC;KACjE,CAAC,CAAC;IACH,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;IAE9D,MAAM,aAAa,GAAa,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,OAAO,CAC/D,CAAC,QAAQ,EAAE,EAAE;QACX,OAAO,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,GAAC,+QAAW,EAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,CAAC;IACnE,CAAC,CACF,CAAC;IAEF,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,EAAE;QAC5D,MAAM,4BAA4B,GAAG,IAAI,GAAG,CAC1C,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,GAAC,+QAAW,EAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,CAC1D,CAAC;QAEF,IAAI,OAAO,GAAG,QAAQ,CAAC,QAAQ,CAAC,CAAC;QAEjC,IAAI,cAAc,KAAK,WAAW,EAAE,CAAC;YACnC,OAAO,GAAG,aAAa,OAAG,uRAAiB,EAAC,OAAO,CAAC,CAAC;QACvD,CAAC;QAED,MAAM,MAAM,OAAG,gRAAY,EAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QAE/C,MAAM,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,EAAE;YACvB,4BAA4B,CAAC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;QAClD,CAAC,CAAC,CAAC;QAEH,aAAa,CAAC,IAAI,CAAC,GAAG,4BAA4B,CAAC,CAAC;QAEpD,OAAO,MAAM,CAAC;IAChB,CAAC,CAAC,CAAC;IAEH,MAAM,mBAAmB,GAAG;QAC1B,GAAG,4RAAsB;QACzB,GAAG,aAAa;QAChB,MAAM,EAAE,CAAC;KACV,CAAC;IACF,MAAM,gBAAgB,GAAG;QACvB,GAAG,4RAAsB;QACzB,GAAG,aAAa;QAChB,MAAM,EAAE,4RAAsB,CAAC,MAAM;KACtC,CAAC;IAEF,iEAAiE;IACjE,8BAA8B;IAC9B,OAAQ,mBAA2B,CAAC,IAAI,CAAC;IACzC,OAAQ,gBAAwB,CAAC,IAAI,CAAC;IAEtC,MAAM,MAAM,CAAC;WACR,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gBAC9B,IAAI;gBACJ,KAAK,EAAE,EAAE;gBACT,OAAO,EAAE,mBAAmB;aAC7B,CAAC,CAAC;WACA,UAAU,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,EAAE,CAAG,CAAD,AAAE;gBACtC,IAAI;gBACJ,KAAK;gBACL,OAAO,EAAE,gBAAgB;aAC1B,CAAC,CAAC;KACJ,CAAC,CAAC;AACL,CAAC"}},
    {"offset": {"line": 6608, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/createBrowserClient.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/createBrowserClient.ts"],"sourcesContent":["import { createClient, SupabaseClient } from \"@supabase/supabase-js\";\nimport type {\n  GenericSchema,\n  SupabaseClientOptions,\n} from \"@supabase/supabase-js/dist/module/lib/types\";\n\nimport { VERSION } from \"./version\";\nimport { isBrowser } from \"./utils\";\n\nimport type {\n  CookieMethodsBrowser,\n  CookieMethodsBrowserDeprecated,\n  CookieOptionsWithName,\n} from \"./types\";\n\nimport { createStorageFromOptions } from \"./cookies\";\n\nlet cachedBrowserClient: SupabaseClient<any, any, any> | undefined;\n\n/**\n * Creates a Supabase Client for use in a browser environment.\n *\n * In most cases you should not configure the `options.cookies` object, as this\n * is automatically handled for you. If you do customize this, prefer using the\n * `getAll` and `setAll` functions over `get`, `set` and `remove`. The latter\n * are deprecated due to being difficult to correctly implement and not\n * supporting some edge-cases. Both `getAll` and `setAll` (or both `get`, `set`\n * and `remove`) must be provided. Failing to provide the methods for setting\n * will throw an exception, and in previous versions of the library will result\n * in difficult to debug authentication issues such as random logouts, early\n * session termination or problems with inconsistent state.\n *\n * @param supabaseUrl The URL of the Supabase project.\n * @param supabaseKey The `anon` API key of the Supabase project.\n * @param options Various configuration options.\n */\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies?: CookieMethodsBrowser;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName, Schema>;\n\n/**\n * @deprecated Please specify `getAll` and `setAll` cookie methods instead of\n * the `get`, `set` and `remove`. These will not be supported in the next major\n * version.\n */\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies: CookieMethodsBrowserDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName, Schema>;\n\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies?: CookieMethodsBrowser | CookieMethodsBrowserDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName, Schema> {\n  // singleton client is created only if isSingleton is set to true, or if isSingleton is not defined and we detect a browser\n  const shouldUseSingleton =\n    options?.isSingleton === true ||\n    ((!options || !(\"isSingleton\" in options)) && isBrowser());\n\n  if (shouldUseSingleton && cachedBrowserClient) {\n    return cachedBrowserClient;\n  }\n\n  if (!supabaseUrl || !supabaseKey) {\n    throw new Error(\n      `@supabase/ssr: Your project's URL and API key are required to create a Supabase client!\\n\\nCheck your Supabase project's API settings to find these values\\n\\nhttps://supabase.com/dashboard/project/_/settings/api`,\n    );\n  }\n\n  const { storage } = createStorageFromOptions(\n    {\n      ...options,\n      cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n    },\n    false,\n  );\n\n  const client = createClient<Database, SchemaName, Schema>(\n    supabaseUrl,\n    supabaseKey,\n    {\n      ...options,\n      global: {\n        ...options?.global,\n        headers: {\n          ...options?.global?.headers,\n          \"X-Client-Info\": `supabase-ssr/${VERSION} createBrowserClient`,\n        },\n      },\n      auth: {\n        ...options?.auth,\n        ...(options?.cookieOptions?.name\n          ? { storageKey: options.cookieOptions.name }\n          : null),\n        flowType: \"pkce\",\n        autoRefreshToken: isBrowser(),\n        detectSessionInUrl: isBrowser(),\n        persistSession: true,\n        storage,\n      },\n    },\n  );\n\n  if (shouldUseSingleton) {\n    cachedBrowserClient = client;\n  }\n\n  return client;\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,YAAY,EAAkB,MAAM,uBAAuB,CAAC;AAMrE,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAC;;AACpC,OAAO,EAAE,SAAS,EAAE,MAAM,SAAS,CAAC;AAQpC,OAAO,EAAE,wBAAwB,EAAE,MAAM,WAAW,CAAC;;;;;AAErD,IAAI,mBAA8D,CAAC;AA8D7D,SAAU,mBAAmB,CASjC,WAAmB,EACnB,WAAmB,EACnB,OAKC;IAED,2HAA2H;IAC3H,MAAM,kBAAkB,GACtB,OAAO,EAAE,WAAW,KAAK,IAAI,IAC5B,CAAC,CAAC,OAAO,IAAI,CAAC,CAAC,aAAa,IAAI,OAAO,CAAC,CAAC,QAAI,6QAAS,EAAE,CAAC,CAAC;IAE7D,IAAI,kBAAkB,IAAI,mBAAmB,EAAE,CAAC;QAC9C,OAAO,mBAAmB,CAAC;IAC7B,CAAC;IAED,IAAI,CAAC,WAAW,IAAI,CAAC,WAAW,EAAE,CAAC;QACjC,MAAM,IAAI,KAAK,CACb,CAAA,mNAAA,CAAqN,CACtN,CAAC;IACJ,CAAC;IAED,MAAM,EAAE,OAAO,EAAE,OAAG,mRAAwB,EAC1C;QACE,GAAG,OAAO;QACV,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;KACvD,EACD,KAAK,CACN,CAAC;IAEF,MAAM,MAAM,OAAG,+QAAY,EACzB,WAAW,EACX,WAAW,EACX;QACE,GAAG,OAAO;QACV,MAAM,EAAE;YACN,GAAG,OAAO,EAAE,MAAM;YAClB,OAAO,EAAE;gBACP,GAAG,OAAO,EAAE,MAAM,EAAE,OAAO;gBAC3B,eAAe,EAAE,CAAA,aAAA,EAAgB,kQAAO,CAAA,oBAAA,CAAsB;aAC/D;SACF;QACD,IAAI,EAAE;YACJ,GAAG,OAAO,EAAE,IAAI;YAChB,GAAG,AAAC,OAAO,EAAE,aAAa,EAAE,IAAI,GAC5B;gBAAE,UAAU,EAAE,OAAO,CAAC,aAAa,CAAC,IAAI;YAAA,CAAE,GAC1C,IAAI,CAAC;YACT,QAAQ,EAAE,MAAM;YAChB,gBAAgB,MAAE,6QAAS,EAAE;YAC7B,kBAAkB,MAAE,6QAAS,EAAE;YAC/B,cAAc,EAAE,IAAI;YACpB,OAAO;SACR;KACF,CACF,CAAC;IAEF,IAAI,kBAAkB,EAAE,CAAC;QACvB,mBAAmB,GAAG,MAAM,CAAC;IAC/B,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 6665, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/createServerClient.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/createServerClient.ts"],"sourcesContent":["import {\n  AuthChangeEvent,\n  createClient,\n  SupabaseClient,\n} from \"@supabase/supabase-js\";\nimport type {\n  GenericSchema,\n  SupabaseClientOptions,\n} from \"@supabase/supabase-js/dist/module/lib/types\";\n\nimport { VERSION } from \"./version\";\nimport { createStorageFromOptions, applyServerStorage } from \"./cookies\";\nimport type {\n  CookieOptionsWithName,\n  CookieMethodsServer,\n  CookieMethodsServerDeprecated,\n} from \"./types\";\n\n/**\n * @deprecated Please specify `getAll` and `setAll` cookie methods instead of\n * the `get`, `set` and `remove`. These will not be supported in the next major\n * version.\n */\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServerDeprecated;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName, Schema>;\n\n/**\n * Creates a Supabase Client for use on the server-side of a server-side\n * rendering (SSR) framework.\n *\n * There are two categories of uses for this function: use in middlewares and\n * use in pages, components or routes.\n *\n * **Use in middlewares.**\n *\n * Middlewares are functions that run before any rendering logic is executed on\n * the server-side. They typically have access to request headers (cookies) and\n * can modify both the request and response headers.\n *\n * In most SSR frameworks, to use Supabase correctly you *must set up a\n * middleware* and use this function in it.\n *\n * When using this in a middleware, the `cookie` option must be configured to\n * use both `getAll` and `setAll`. Alternatively you can use the `get`, `set`\n * and `remove` functions. The latter are deprecated **and not recommended**\n * for most use cases due to being difficult to use properly and they do not\n * cover important edge cases. In future major versions of the library, the\n * option to configure `get`, `set` and `remove` will be removed.\n *\n * **IMPORTANT:** Failing to implement `getAll` and `setAll` correctly (or the\n * deprecated `get`, `set` and `remove`) including omitting them **will cause\n * significant and difficult to debug authentication issues**. They will\n * manifest as: random logouts, early session termination, JSON parsing errors,\n * increased number of refresh token requests, or relying on garbage state.\n *\n * **Use in pages, components or routes.**\n *\n * To use Supabase features server-side rendered in pages, components or routes\n * (a.k.a. actions / APIs) you must create a client with this function. Not all\n * frameworks allow the ability to set cookies or response headers when pages\n * or components are rendered. In those cases you _can omit `setAll` (or the\n * deprecated `set`, `remove`) cookie option methods_. **It is strongly\n * recommended that if the ability to set cookies and response headers is\n * present, you should configure the `setAll` (or the deprecated `set` and\n * `remove`) cookie access methods.**\n *\n * **IMPORTANT:** If the ability to set cookies or response headers is not\n * available **middleware or an equivalent must be used.** Failing to do this\n * will cause significant and difficult to debug authentication issues.\n *\n * When `setAll` (or the deprecated `set`, `remove`) cookie methods are not\n * configured, the Supabase Client will emit a warning if it is used in a way\n * that requires setting cookies. If you see this warning, it usually means\n * that you are using the Supabase Client in a wrong way:\n *\n * - You should have, but did not configure a middleware client.\n * - There is a bug in your middleware function.\n * - You are using features of the Supabase Client that change the User, e.g.\n *   by calling `supabase.auth.updateUser()` on the server.\n *\n * Please consult the latest Supabase guides for advice on how to avoid common\n * pitfalls depending on SSR framework.\n *\n * @param supabaseUrl The URL of the Supabase project.\n * @param supabaseKey The `anon` API key of the Supabase project.\n * @param options Various configuration options.\n */\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServer;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName, Schema>;\n\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string & keyof Database = \"public\" extends keyof Database\n    ? \"public\"\n    : string & keyof Database,\n  Schema extends GenericSchema = Database[SchemaName] extends GenericSchema\n    ? Database[SchemaName]\n    : any,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServer | CookieMethodsServerDeprecated;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName, Schema> {\n  if (!supabaseUrl || !supabaseKey) {\n    throw new Error(\n      `Your project's URL and Key are required to create a Supabase client!\\n\\nCheck your Supabase project's API settings to find these values\\n\\nhttps://supabase.com/dashboard/project/_/settings/api`,\n    );\n  }\n\n  const { storage, getAll, setAll, setItems, removedItems } =\n    createStorageFromOptions(\n      {\n        ...options,\n        cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n      },\n      true,\n    );\n\n  const client = createClient<Database, SchemaName, Schema>(\n    supabaseUrl,\n    supabaseKey,\n    {\n      ...options,\n      global: {\n        ...options?.global,\n        headers: {\n          ...options?.global?.headers,\n          \"X-Client-Info\": `supabase-ssr/${VERSION} createServerClient`,\n        },\n      },\n      auth: {\n        ...(options?.cookieOptions?.name\n          ? { storageKey: options.cookieOptions.name }\n          : null),\n        ...options?.auth,\n        flowType: \"pkce\",\n        autoRefreshToken: false,\n        detectSessionInUrl: false,\n        persistSession: true,\n        storage,\n      },\n    },\n  );\n\n  client.auth.onAuthStateChange(async (event: AuthChangeEvent) => {\n    // The SIGNED_IN event is fired very often, but we don't need to\n    // apply the storage each time it fires, only if there are changes\n    // that need to be set -- which is if setItems / removeItems have\n    // data.\n    const hasStorageChanges =\n      Object.keys(setItems).length > 0 || Object.keys(removedItems).length > 0;\n\n    if (\n      hasStorageChanges &&\n      (event === \"SIGNED_IN\" ||\n        event === \"TOKEN_REFRESHED\" ||\n        event === \"USER_UPDATED\" ||\n        event === \"PASSWORD_RECOVERY\" ||\n        event === \"SIGNED_OUT\" ||\n        event === \"MFA_CHALLENGE_VERIFIED\")\n    ) {\n      await applyServerStorage(\n        { getAll, setAll, setItems, removedItems },\n        {\n          cookieOptions: options?.cookieOptions ?? null,\n          cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n        },\n      );\n    }\n  });\n\n  return client;\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAEL,YAAY,GAEb,MAAM,uBAAuB,CAAC;AAM/B,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAC;AACpC,OAAO,EAAE,wBAAwB,EAAE,kBAAkB,EAAE,MAAM,WAAW,CAAC;;;;AA6GnE,SAAU,kBAAkB,CAShC,WAAmB,EACnB,WAAmB,EACnB,OAIC;IAED,IAAI,CAAC,WAAW,IAAI,CAAC,WAAW,EAAE,CAAC;QACjC,MAAM,IAAI,KAAK,CACb,CAAA,gMAAA,CAAkM,CACnM,CAAC;IACJ,CAAC;IAED,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,QAAQ,EAAE,YAAY,EAAE,OACvD,mRAAwB,EACtB;QACE,GAAG,OAAO;QACV,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;KACvD,EACD,IAAI,CACL,CAAC;IAEJ,MAAM,MAAM,OAAG,+QAAY,EACzB,WAAW,EACX,WAAW,EACX;QACE,GAAG,OAAO;QACV,MAAM,EAAE;YACN,GAAG,OAAO,EAAE,MAAM;YAClB,OAAO,EAAE;gBACP,GAAG,OAAO,EAAE,MAAM,EAAE,OAAO;gBAC3B,eAAe,EAAE,CAAA,aAAA,EAAgB,kQAAO,CAAA,mBAAA,CAAqB;aAC9D;SACF;QACD,IAAI,EAAE;YACJ,GAAG,AAAC,OAAO,EAAE,aAAa,EAAE,IAAI,GAC5B;gBAAE,UAAU,EAAE,OAAO,CAAC,aAAa,CAAC,IAAI;YAAA,CAAE,GAC1C,IAAI,CAAC;YACT,GAAG,OAAO,EAAE,IAAI;YAChB,QAAQ,EAAE,MAAM;YAChB,gBAAgB,EAAE,KAAK;YACvB,kBAAkB,EAAE,KAAK;YACzB,cAAc,EAAE,IAAI;YACpB,OAAO;SACR;KACF,CACF,CAAC;IAEF,MAAM,CAAC,IAAI,CAAC,iBAAiB,CAAC,KAAK,EAAE,KAAsB,EAAE,EAAE;QAC7D,gEAAgE;QAChE,kEAAkE;QAClE,iEAAiE;QACjE,QAAQ;QACR,MAAM,iBAAiB,GACrB,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC;QAE3E,IACE,iBAAiB,IACjB,CAAC,KAAK,KAAK,WAAW,IACpB,KAAK,KAAK,iBAAiB,IAC3B,KAAK,KAAK,cAAc,IACxB,KAAK,KAAK,mBAAmB,IAC7B,KAAK,KAAK,YAAY,IACtB,KAAK,KAAK,wBAAwB,CAAC,EACrC,CAAC;YACD,UAAM,6QAAkB,EACtB;gBAAE,MAAM;gBAAE,MAAM;gBAAE,QAAQ;gBAAE,YAAY;YAAA,CAAE,EAC1C;gBACE,aAAa,EAAE,OAAO,EAAE,aAAa,IAAI,IAAI;gBAC7C,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;aACvD,CACF,CAAC;QACJ,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 6727, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/types.js"],"sourcesContent":["//# sourceMappingURL=types.js.map"],"names":[],"mappings":"AAAA,iCAAiC","ignoreList":[0]}},
    {"offset": {"line": 6732, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/dist/module/index.js","sources":["turbopack:///[project]/node_modules/.bun/@supabase+ssr@0.6.1+d599ce7249005bba/node_modules/@supabase/ssr/src/index.ts"],"sourcesContent":["export * from \"./createBrowserClient\";\nexport * from \"./createServerClient\";\nexport * from \"./types\";\nexport * from \"./utils\";\n"],"names":[],"mappings":";AAAA,cAAc,uBAAuB,CAAC;AACtC,cAAc,sBAAsB,CAAC;AACrC,cAAc,SAAS,CAAC;AACxB,cAAc,SAAS,CAAC"}},
    {"offset": {"line": 6745, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.bun/cookie@1.1.1/node_modules/cookie/dist/index.js","sources":["turbopack:///[project]/node_modules/.bun/cookie@1.1.1/node_modules/cookie/src/index.ts"],"sourcesContent":["/**\n * RegExp to match cookie-name in RFC 6265 sec 4.1.1\n * This refers out to the obsoleted definition of token in RFC 2616 sec 2.2\n * which has been replaced by the token definition in RFC 7230 appendix B.\n *\n * cookie-name       = token\n * token             = 1*tchar\n * tchar             = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" /\n *                     \"*\" / \"+\" / \"-\" / \".\" / \"^\" / \"_\" /\n *                     \"`\" / \"|\" / \"~\" / DIGIT / ALPHA\n *\n * Note: Allowing more characters - https://github.com/jshttp/cookie/issues/191\n * Allow same range as cookie value, except `=`, which delimits end of name.\n */\nconst cookieNameRegExp = /^[\\u0021-\\u003A\\u003C\\u003E-\\u007E]+$/;\n\n/**\n * RegExp to match cookie-value in RFC 6265 sec 4.1.1\n *\n * cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )\n * cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E\n *                     ; US-ASCII characters excluding CTLs,\n *                     ; whitespace DQUOTE, comma, semicolon,\n *                     ; and backslash\n *\n * Allowing more characters: https://github.com/jshttp/cookie/issues/191\n * Comma, backslash, and DQUOTE are not part of the parsing algorithm.\n */\nconst cookieValueRegExp = /^[\\u0021-\\u003A\\u003C-\\u007E]*$/;\n\n/**\n * RegExp to match domain-value in RFC 6265 sec 4.1.1\n *\n * domain-value      = <subdomain>\n *                     ; defined in [RFC1034], Section 3.5, as\n *                     ; enhanced by [RFC1123], Section 2.1\n * <subdomain>       = <label> | <subdomain> \".\" <label>\n * <label>           = <let-dig> [ [ <ldh-str> ] <let-dig> ]\n *                     Labels must be 63 characters or less.\n *                     'let-dig' not 'letter' in the first char, per RFC1123\n * <ldh-str>         = <let-dig-hyp> | <let-dig-hyp> <ldh-str>\n * <let-dig-hyp>     = <let-dig> | \"-\"\n * <let-dig>         = <letter> | <digit>\n * <letter>          = any one of the 52 alphabetic characters A through Z in\n *                     upper case and a through z in lower case\n * <digit>           = any one of the ten digits 0 through 9\n *\n * Keep support for leading dot: https://github.com/jshttp/cookie/issues/173\n *\n * > (Note that a leading %x2E (\".\"), if present, is ignored even though that\n * character is not permitted, but a trailing %x2E (\".\"), if present, will\n * cause the user agent to ignore the attribute.)\n */\nconst domainValueRegExp =\n  /^([.]?[a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?)([.][a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?)*$/i;\n\n/**\n * RegExp to match path-value in RFC 6265 sec 4.1.1\n *\n * path-value        = <any CHAR except CTLs or \";\">\n * CHAR              = %x01-7F\n *                     ; defined in RFC 5234 appendix B.1\n */\nconst pathValueRegExp = /^[\\u0020-\\u003A\\u003D-\\u007E]*$/;\n\n/**\n * RegExp to match max-age-value in RFC 6265 sec 5.6.2\n */\nconst maxAgeRegExp = /^-?\\d+$/;\n\nconst __toString = Object.prototype.toString;\n\nconst NullObject = /* @__PURE__ */ (() => {\n  const C = function () {};\n  C.prototype = Object.create(null);\n  return C;\n})() as unknown as { new (): any };\n\n/**\n * Parse options.\n */\nexport interface ParseOptions {\n  /**\n   * Specifies a function that will be used to decode a [cookie-value](https://datatracker.ietf.org/doc/html/rfc6265#section-4.1.1).\n   * Since the value of a cookie has a limited character set (and must be a simple string), this function can be used to decode\n   * a previously-encoded cookie value into a JavaScript string.\n   *\n   * The default function is the global `decodeURIComponent`, wrapped in a `try..catch`. If an error\n   * is thrown it will return the cookie's original value. If you provide your own encode/decode\n   * scheme you must ensure errors are appropriately handled.\n   *\n   * @default decode\n   */\n  decode?: (str: string) => string | undefined;\n}\n\n/**\n * Cookies object.\n */\nexport type Cookies = Record<string, string | undefined>;\n\n/**\n * Parse a `Cookie` header.\n *\n * Parse the given cookie header string into an object\n * The object has the various cookies as keys(names) => values\n */\nexport function parseCookie(str: string, options?: ParseOptions): Cookies {\n  const obj: Cookies = new NullObject();\n  const len = str.length;\n  // RFC 6265 sec 4.1.1, RFC 2616 2.2 defines a cookie name consists of one char minimum, plus '='.\n  if (len < 2) return obj;\n\n  const dec = options?.decode || decode;\n  let index = 0;\n\n  do {\n    const eqIdx = eqIndex(str, index, len);\n    if (eqIdx === -1) break; // No more cookie pairs.\n\n    const endIdx = endIndex(str, index, len);\n\n    if (eqIdx > endIdx) {\n      // backtrack on prior semicolon\n      index = str.lastIndexOf(\";\", eqIdx - 1) + 1;\n      continue;\n    }\n\n    const key = valueSlice(str, index, eqIdx);\n\n    // only assign once\n    if (obj[key] === undefined) {\n      obj[key] = dec(valueSlice(str, eqIdx + 1, endIdx));\n    }\n\n    index = endIdx + 1;\n  } while (index < len);\n\n  return obj;\n}\n\nexport interface StringifyOptions {\n  /**\n   * Specifies a function that will be used to encode a [cookie-value](https://datatracker.ietf.org/doc/html/rfc6265#section-4.1.1).\n   * Since value of a cookie has a limited character set (and must be a simple string), this function can be used to encode\n   * a value into a string suited for a cookie's value, and should mirror `decode` when parsing.\n   *\n   * @default encodeURIComponent\n   */\n  encode?: (str: string) => string;\n}\n\n/**\n * Stringifies an object into an HTTP `Cookie` header.\n */\nexport function stringifyCookie(\n  cookie: Cookies,\n  options?: StringifyOptions,\n): string {\n  const enc = options?.encode || encodeURIComponent;\n  const cookieStrings: string[] = [];\n\n  for (const name of Object.keys(cookie)) {\n    const val = cookie[name];\n    if (val === undefined) continue;\n\n    if (!cookieNameRegExp.test(name)) {\n      throw new TypeError(`cookie name is invalid: ${name}`);\n    }\n\n    const value = enc(val);\n\n    if (!cookieValueRegExp.test(value)) {\n      throw new TypeError(`cookie val is invalid: ${val}`);\n    }\n\n    cookieStrings.push(`${name}=${value}`);\n  }\n\n  return cookieStrings.join(\"; \");\n}\n\n/**\n * Set-Cookie object.\n */\nexport interface SetCookie {\n  /**\n   * Specifies the name of the cookie.\n   */\n  name: string;\n  /**\n   * Specifies the string to be the value for the cookie.\n   */\n  value: string | undefined;\n  /**\n   * Specifies the `number` (in seconds) to be the value for the [`Max-Age` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.2).\n   *\n   * The [cookie storage model specification](https://tools.ietf.org/html/rfc6265#section-5.3) states that if both `expires` and\n   * `maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\n   * so if both are set, they should point to the same date and time.\n   */\n  maxAge?: number;\n  /**\n   * Specifies the `Date` object to be the value for the [`Expires` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.1).\n   * When no expiration is set, clients consider this a \"non-persistent cookie\" and delete it when the current session is over.\n   *\n   * The [cookie storage model specification](https://tools.ietf.org/html/rfc6265#section-5.3) states that if both `expires` and\n   * `maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\n   * so if both are set, they should point to the same date and time.\n   */\n  expires?: Date;\n  /**\n   * Specifies the value for the [`Domain` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.3).\n   * When no domain is set, clients consider the cookie to apply to the current domain only.\n   */\n  domain?: string;\n  /**\n   * Specifies the value for the [`Path` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.4).\n   * When no path is set, the path is considered the [\"default path\"](https://tools.ietf.org/html/rfc6265#section-5.1.4).\n   */\n  path?: string;\n  /**\n   * Enables the [`HttpOnly` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.6).\n   * When enabled, clients will not allow client-side JavaScript to see the cookie in `document.cookie`.\n   */\n  httpOnly?: boolean;\n  /**\n   * Enables the [`Secure` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.5).\n   * When enabled, clients will only send the cookie back if the browser has an HTTPS connection.\n   */\n  secure?: boolean;\n  /**\n   * Enables the [`Partitioned` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-cutler-httpbis-partitioned-cookies/).\n   * When enabled, clients will only send the cookie back when the current domain _and_ top-level domain matches.\n   *\n   * This is an attribute that has not yet been fully standardized, and may change in the future.\n   * This also means clients may ignore this attribute until they understand it. More information\n   * about can be found in [the proposal](https://github.com/privacycg/CHIPS).\n   */\n  partitioned?: boolean;\n  /**\n   * Specifies the value for the [`Priority` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-west-cookie-priority-00#section-4.1).\n   *\n   * - `'low'` will set the `Priority` attribute to `Low`.\n   * - `'medium'` will set the `Priority` attribute to `Medium`, the default priority when not set.\n   * - `'high'` will set the `Priority` attribute to `High`.\n   *\n   * More information about priority levels can be found in [the specification](https://tools.ietf.org/html/draft-west-cookie-priority-00#section-4.1).\n   */\n  priority?: \"low\" | \"medium\" | \"high\";\n  /**\n   * Specifies the value for the [`SameSite` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-09#section-5.4.7).\n   *\n   * - `true` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n   * - `'lax'` will set the `SameSite` attribute to `Lax` for lax same site enforcement.\n   * - `'none'` will set the `SameSite` attribute to `None` for an explicit cross-site cookie.\n   * - `'strict'` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n   *\n   * More information about enforcement levels can be found in [the specification](https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-09#section-5.4.7).\n   */\n  sameSite?: boolean | \"lax\" | \"strict\" | \"none\";\n}\n\n/**\n * Backward compatibility serialize options.\n */\nexport type SerializeOptions = StringifyOptions &\n  Omit<SetCookie, \"name\" | \"value\">;\n\n/**\n * Serialize data into a cookie header.\n *\n * Serialize a name value pair into a cookie string suitable for\n * http headers. An optional options object specifies cookie parameters.\n *\n * serialize('foo', 'bar', { httpOnly: true })\n *   => \"foo=bar; httpOnly\"\n */\nexport function stringifySetCookie(\n  cookie: SetCookie,\n  options?: StringifyOptions,\n): string;\nexport function stringifySetCookie(\n  name: string,\n  val: string,\n  options?: SerializeOptions,\n): string;\nexport function stringifySetCookie(\n  _name: string | SetCookie,\n  _val?: string | StringifyOptions,\n  _opts?: SerializeOptions,\n): string {\n  const cookie =\n    typeof _name === \"object\"\n      ? _name\n      : { ..._opts, name: _name, value: String(_val) };\n  const options = typeof _val === \"object\" ? _val : _opts;\n  const enc = options?.encode || encodeURIComponent;\n\n  if (!cookieNameRegExp.test(cookie.name)) {\n    throw new TypeError(`argument name is invalid: ${cookie.name}`);\n  }\n\n  const value = cookie.value ? enc(cookie.value) : \"\";\n\n  if (!cookieValueRegExp.test(value)) {\n    throw new TypeError(`argument val is invalid: ${cookie.value}`);\n  }\n\n  let str = cookie.name + \"=\" + value;\n\n  if (cookie.maxAge !== undefined) {\n    if (!Number.isInteger(cookie.maxAge)) {\n      throw new TypeError(`option maxAge is invalid: ${cookie.maxAge}`);\n    }\n\n    str += \"; Max-Age=\" + cookie.maxAge;\n  }\n\n  if (cookie.domain) {\n    if (!domainValueRegExp.test(cookie.domain)) {\n      throw new TypeError(`option domain is invalid: ${cookie.domain}`);\n    }\n\n    str += \"; Domain=\" + cookie.domain;\n  }\n\n  if (cookie.path) {\n    if (!pathValueRegExp.test(cookie.path)) {\n      throw new TypeError(`option path is invalid: ${cookie.path}`);\n    }\n\n    str += \"; Path=\" + cookie.path;\n  }\n\n  if (cookie.expires) {\n    if (!isDate(cookie.expires) || !Number.isFinite(cookie.expires.valueOf())) {\n      throw new TypeError(`option expires is invalid: ${cookie.expires}`);\n    }\n\n    str += \"; Expires=\" + cookie.expires.toUTCString();\n  }\n\n  if (cookie.httpOnly) {\n    str += \"; HttpOnly\";\n  }\n\n  if (cookie.secure) {\n    str += \"; Secure\";\n  }\n\n  if (cookie.partitioned) {\n    str += \"; Partitioned\";\n  }\n\n  if (cookie.priority) {\n    const priority =\n      typeof cookie.priority === \"string\"\n        ? cookie.priority.toLowerCase()\n        : undefined;\n    switch (priority) {\n      case \"low\":\n        str += \"; Priority=Low\";\n        break;\n      case \"medium\":\n        str += \"; Priority=Medium\";\n        break;\n      case \"high\":\n        str += \"; Priority=High\";\n        break;\n      default:\n        throw new TypeError(`option priority is invalid: ${cookie.priority}`);\n    }\n  }\n\n  if (cookie.sameSite) {\n    const sameSite =\n      typeof cookie.sameSite === \"string\"\n        ? cookie.sameSite.toLowerCase()\n        : cookie.sameSite;\n    switch (sameSite) {\n      case true:\n      case \"strict\":\n        str += \"; SameSite=Strict\";\n        break;\n      case \"lax\":\n        str += \"; SameSite=Lax\";\n        break;\n      case \"none\":\n        str += \"; SameSite=None\";\n        break;\n      default:\n        throw new TypeError(`option sameSite is invalid: ${cookie.sameSite}`);\n    }\n  }\n\n  return str;\n}\n\n/**\n * Deserialize a `Set-Cookie` header into an object.\n *\n * deserialize('foo=bar; httpOnly')\n *   => { name: 'foo', value: 'bar', httpOnly: true }\n */\nexport function parseSetCookie(str: string, options?: ParseOptions): SetCookie {\n  const dec = options?.decode || decode;\n  const len = str.length;\n  const endIdx = endIndex(str, 0, len);\n  const eqIdx = eqIndex(str, 0, endIdx);\n  const setCookie: SetCookie =\n    eqIdx === -1\n      ? { name: \"\", value: dec(valueSlice(str, 0, endIdx)) }\n      : {\n          name: valueSlice(str, 0, eqIdx),\n          value: dec(valueSlice(str, eqIdx + 1, endIdx)),\n        };\n\n  let index = endIdx + 1;\n  while (index < len) {\n    const endIdx = endIndex(str, index, len);\n    const eqIdx = eqIndex(str, index, endIdx);\n    const attr =\n      eqIdx === -1\n        ? valueSlice(str, index, endIdx)\n        : valueSlice(str, index, eqIdx);\n    const val = eqIdx === -1 ? undefined : valueSlice(str, eqIdx + 1, endIdx);\n\n    switch (attr.toLowerCase()) {\n      case \"httponly\":\n        setCookie.httpOnly = true;\n        break;\n      case \"secure\":\n        setCookie.secure = true;\n        break;\n      case \"partitioned\":\n        setCookie.partitioned = true;\n        break;\n      case \"domain\":\n        setCookie.domain = val;\n        break;\n      case \"path\":\n        setCookie.path = val;\n        break;\n      case \"max-age\":\n        if (val && maxAgeRegExp.test(val)) setCookie.maxAge = Number(val);\n        break;\n      case \"expires\":\n        if (!val) break;\n        const date = new Date(val);\n        if (Number.isFinite(date.valueOf())) setCookie.expires = date;\n        break;\n      case \"priority\":\n        if (!val) break;\n        const priority = val.toLowerCase();\n        if (\n          priority === \"low\" ||\n          priority === \"medium\" ||\n          priority === \"high\"\n        ) {\n          setCookie.priority = priority;\n        }\n        break;\n      case \"samesite\":\n        if (!val) break;\n        const sameSite = val.toLowerCase();\n        if (\n          sameSite === \"lax\" ||\n          sameSite === \"strict\" ||\n          sameSite === \"none\"\n        ) {\n          setCookie.sameSite = sameSite;\n        }\n        break;\n    }\n\n    index = endIdx + 1;\n  }\n\n  return setCookie;\n}\n\n/**\n * Find the `;` character between `min` and `len` in str.\n */\nfunction endIndex(str: string, min: number, len: number) {\n  const index = str.indexOf(\";\", min);\n  return index === -1 ? len : index;\n}\n\n/**\n * Find the `=` character between `min` and `max` in str.\n */\nfunction eqIndex(str: string, min: number, max: number) {\n  const index = str.indexOf(\"=\", min);\n  return index < max ? index : -1;\n}\n\n/**\n * Slice out a value between startPod to max.\n */\nfunction valueSlice(str: string, min: number, max: number) {\n  let start = min;\n  let end = max;\n\n  do {\n    const code = str.charCodeAt(start);\n    if (code !== 0x20 /*   */ && code !== 0x09 /* \\t */) break;\n  } while (++start < end);\n\n  while (end > start) {\n    const code = str.charCodeAt(end - 1);\n    if (code !== 0x20 /*   */ && code !== 0x09 /* \\t */) break;\n    end--;\n  }\n\n  return str.slice(start, end);\n}\n\n/**\n * URL-decode string value. Optimized to skip native call when no %.\n */\nfunction decode(str: string): string {\n  if (str.indexOf(\"%\") === -1) return str;\n\n  try {\n    return decodeURIComponent(str);\n  } catch (e) {\n    return str;\n  }\n}\n\n/**\n * Determine if value is a Date.\n */\nfunction isDate(val: any): val is Date {\n  return __toString.call(val) === \"[object Date]\";\n}\n\n/**\n * Backward compatibility exports.\n */\nexport { stringifySetCookie as serialize, parseCookie as parse };\n"],"names":[],"mappings":";;;AA2GA,QAAA,WAAA,GAAA,YAgCC;AAmZwD,QAAA,KAAA,GAAA,YAAK;AAnY9D,QAAA,eAAA,GAAA,gBAyBC;AA2GD,QAAA,kBAAA,GAAA,mBA8GC;AAiJ8B,QAAA,SAAA,GAAA,mBAAS;AAzIxC,QAAA,cAAA,GAAA,eA2EC;AA1MD,QAAA,kBAAA,GAAA,mBAGU;AAqQqB,QAAA,SAAA,GAAA,mBAAS;AA9hBxC;;;;;;;;;;;;;GAaG,CACH,MAAM,gBAAgB,GAAG,uCAAuC,CAAC;AAEjE;;;;;;;;;;;GAWG,CACH,MAAM,iBAAiB,GAAG,iCAAiC,CAAC;AAE5D;;;;;;;;;;;;;;;;;;;;;;GAsBG,CACH,MAAM,iBAAiB,GACrB,qFAAqF,CAAC;AAExF;;;;;;GAMG,CACH,MAAM,eAAe,GAAG,iCAAiC,CAAC;AAE1D;;GAEG,CACH,MAAM,YAAY,GAAG,SAAS,CAAC;AAE/B,MAAM,UAAU,GAAG,MAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;AAE7C,MAAM,UAAU,GAAG,aAAA,EAAe,CAAC,CAAC,GAAG,EAAE;IACvC,MAAM,CAAC,GAAG,YAAa,CAAC,CAAC;IACzB,CAAC,CAAC,SAAS,GAAG,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;IAClC,OAAO,CAAC,CAAC;AACX,CAAC,CAAC,EAAgC,CAAC;AAyBnC;;;;;GAKG,CACH,SAAgB,WAAW,CAAC,GAAW,EAAE,OAAsB;IAC7D,MAAM,GAAG,GAAY,IAAI,UAAU,EAAE,CAAC;IACtC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC;IACvB,iGAAiG;IACjG,IAAI,GAAG,GAAG,CAAC,EAAE,OAAO,GAAG,CAAC;IAExB,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,MAAM,CAAC;IACtC,IAAI,KAAK,GAAG,CAAC,CAAC;IAEd,GAAG,CAAC;QACF,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,EAAE,KAAK,EAAE,GAAG,CAAC,CAAC;QACvC,IAAI,KAAK,KAAK,CAAC,CAAC,EAAE,MAAM,CAAC,wBAAwB;QAEjD,MAAM,MAAM,GAAG,QAAQ,CAAC,GAAG,EAAE,KAAK,EAAE,GAAG,CAAC,CAAC;QAEzC,IAAI,KAAK,GAAG,MAAM,EAAE,CAAC;YACnB,+BAA+B;YAC/B,KAAK,GAAG,GAAG,CAAC,WAAW,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YAC5C,SAAS;QACX,CAAC;QAED,MAAM,GAAG,GAAG,UAAU,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;QAE1C,mBAAmB;QACnB,IAAI,GAAG,CAAC,GAAG,CAAC,KAAK,SAAS,EAAE,CAAC;YAC3B,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,UAAU,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC;QACrD,CAAC;QAED,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC;IACrB,CAAC,OAAQ,KAAK,GAAG,GAAG,CAAE;IAEtB,OAAO,GAAG,CAAC;AACb,CAAC;AAaD;;GAEG,CACH,SAAgB,eAAe,CAC7B,MAAe,EACf,OAA0B;IAE1B,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,kBAAkB,CAAC;IAClD,MAAM,aAAa,GAAa,EAAE,CAAC;IAEnC,KAAK,MAAM,IAAI,IAAI,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAE,CAAC;QACvC,MAAM,GAAG,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC;QACzB,IAAI,GAAG,KAAK,SAAS,EAAE,SAAS;QAEhC,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;YACjC,MAAM,IAAI,SAAS,CAAC,CAAA,wBAAA,EAA2B,IAAI,EAAE,CAAC,CAAC;QACzD,CAAC;QAED,MAAM,KAAK,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC;QAEvB,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;YACnC,MAAM,IAAI,SAAS,CAAC,CAAA,uBAAA,EAA0B,GAAG,EAAE,CAAC,CAAC;QACvD,CAAC;QAED,aAAa,CAAC,IAAI,CAAC,GAAG,IAAI,CAAA,CAAA,EAAI,KAAK,EAAE,CAAC,CAAC;IACzC,CAAC;IAED,OAAO,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;AAClC,CAAC;AA2GD,SAAgB,kBAAkB,CAChC,KAAyB,EACzB,IAAgC,EAChC,KAAwB;IAExB,MAAM,MAAM,GACV,OAAO,KAAK,KAAK,QAAQ,GACrB,KAAK,GACL;QAAE,GAAG,KAAK;QAAE,IAAI,EAAE,KAAK;QAAE,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC;IAAA,CAAE,CAAC;IACrD,MAAM,OAAO,GAAG,OAAO,IAAI,KAAK,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC;IACxD,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,kBAAkB,CAAC;IAElD,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC;QACxC,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;IAClE,CAAC;IAED,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;IAEpD,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;QACnC,MAAM,IAAI,SAAS,CAAC,CAAA,yBAAA,EAA4B,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;IAClE,CAAC;IAED,IAAI,GAAG,GAAG,MAAM,CAAC,IAAI,GAAG,GAAG,GAAG,KAAK,CAAC;IAEpC,IAAI,MAAM,CAAC,MAAM,KAAK,SAAS,EAAE,CAAC;QAChC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC;YACrC,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,MAAM,CAAC,MAAM,EAAE,CAAC,CAAC;QACpE,CAAC;QAED,GAAG,IAAI,YAAY,GAAG,MAAM,CAAC,MAAM,CAAC;IACtC,CAAC;IAED,IAAI,MAAM,CAAC,MAAM,EAAE,CAAC;QAClB,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC;YAC3C,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,MAAM,CAAC,MAAM,EAAE,CAAC,CAAC;QACpE,CAAC;QAED,GAAG,IAAI,WAAW,GAAG,MAAM,CAAC,MAAM,CAAC;IACrC,CAAC;IAED,IAAI,MAAM,CAAC,IAAI,EAAE,CAAC;QAChB,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC;YACvC,MAAM,IAAI,SAAS,CAAC,CAAA,wBAAA,EAA2B,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;QAChE,CAAC;QAED,GAAG,IAAI,SAAS,GAAG,MAAM,CAAC,IAAI,CAAC;IACjC,CAAC;IAED,IAAI,MAAM,CAAC,OAAO,EAAE,CAAC;QACnB,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC,EAAE,CAAC;YAC1E,MAAM,IAAI,SAAS,CAAC,CAAA,2BAAA,EAA8B,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;QACtE,CAAC;QAED,GAAG,IAAI,YAAY,GAAG,MAAM,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC;IACrD,CAAC;IAED,IAAI,MAAM,CAAC,QAAQ,EAAE,CAAC;QACpB,GAAG,IAAI,YAAY,CAAC;IACtB,CAAC;IAED,IAAI,MAAM,CAAC,MAAM,EAAE,CAAC;QAClB,GAAG,IAAI,UAAU,CAAC;IACpB,CAAC;IAED,IAAI,MAAM,CAAC,WAAW,EAAE,CAAC;QACvB,GAAG,IAAI,eAAe,CAAC;IACzB,CAAC;IAED,IAAI,MAAM,CAAC,QAAQ,EAAE,CAAC;QACpB,MAAM,QAAQ,GACZ,OAAO,MAAM,CAAC,QAAQ,KAAK,QAAQ,GAC/B,MAAM,CAAC,QAAQ,CAAC,WAAW,EAAE,GAC7B,SAAS,CAAC;QAChB,OAAQ,QAAQ,EAAE,CAAC;YACjB,KAAK,KAAK;gBACR,GAAG,IAAI,gBAAgB,CAAC;gBACxB,MAAM;YACR,KAAK,QAAQ;gBACX,GAAG,IAAI,mBAAmB,CAAC;gBAC3B,MAAM;YACR,KAAK,MAAM;gBACT,GAAG,IAAI,iBAAiB,CAAC;gBACzB,MAAM;YACR;gBACE,MAAM,IAAI,SAAS,CAAC,CAAA,4BAAA,EAA+B,MAAM,CAAC,QAAQ,EAAE,CAAC,CAAC;QAC1E,CAAC;IACH,CAAC;IAED,IAAI,MAAM,CAAC,QAAQ,EAAE,CAAC;QACpB,MAAM,QAAQ,GACZ,OAAO,MAAM,CAAC,QAAQ,KAAK,QAAQ,GAC/B,MAAM,CAAC,QAAQ,CAAC,WAAW,EAAE,GAC7B,MAAM,CAAC,QAAQ,CAAC;QACtB,OAAQ,QAAQ,EAAE,CAAC;YACjB,KAAK,IAAI,CAAC;YACV,KAAK,QAAQ;gBACX,GAAG,IAAI,mBAAmB,CAAC;gBAC3B,MAAM;YACR,KAAK,KAAK;gBACR,GAAG,IAAI,gBAAgB,CAAC;gBACxB,MAAM;YACR,KAAK,MAAM;gBACT,GAAG,IAAI,iBAAiB,CAAC;gBACzB,MAAM;YACR;gBACE,MAAM,IAAI,SAAS,CAAC,CAAA,4BAAA,EAA+B,MAAM,CAAC,QAAQ,EAAE,CAAC,CAAC;QAC1E,CAAC;IACH,CAAC;IAED,OAAO,GAAG,CAAC;AACb,CAAC;AAED;;;;;GAKG,CACH,SAAgB,cAAc,CAAC,GAAW,EAAE,OAAsB;IAChE,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,MAAM,CAAC;IACtC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC;IACvB,MAAM,MAAM,GAAG,QAAQ,CAAC,GAAG,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC;IACrC,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC;IACtC,MAAM,SAAS,GACb,KAAK,KAAK,CAAC,CAAC,GACR;QAAE,IAAI,EAAE,EAAE;QAAE,KAAK,EAAE,GAAG,CAAC,UAAU,CAAC,GAAG,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC;IAAA,CAAE,GACpD;QACE,IAAI,EAAE,UAAU,CAAC,GAAG,EAAE,CAAC,EAAE,KAAK,CAAC;QAC/B,KAAK,EAAE,GAAG,CAAC,UAAU,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,EAAE,MAAM,CAAC,CAAC;KAC/C,CAAC;IAER,IAAI,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC;IACvB,MAAO,KAAK,GAAG,GAAG,CAAE,CAAC;QACnB,MAAM,MAAM,GAAG,QAAQ,CAAC,GAAG,EAAE,KAAK,EAAE,GAAG,CAAC,CAAC;QACzC,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;QAC1C,MAAM,IAAI,GACR,KAAK,KAAK,CAAC,CAAC,GACR,UAAU,CAAC,GAAG,EAAE,KAAK,EAAE,MAAM,CAAC,GAC9B,UAAU,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;QACpC,MAAM,GAAG,GAAG,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,UAAU,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,EAAE,MAAM,CAAC,CAAC;QAE1E,OAAQ,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC;YAC3B,KAAK,UAAU;gBACb,SAAS,CAAC,QAAQ,GAAG,IAAI,CAAC;gBAC1B,MAAM;YACR,KAAK,QAAQ;gBACX,SAAS,CAAC,MAAM,GAAG,IAAI,CAAC;gBACxB,MAAM;YACR,KAAK,aAAa;gBAChB,SAAS,CAAC,WAAW,GAAG,IAAI,CAAC;gBAC7B,MAAM;YACR,KAAK,QAAQ;gBACX,SAAS,CAAC,MAAM,GAAG,GAAG,CAAC;gBACvB,MAAM;YACR,KAAK,MAAM;gBACT,SAAS,CAAC,IAAI,GAAG,GAAG,CAAC;gBACrB,MAAM;YACR,KAAK,SAAS;gBACZ,IAAI,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,SAAS,CAAC,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC;gBAClE,MAAM;YACR,KAAK,SAAS;gBACZ,IAAI,CAAC,GAAG,EAAE,MAAM;gBAChB,MAAM,IAAI,GAAG,IAAI,IAAI,CAAC,GAAG,CAAC,CAAC;gBAC3B,IAAI,MAAM,CAAC,QAAQ,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC,EAAE,SAAS,CAAC,OAAO,GAAG,IAAI,CAAC;gBAC9D,MAAM;YACR,KAAK,UAAU;gBACb,IAAI,CAAC,GAAG,EAAE,MAAM;gBAChB,MAAM,QAAQ,GAAG,GAAG,CAAC,WAAW,EAAE,CAAC;gBACnC,IACE,QAAQ,KAAK,KAAK,IAClB,QAAQ,KAAK,QAAQ,IACrB,QAAQ,KAAK,MAAM,EACnB,CAAC;oBACD,SAAS,CAAC,QAAQ,GAAG,QAAQ,CAAC;gBAChC,CAAC;gBACD,MAAM;YACR,KAAK,UAAU;gBACb,IAAI,CAAC,GAAG,EAAE,MAAM;gBAChB,MAAM,QAAQ,GAAG,GAAG,CAAC,WAAW,EAAE,CAAC;gBACnC,IACE,QAAQ,KAAK,KAAK,IAClB,QAAQ,KAAK,QAAQ,IACrB,QAAQ,KAAK,MAAM,EACnB,CAAC;oBACD,SAAS,CAAC,QAAQ,GAAG,QAAQ,CAAC;gBAChC,CAAC;gBACD,MAAM;QACV,CAAC;QAED,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC;IACrB,CAAC;IAED,OAAO,SAAS,CAAC;AACnB,CAAC;AAED;;GAEG,CACH,SAAS,QAAQ,CAAC,GAAW,EAAE,GAAW,EAAE,GAAW;IACrD,MAAM,KAAK,GAAG,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IACpC,OAAO,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,CAAC;AACpC,CAAC;AAED;;GAEG,CACH,SAAS,OAAO,CAAC,GAAW,EAAE,GAAW,EAAE,GAAW;IACpD,MAAM,KAAK,GAAG,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IACpC,OAAO,KAAK,GAAG,GAAG,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;AAClC,CAAC;AAED;;GAEG,CACH,SAAS,UAAU,CAAC,GAAW,EAAE,GAAW,EAAE,GAAW;IACvD,IAAI,KAAK,GAAG,GAAG,CAAC;IAChB,IAAI,GAAG,GAAG,GAAG,CAAC;IAEd,GAAG,CAAC;QACF,MAAM,IAAI,GAAG,GAAG,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;QACnC,IAAI,IAAI,KAAK,IAAI,CAAC,KAAA,EAAO,KAAI,IAAI,KAAK,IAAI,CAAC,MAAA,EAAQ,GAAE,MAAM;IAC7D,CAAC,OAAQ,EAAE,KAAK,GAAG,GAAG,CAAE;IAExB,MAAO,GAAG,GAAG,KAAK,CAAE,CAAC;QACnB,MAAM,IAAI,GAAG,GAAG,CAAC,UAAU,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;QACrC,IAAI,IAAI,KAAK,IAAI,CAAC,KAAA,EAAO,KAAI,IAAI,KAAK,IAAI,CAAC,MAAA,EAAQ,GAAE,MAAM;QAC3D,GAAG,EAAE,CAAC;IACR,CAAC;IAED,OAAO,GAAG,CAAC,KAAK,CAAC,KAAK,EAAE,GAAG,CAAC,CAAC;AAC/B,CAAC;AAED;;GAEG,CACH,SAAS,MAAM,CAAC,GAAW;IACzB,IAAI,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,EAAE,OAAO,GAAG,CAAC;IAExC,IAAI,CAAC;QACH,OAAO,kBAAkB,CAAC,GAAG,CAAC,CAAC;IACjC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;QACX,OAAO,GAAG,CAAC;IACb,CAAC;AACH,CAAC;AAED;;GAEG,CACH,SAAS,MAAM,CAAC,GAAQ;IACtB,OAAO,UAAU,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,eAAe,CAAC;AAClD,CAAC"}}]
}